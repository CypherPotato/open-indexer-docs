{
  "docs/authentication.html": {
    "href": "docs/authentication.html",
    "title": "Autenticação | Open Indexer",
    "keywords": "Autenticação Quando tiver sua conta em mãos, use sua chave de autenticação única para se autenticar na nossa API através do cabeçalho Authorization: curl https://open-indexer.proj.pw/api/v1/information/models.txt \\ -H 'Authorization: Bearer oky_gr5uepj...' Você também pode enviar o seu token de autorização pelo parâmetro da query ?api-key, exemplo: curl https://open-indexer.proj.pw/api/v1/information/models.txt?api-key=oky_gr5uepj... Não há necessidade de enviar o esquema de autenticação Bearer em ambos cabeçalhos, mas é possível por questões de compatibilidade. Obtendo a API Key a partir da Login Key Sua Login Key é a chave que você usa para acessar seu painel de usuário e controlar as diversas funções do Open Indexer. A partir dessa chave é possível recuperar sua API key: Requisição GET /api/v1/auth/login { \"loginKey\": \"n38oy4nq2orry7\" } Resposta { \"message\": null, \"data\": { \"apiKey\": \"oky_gr5uepj18yhdec3z6nskw3w1kqfbaawcfrwe837c8o\", \"accountName\": \"Fernando Diniz\" } }"
  },
  "docs/en/authentication.html": {
    "href": "docs/en/authentication.html",
    "title": "Authentication | Open Indexer",
    "keywords": "Authentication When you have your account in hand, use your unique authentication key to authenticate on our API through the Authorization header: curl https://open-indexer.proj.pw/api/v1/information/models.txt \\ -H 'Authorization: Bearer oky_gr5uepj...' You can also send your authorization token through the query parameter ?api-key, example: curl https://open-indexer.proj.pw/api/v1/information/models.txt?api-key=oky_gr5uepj... There is no need to send the authentication scheme Bearer in both headers, but it is possible for compatibility reasons. Obtaining the API Key from the Login Key Your Login Key is the key you use to access your user panel and control the various functions of Open Indexer. From this key, it is possible to recover your API key: Request GET /api/v1/auth/login { \"loginKey\": \"n38oy4nq2orry7\" } Response { \"message\": null, \"data\": { \"apiKey\": \"oky_gr5uepj18yhdec3z6nskw3w1kqfbaawcfrwe837c8o\", \"accountName\": \"Fernando Diniz\" } }"
  },
  "docs/en/entities/ai-gateway.html": {
    "href": "docs/en/entities/ai-gateway.html",
    "title": "AI Gateway | Open Indexer",
    "keywords": "AI Gateway The AI gateways are a service that the Open Indexer provides to create an inference tunnel between an LLM model and a knowledge base. It is possible to: Create a model with customized instructions Use a model provided by you through an OpenAI compatible endpoint, or use a model made available by the Open Indexer Customize inference parameters, such as temperature, top_p, prefill Use a knowledge collection as the foundation for AI responses Among other features. With the AI Gateway, you create a model that is ready for use, parameterized, and based on the instructions you define. Models You can bring an AI model compatible with the OpenAI interface to the AI gateway. If you bring your AI model, we will only charge for the document search attached to the AI. You can also use one of the models below that are already ready to start with the Open Indexer. When using a model, you will notice that some are more intelligent than others for certain tasks. Some models are better with certain data acquisition strategies than others. Perform tests to find the best model. You can view the available models on the models page. Choosing a search strategy If you are using a knowledge collection with an AI model, you can choose a strategy that the AI will use to perform an information search. Each strategy is more refined than the other. Some create better results than others, but it is essential to perform practical tests with several strategies to understand which one fits best in the model, conversation, and user tone. It may be necessary to make adjustments to the system prompt to better inform how the AI should consider the documents attached to the conversation. The documents are attached as a user message, limited to the parameters you define in the acquisition strategy. Strategies without rewriting cost: Plain: the default strategy. It is the least optimized and has no rewriting cost: the last user message is used as a search term to search the attached collection of the gateway. Concatenate: Concatenates the last N user messages in lines, and then the result of the concatenation is used as a search term. Strategies with rewriting cost (inference tokens are charged): UserRewrite: Rewrites the last N user messages using a smaller model, creating a contextualized question about what the user means. FullRewrite: Rewrites the last N*2 chat messages using a smaller model. Similar to UserRewrite, but also considers the assistant's messages in formulating the new question. It usually creates the best questions, with a slightly higher cost. It is the most stable and consistent strategy. It works with any model. Rewriting strategies normally generate the best results at a low latency and cost. The rewriting model used always has the lowest cost, usually chosen by an internal pool that decides which model has the lowest latency at the moment. Using AI functions (tools) At the moment, it is not possible to specify function calls through our API, either through the AI-Gateway or the OpenAI compatible API. This feature is on our radar for future implementation. If this is critical for your AI model to work, you can use the document search API in your model. Creating an AI gateway If you are using a model provided by you, have the following in hand: The base address compatible with the OpenAI API The API key of the endpoint (if applicable) The name of the inference model. It is not necessary to have a collection to link to your AI gateway. You can create an AI gateway and link a knowledge base to it later. Request POST /api/v1/ai-gateways { // Name of the gateway to identify it later. \"name\": \"my-gateway-model\", \"parameters\": { // Endpoint compatible with OpenAI chat/completions, or use @integrated // to use a model provided by the Open Indexer. \"baseAddress\": \"@integrated\", // ID of the collection that will be used as the knowledge base by the AI. // Can be null. \"knowledgeCollectionId\": \"01965b62-17c4-7258-9aa8-af5139799527\", // Optional. Specifies how many documents should be attached to the AI context. \"knowledgeBaseMaximumResults\": 16, // Optional. Specifies the minimum similarity score that the document search should attach to the AI context. \"knowledgeBaseMinimumScore\": 0.55, // Optional. Specifies whether document references should be attached to the AI context. \"knowledgeUseReferences\": false, // Optional. Specifies the document acquisition strategy. Read \"Choosing a search strategy\" to learn more. \"queryStrategy\": \"UserRewrite\", // Parameters of the acquisition strategy. \"queryStrategyParameters\": { // Optional. Specifies the number of messages that should be considered for the UserRewrite and FullRewrite strategies. Note: for FullRewrite, the value is always multiplied by 2 to consider assistant messages. \"rewriteContextSize\": 3, // Optional. Specifies the number of user messages that should be concatenated in the search term. \"concatenateContextSize\": 3 } // Optional. Specifies the API key \"Authorization: Bearer ...\" used in inference. Leave null if using an embedded Open Indexer model. \"apiKey\": null, // Required. Specifies the name of the model that will be used in inference. \"modelName\": \"@groq/compound-beta\", // Optional. Specifies the model temperature. \"temperature\": 1.25, // Optional. Specifies the model's nucleos sampling. \"topP\": null, // Optional. Specifies the model's presence penalty. \"presencePenalty\": null, // Optional. Specifies a \"stop\" term for the model. \"stop\": null, // Optional. Specifies the maximum number of response tokens for the model. \"maxCompletionTokens\": 4096, // Optional. Specifies the system prompt used in the model. \"systemInstruction\": \"You are a helpful assistant.\", // Optional. Transforms the user's question into the indicated format, where \"{prompt}\" is the user's original prompt. \"userPromptTemplate\": null, // Optional. Specifies a prefill (initialization) of the assistant's message. \"assistantPrefill\": null, // Optional. Specifies whether the assistantPrefill and stop should be included in the message generated by the assistant. \"includePrefillingInMessages\": false, // Optional. Specifies special flags for the model. Leave as \"0\" to not use any flag. The allowed flags are: // NoSystemInstruct: instead of using system prompt, inserts system instructions into a user message \"flags\": \"0\", // Optional. Passes an array of functions to the AI. \"tools\": null } } Response { \"message\": null, \"data\": { \"aiGatewayId\": \"01965b64-a8eb-716c-892d-880159a9f12d\" } } Editing an AI gateway The request body is basically the same as the create AI gateway endpoint. Instead of using POST, use PATCH. Request PATCH /api/v1/ai-gateways/{ai-gateway-id} Response { \"message\": \"Gateway edited.\", \"data\": null } Using an AI gateway The endpoint for conversing with an AI gateway is simple: it only expects the conversation. You can receive the response at once or by streaming. Request POST /api/v1/ai-gateways/{ai-gateway-id}/inference { \"messages\": [ { \"role\": \"user\", \"content\": \"How can I turn on my Civic 2015?\" } ], \"stream\": true } Response for stream=true The streaming response is based on server-sent events. The first line is always a response with debugging information. data: {\"content\":\"\",\"isFirstChunkMetadata\":true,\"embeddedDocuments\":[],\"debugInfo\":[{\"name\":\"EmbeddingTimeMs\",\"value\":7.5045},{\"name\":\"InferenceTimeMs\",\"value\":0},{\"name\":\"ElapsedTotalMs\",\"value\":8.3489},{\"name\":\"KnowledgeQueryText\",\"value\":null}]} data: {\"content\":\"[...]\",\"isFirstChunkMetadata\":false,\"embeddedDocuments\":[],\"debugInfo\":[]} data: {\"content\":\"[...]\",\"isFirstChunkMetadata\":false,\"embeddedDocuments\":[],\"debugInfo\":[]} data: {\"content\":\"[...]\",\"isFirstChunkMetadata\":false,\"embeddedDocuments\":[],\"debugInfo\":[]} data: {\"content\":\"[...]\",\"isFirstChunkMetadata\":false,\"embeddedDocuments\":[],\"debugInfo\":[]} ... data: [END] Response for stream=false { \"message\": null, \"data\": { \"generatedMessage\": \"[...]\", \"embeddedDocuments\": [], \"debugInfo\": [ { \"name\": \"EmbeddingTimeMs\", \"value\": 4140.8628 }, { \"name\": \"InferenceTimeMs\", \"value\": 4140.803 }, { \"name\": \"ElapsedTotalMs\", \"value\": 4141.4771 }, { \"name\": \"KnowledgeQueryText\", \"value\": null } ] } } Viewing an AI gateway The request below brings details of an AI gateway. Request GET /api/v1/ai-gateways/{ai-gateway-id} Response { \"message\": null, \"data\": { \"name\": \"my-gateway-client\", \"parameters\": { \"baseAddress\": \"@integrated\", \"knowledgeCollectionId\": \"01965b54-7fbd-70cd-982b-604de002ac0a\", \"knowledgeBaseMaximumResults\": 16, \"knowledgeBaseMinimumScore\": 0.55, \"knowledgeUseReferences\": false, \"queryStrategy\": \"ToolCall\", \"queryStrategyParameters\": { \"rewriteContextSize\": 3, \"concatenateContextSize\": 3 }, \"apiKey\": null, \"modelName\": \"@google/gemini-2.0-flash-lite\", \"temperature\": 1.25, \"topP\": null, \"presencePenalty\": null, \"stop\": null, \"maxCompletionTokens\": 4096, \"systemInstruction\": \"[...]\", \"userPromptTemplate\": null, \"assistantPrefill\": null, \"includePrefillingInMessages\": false, \"flags\": \"0\", \"tools\": null } } } Deleting an AI gateway Permanently removes an AI gateway. Warning When removing an AI gateway, all associated chat clients are also removed. Collections are not removed. Request DELETE /api/v1/ai-gateways/{ai-gateway-id} Response { \"message\": \"AI gateway deleted.\", \"data\": null } OpenAI Endpoint The Open Indexer provides an OpenAI compatible endpoint through an AI gateway, which facilitates the integration of the model created by the Open Indexer with existing applications. It is worth noting that only some properties are supported. In an AI gateway, you already configure the model parameters, such as System Prompt, temperature, and model name. When using this endpoint, some gateway values can be overwritten by the request. Request POST /api/v1/ai-gateways/{ai-gateway-id}/open-ai/v1/chat/completions { // The \"model\" field is required, but it does nothing in this request. It only exists to be compatible with the Open AI API. You can leave it empty or write anything in its place, as the model considered is the one defined in the AI Gateway. \"model\": \"foobar\", // Messages must follow the Open AI format. Only \"system\" and \"user\" are supported as conversation \"roles\". \"messages\": [ { \"role\": \"system\", \"content\": \"You are a helpful assistant.\" }, { \"role\": \"user\", \"content\": \"Hello!\" } ], // Both properties are equivalent and optional, and will replace the maxCompletionTokens field if sent in the request. \"max_completion_tokens\": 1024, \"max_tokens\": 1024, // Optional. Replaces the gateway parameter. \"stop\": \"\\n\", // Optional. By default, the response is not streaming. \"stream\": true } Response for non-streaming { \"id\": \"019672f3-699c-7d45-8484-7a23f4cdc079\", \"object\": \"chat.completion\", \"created\": 1745685277, \"model\": \"gemini-2.0-flash-lite\", \"choices\": [ { \"index\": 0, \"message\": { \"role\": \"assistant\", \"content\": \"Hi there! How can I help you today?\\n\", \"refusal\": null, \"annotations\": [] }, \"logprobs\": null, \"finish_reason\": \"stop\" } ], \"usage\": { \"prompt_tokens\": 0, \"completion_tokens\": 0, \"total_tokens\": 0 }, \"service_tier\": \"default\" } Response for streaming data: {\"id\":\"019672f4-9a58-7932-82f0-022e457a2e63\",\"object\":\"chat.completion.chunk\",\"created\":1745685355,\"model\":\"gemini-2.0-flash-lite\",\"system_fingerprint\":\"fp_2i0nmn\",\"choices\":[{\"index\":0,\"finish_reason\":null,\"delta\":{\"role\":\"assistant\",\"content\":\"Hi\"}}]} data: {\"id\":\"019672f4-9ab9-73a2-bdb8-23c4481453a8\",\"object\":\"chat.completion.chunk\",\"created\":1745685355,\"model\":\"gemini-2.0-flash-lite\",\"system_fingerprint\":\"fp_ar1qol\",\"choices\":[{\"index\":0,\"finish_reason\":null,\"delta\":{\"content\":\" there! How can I help you today?\\n\"}}]} ... data: {\"id\":\"019672f4-9ac0-7ddf-a76a-e7f8043dd082\",\"object\":\"chat.completion.chunk\",\"created\":1745685355,\"model\":\"gemini-2.0-flash-lite\",\"system_fingerprint\":\"fp_3e84ge\",\"choices\":[{\"index\":0,\"finish_reason\":\"stop\",\"delta\":{}}]}"
  },
  "docs/en/entities/chat-clients.html": {
    "href": "docs/en/entities/chat-clients.html",
    "title": "Chat Clients | Open Indexer",
    "keywords": "Chat Clients A chat client provides a user interface through an AI Gateway that allows the user to converse with their assistant. A chat client is integrated with the AI gateway's inference and supports deep thinking, research, and text conversation. Multi-modal features, such as sending images and audio, are under development. Note The Open Indexer never stores the content of a chat between a client and the user. You can use JavaScript for this task, but it is your responsibility to use and store it. You can customize the interface of your chat client with custom CSS and JavaScript, as well as choose the language of the chat features. Creating a Chat Client Create a new chat client. POST /api/v1/web-chat-client/ { // Specifies the public name of your chat client \"name\": \"My Assistant\", // Specifies the ID of the AI gateway to be used by the chat \"aiGatewayId\": \"01965b64-a8eb-716c-892d-880159a9f12d\", \"clientParameters\": { // Optional. Specifies the language code to be used in the chat for most elements, such as error messages, buttons, etc. // Values: pt-BR, en \"languageCode\": \"pt-BR\" | \"en\", // Optional. Specifies a JavaScript code to execute in the chat. \"customScripts\": null, // Optional. Specifies a CSS code to apply custom styles to the chat. \"customStyles\": null, // Optional. Specifies the highlight color of the chat client elements. \"primaryColor\": \"#eabe44\", // Optional. Specifies the title of the chat page. \"pageTitle\": \"Assistant\", // Optional. Specifies the title when entering the chat for the first time. \"helloLabel\": \"It's great to see you here.\", // Optional. Specifies the subtitle when entering the chat for the first time. \"helloSubLabel\": \"I'm your assistant.\", // Optional. Specifies the placeholder of the message sending field. \"textAreaPlaceholder\": \"Talk to the assistant\", // Optional. Specifies an image/logo to display in the chat for the first time. \"logoImageUrl\": null, // Optional. Enables debugging features. \"debug\": true, // Optional. Specifies which origins should be allowed to embed the chat client in an iframe. If this field is empty, any origin will be accepted. \"allowedFrameOrigins\": [\"https://my-domain.com.br\"], // Optional. Specifies conversation suggestion buttons when starting a new chat session. You can add as many buttons as you want, but it is recommended to have up to 3 buttons. \"suggestionButtons\": [ { // Title to be displayed on the button. \"label\": \"How to buy a car?\", // Prompt to be sent to the model. \"prompt\": \"Where and how can I buy a car in your store?\" }, ... ] }, \"limitingParameters\": { // Optional. Specifies how many messages the user can send per hour in the chat. This option is tracked by the userTag of the session. \"messagesPerHour\": 30, // Optional. Specifies the maximum number of tokens that a user message can contain. This field is only valid when used with models integrated into the Open Indexer. \"userInputMaxTokens\": 1024, // Optional. Specifies the limit of messages (for the user and AI) that a session can have. \"maxMessages\": 300 } } Response { \"message\": null, \"data\": { \"id\": \"01965b65-e95e-7795-848c-ff0919ef1436\" } } Editing a Chat Client The body of this request is exactly the same as creating a chat client. PUT /api/v1/web-chat-client/{chat-client-id} Response { \"message\": \"Web client updated successfully.\", \"data\": null } Listing Chat Clients Get a list of created chat clients. GET /api/v1/web-chat-client/ Response { \"message\": null, \"data\": [ { \"id\": \"01965b59-daf6-7809-94c8-2a65b7264dba\", \"name\": \"My Chat Client\" }, ... ] } Viewing a Specific Chat Client Get details of an existing chat client. GET /api/v1/web-chat-client/{chat-client-id} Response { \"message\": null, \"data\": { \"name\": \"My Chat Client\", \"aiGateway\": { \"id\": \"01965b59-49ff-7753-8327-b3b6a6a871f2\", \"name\": \"gateway-t1\", \"knowledgeCollection\": { \"id\": \"01965b54-7fbd-70cd-982b-604de002ac0a\", \"name\": \"Car Information\" } }, \"limitingParameters\": { \"messagesPerHour\": 30, \"userInputMaxTokens\": 1024, \"maxMessages\": 500 }, \"clientParameters\": { \"languageCode\": \"pt-BR\", \"customScripts\": null, \"customStyles\": null, \"primaryColor\": \"#f011d2\", \"pageTitle\": \"Lyra\", \"helloLabel\": \"It's great to see you here.\", \"helloSubLabel\": \"I'm your assistant.\", \"textAreaPlaceholder\": \"Talk to the assistant\", \"logoImageUrl\": null, \"debug\": true, \"allowedFrameOrigins\": [] } } } Creating a Chat Session A chat session is where you create a conversation between your chat client and the user. You can call this endpoint providing additional context for the conversation, such as the user's name, location, etc. A chat session expires after a certain time for security reasons of the generated access token. When you call this endpoint providing a tag, you can call the same endpoint multiple times and get the active chat session for the informed tag, or create a new chat if there is no ongoing session. A chat session also restores all conversation messages from the same session after disconnection. The user can clear the conversation by clicking the clear conversation button in the top right corner of the chat client. This session uses the limits defined by the chat client, such as the maximum number of messages and tokens in the conversation. A session is automatically renewed for another 3 days when receiving a message from the user. Important It is only possible to determine the number of tokens used in a message when using a model provided by the Open Indexer. If you use an external model, the limitingParameters.userInputMaxTokens property will be ignored. POST /api/v1/web-chat-client/{chat-client-id}/sessions { // Optional. Additional context for the AI about the chat. \"extraContext\": \"# Additional context\\r\\n\\r\\nYou are talking to Eduardo.\", // Time in seconds for the chat to expire. The minimum is 10 minutes. The maximum is 30 days. \"expires\": 3600, // Optional (recommended). An external ID to identify the session later and reuse it whenever you call the same endpoint. It can be the ID of the user in your database or a string that facilitates the identification of this chat later. \"tag\": \"my-user-tag\" } Response { \"message\": null, \"data\": { // ID of the created chat session. \"sessionId\": \"01966f0b-172d-7bbc-9393-4273b86667d2\", // Public access key of the chat. \"accessKey\": \"wky_gr5uepjsgrhuqcj3aaat1iagrsmozwr9gghusnnu6zjhrsyures5xoe\", // Public URL to converse with the chat. \"talkUrl\": \"https://preview-s01.proj.pw/www/web-chat-clients/wky_gr5uepjsgrhuqcj3aaat1iagrsmozwr9gghusnnu6zjhrsyures5xoe\" } }"
  },
  "docs/en/entities/collections.html": {
    "href": "docs/en/entities/collections.html",
    "title": "Collections | Open Indexer",
    "keywords": "Collections A collection is a knowledge library: it houses several knowledge documents. Use collections to group documents by purpose, such as documenting a product, a company, a service, or workflow. Collections do not incur costs. There is no limit to the number of collections per account. Create a Collection To create an empty collection, provide only its name: Request POST /api/v1/collections { // The collection name cannot be empty. \"collectionName\": \"My first collection\" } Response { \"message\": null, \"data\": { // Unique ID of the created collection. \"collectionId\": \"01965b62-17c4-7258-9aa8-af5139799527\", // A private key used to perform semantic queries on the collection. \"queryKey\": \"cky_gr5uepj18yhuop3zcsa4c7b8stdmpgg7kk4jaf4iug6x3hg7umyhk3o\" } } List Collections Lists the collections available in your account. Request GET /api/v1/collections Response { \"message\": null, \"data\": { \"pageInfo\": { \"currentPage\": 1, \"hasMoreItems\": true }, \"items\": [ { \"id\": \"01965b62-17c4-7258-9aa8-af5139799527\", \"createdAt\": \"2025-04-22T02:44:37\", \"name\": \"My collection\" }, { \"id\": \"01965b54-7fbd-70cd-982b-604de002ac0a\", \"createdAt\": \"2025-04-22T02:29:46\", \"name\": \"Another collection\" } ] } } View a Collection Obtains details of a collection, such as its indexing progress and information like creation date. Request GET /api/v1/collections/{collection-id}/ Response { \"message\": null, \"data\": { \"name\": \"My collection\", \"createdAt\": \"2025-04-22T02:29:46\", \"queryKey\": \"cky_gr5uepj18yhd1qbshep7bki5e83hftbp6hbep97r8di9n4tta9ykswo\", \"state\": { // Returns the number of documents waiting for indexing \"queuedDocuments\": 0, // Number of documents ready for query \"indexedDocuments\": 227 } } } Delete a Collection Deletes a collection and all documents within it. This action is irreversible. Request DELETE /api/v1/collections/{collection-id}/ Response { \"message\": \"Collection deleted successfully.\", \"data\": null } Clear a Collection Unlike deleting a collection, this operation removes all documents from the collection, including indexed and queued ones. Request DELETE /api/v1/collections/{collection-id}/reset-only Response { \"message\": \"Collection cleaned successfully.\", \"data\": null }"
  },
  "docs/en/entities/documents.html": {
    "href": "docs/en/entities/documents.html",
    "title": "Documents | Open Indexer",
    "keywords": "Documents A document represents a piece of knowledge. It is a limited, self-sufficient, and meaningful piece of information on its own. A document is the component that is indexed by the internal model to be retrieved later through a semantic search term. Consider a car manual: it is not a document, but rather several documents. Each of these documents talks, in isolation, about a specific topic related to that car, in such a way that the document does not depend on external context or information to make sense. Each document in this manual will discuss a topic: one will discuss how to turn on the car, another how to turn it off, another how the paint is made, and another how to change the oil periodically. It is not a good idea to reserve a document to discuss several things at the same time, as this will reduce the objectivity and scope of the inference and reduce the quality of acquisition. Examples of document creation: ❌ Do not Do not create very short documents (with 10 or fewer words). Do not create very large documents (with 700 or more words). Do not discuss more than one thing in a document. Do not mix different languages in documents. Do not be implicit in documents. Do not write documents using technical language, such as codes or structures like JSON. ✅ Do Be explicit about the purpose of your document. Focus documents on individual topics, summarizing what should be done or explained. Always repeat terms that are keywords for the document search. Example: prefer to use \"The color of the Honda Civic 2015 is yellow\" instead of \"the color of the car is yellow\". Restrict the document content to discuss only one topic or subject. Use simple and easy-to-understand human language. Using the API As all documents are entities that belong to a collection, always have the collection where the document is/will be located at hand. Sending documents in bulk To send a large list of documents to a collection, structure them following the JSONL format. The indexing file structure is: {\"docid\":\"Cars/HondaCivic2015.rmd:1\",\"text\":\"The Honda Civic 2015 is available in [...]\",\"__ref\":null,\"__tags\":[\"Cars\",\"Honda-Civic-2015\"]} {\"docid\":\"Cars/HondaCivic2015.rmd:2\",\"text\":\"The engine of the Honda Civic 2015 is [...]\",\"__ref\":null,\"__tags\":[\"Cars\",\"Honda-Civic-2015\"]} {\"docid\":\"Cars/HondaCivic2015.rmd:3\",\"text\":\"The color of the Honda Civic 2015 is Yellow [...]\",\"__ref\":null,\"__tags\":[\"Cars\",\"Honda-Civic-2015\"]} ... The structure consists of the following properties: Property Type Description docid string Specifies the name of the document. Useful for debugging and identification. text string The \"raw\" content of the document that will be indexed. __ref string Optional. Specifies a reference ID for the document. __tags string[] Optional. Specifies an array of tags for the document. Useful for document management. A document reference is an ID that can be specified in several documents that need to be linked in a search when one of them is matched in a similarity search. For example, if a search finds a document that has a reference ID, all other documents in the same collection that share the same reference ID as the matched document will also be included in the search response. The use of references can be useful when a document depends on another or more documents to make sense. There is no format requirement for the reference ID: any format is accepted. You can send up to 1,000 lines of documents per request. If you need to send more documents, separate the sending into more requests. If you send a document with more than 1,000 lines, the following lines will be ignored. Note that very long documents, which exceed the allowed number of tokens in the internal embedding model, will have their content truncated and the indexing quality may be severely affected. To avoid this problem, send documents that contain between 20 and 700 words. Warning Warning: this endpoint generates cost. The cost is calculated based on the tokens of the content of each document. The content of each document is tokenized according to the model used in the indexing of the documents. Request The sending must be done using multipart form data. POST /api/v1/collections/{collection-id}/documents documents=[documents.jsonl] Response { \"message\": null, \"data\": [ { \"name\": \"Institutional/Company.rmd:1\", \"documentId\": \"01965f93-a36b-7fc2-9e6a-c733f4955927\" }, { \"name\": \"Institutional/Company.rmd:2\", \"documentId\": \"01965f93-a390-79d3-9b3d-338d407f6b64\" }, { \"name\": \"Institutional/Company.rmd:3\", \"documentId\": \"01965f93-a391-79ef-adcf-737d98303a78\" }, { \"name\": \"Products/Scheduling.rmd:1\", \"documentId\": \"01965f93-a391-712e-9292-c4d8e010bf42\" }, ... ] } Create or modify document This endpoint creates or modifies a document from its name. When a document is modified, its indexing vectors are reset, i.e., the document will be re-indexed by the indexing engine. This indexing is not cost-free. The cost is relative to the number of tokens in the sent content. Warning Warning: this endpoint generates cost. The cost is calculated based on the tokens of the file content. The file content is tokenized according to the model used in the indexing of the documents. Request PUT /api/v1/collections/{collection-id}/documents { // the name of the document to be modified \"name\": \"document-name\", // the content of the document to be created or overwritten if the name already exists \"contents\": \"Content of my document\", // parameters explained earlier \"reference\": null, \"tags\": [\"products\", \"my-product\"] } Response { \"message\": null, \"data\": { \"documentId\": \"0196663c-3a15-72c7-98e6-b496f8e8bb8c\", // the operation status indicates whether the document was modified \"Modified\" or created \"Created\". \"state\": \"Modified\" } } List documents This endpoint lists all available documents in a collection. Request GET /api/v1/collections/{collection-id}/documents Response { \"message\": null, \"data\": { \"pageInfo\": { \"currentPage\": 1, \"hasMoreItems\": true }, \"items\": [ { \"id\": \"01965b54-b31c-7184-9f5c-60b2648106d9\", \"name\": \"Institutional/Company.rmd:1\", \"reference\": null, \"tags\": [] }, { \"id\": \"01965b54-b32b-7433-b90b-73d71d21ae38\", \"name\": \"Institutional/Company.rmd:2\", \"reference\": null, \"tags\": [] }, { \"id\": \"01965b54-b32b-79bb-ac5e-729dfec701a8\", \"name\": \"Products/Scheduling.rmd:1\", \"reference\": null, \"tags\": [] }, ... ] } } View document View details about a specific document. Request GET /api/v1/collections/{collection-id}/documents/{document-id} Response { \"message\": null, \"data\": { \"id\": \"01965f93-a36b-7fc2-9e6a-c733f4955927\", \"name\": \"Institutional/Company.rmd:1\", // represents the indexing status of the document. // valid values: Queued, Indexed, Cancelled \"state\": \"Indexed\", // content of the indexed document \"contents\": \"...\", // id of the document reference \"reference\": \"institutional-company\", // brings all documents that share the same reference \"references\": [ { \"id\": \"01965b54-b32b-7433-b90b-73d71d21ae38\", \"name\": \"Institutional/Company.rmd:2\" }, { \"id\": \"01965b54-b31c-7184-9f5c-60b2648106d9\", \"name\": \"Institutional/Company.rmd:3\" } ] } } Delete document Permanently deletes a document through its ID. Request DELETE /api/v1/collections/{collection-id}/documents/{document-id} Response { \"message\": \"Document removed.\", \"data\": null }"
  },
  "docs/en/entities/functions.html": {
    "href": "docs/en/entities/functions.html",
    "title": "Functions | Open Indexer",
    "keywords": "Functions Functions are a way to force your model to process information using JSON as an intermediate communication method. With functions, you can make any model respond in the JSON format you want. It can be useful for categorizing comments, applying moderation to reviews, or processing information with the help of AI. Currently, it is only possible to use functions with models provided by Open Indexer. Calling a Function To call an AI function, you will need to inform what the AI should respond with and provide a JSON schema that it should follow. Less intelligent models tend to fail JSON generation, producing an invalid or problematic document. To address this, adjust your model, instruction, and attempt parameter if necessary. You are charged for each attempt the AI makes to generate a response. Slightly more intelligent models tend to produce correct results on the first attempt. It is guaranteed that a valid JSON will be generated, but it is not guaranteed that the model will follow the names and types provided by your JSON schema. Request POST /api/v1/functions/json { // Specify the name of the integrated model to be used for the action. \"modelName\": \"@metaai/llama-3.1-8b\", // Explain what your model should do with the input and how it should provide the response. \"instructions\": \"Classify the user's comment, indicating whether it is positive or negative, and if it contains any relevant information (number between 0 (not relevant) and 10 (very relevant))\", // The JSON object that the model should generate. You can provide generation examples in the instructions field. This object must be a valid JSON in the API. // This object must be an object, an array, or a string. \"responseSchema\": { \"feedbackType\": \"neutral | positive | negative\", \"informationScore\": 5 }, // Optional. Defines a JSON input for the model. Can be any type of JSON value. \"inputData\": { \"userComment\": \"Terrible market. There's a guard inside watching you so you don't steal, and the butchers ignore you and attend to pretty girls in front of you. But thank God there are other markets coming, and the end of this circus will arrive\" }, // Optional. Defines the number of attempts the model should make before the API returns an error. Must be a number between 1 and 30. \"maxAttempts\": 10, // Optional. Defines the time limit in seconds to obtain a valid JSON before the API returns an error. Must be a number between 1 and 3600 (one hour). \"timeout\": 300 } Response { \"message\": null, \"data\": { // The result contains the object defined in \"responseSchema\", with the fields filled in by the AI \"result\": { \"feedbackType\": \"negative\", \"informationScore\": 8 }, // In which attempt the AI managed to get a valid JSON \"attempt\": 1, // The time in milliseconds to obtain a valid JSON \"elapsedMilliseconds\": 527 } } Examples Check out examples of AI functions for various everyday tasks: Summarize order and classify if it requires attention or not POST /api/v1/functions/json { \"modelName\": \"@metaai/llama-4-scout-17b\", \"instructions\": \"Summarize the user's comment, creating a short description with a maximum of 10 words indicating what they want to do. Also, indicate whether this comment requires attention or not.\", \"responseSchema\": { \"shortSummary\": \"...\", \"requiresAttention\": false }, \"inputData\": \"The customer Fernando de Castro has been trying to contact support since Friday and says he will cancel if he doesn't speak to someone today. He also said he is a friend of Rebeca from the commercial and is threatening to speak badly about the company on TikTok. Please, can someone attend to this guy??\" } { \"message\": null, \"data\": { \"result\": { \"shortSummary\": \"Customer wants contact with support to avoid cancellation and threatens\", \"requiresAttention\": true }, \"attempt\": 1, \"elapsedMilliseconds\": 639 } }"
  },
  "docs/en/entities/search.html": {
    "href": "docs/en/entities/search.html",
    "title": "Search | Open Indexer",
    "keywords": "Search The search API, through the query key obtained from the collections, performs a semantic search on it, performing an intelligent comparison for each indexed document in a collection. After creating a collection, you will obtain a query key, which will be used to perform the semantic search in your collection. The search routes do not need to be identified by an Authorization header. Use the endpoints of this API to embed semantic document search in your AI model or chatbot. Searching documents This endpoint expects a GET request with the following parameters: key: required. Specifies the Query Key of the collection to be consulted. term: required. Specifies the search term that will be searched in the documents. top: Specifies the maximum number of documents that should be returned in the search. min: Specifies the minimum score for obtaining the documents. Warning Warning: this endpoint generates cost. The cost is calculated based on the tokens of the search term. The search term is tokenized according to the model used in the indexing of the documents. Request GET /api/v1/search key=cky_gr5uepj18yhd1qbshep7&term=What is the color of the Honda CIVIC? Response { \"message\": null, \"data\": [ { \"documentId\": \"01965f93-a391-71a8-968a-47ccd4949de0\", \"documentName\": \"Products/Honda Civic 2015.rmd:1\", \"documentContent\": \"[...]\", \"score\": 0.7972834229469299, \"referencedDocuments\": [] }, { \"documentId\": \"01965f93-a391-76b3-bbf5-3fb74d10d412\", \"documentName\": \"Products/Honda Civic 2015.rmd:2\", \"documentContent\": \"[...]\", \"score\": 0.5693517327308655, \"referencedDocuments\": [] }, { \"documentId\": \"01965f93-a391-7026-b7aa-1cc6c63cd7d1\", \"documentName\": \"Products/Honda Civic 2015.rmd:5\", \"documentContent\": \"[...]\", \"score\": 0.5475733876228333, \"referencedDocuments\": [] }, ... ] } For the search result, the higher the score, the more similar the document is to the search term. The Open Indexer uses embedding models that allow task orientation. For the search, the term is vectorized with a DOCUMENT_QUERY orientation. For document indexing, the orientation is DOCUMENT_RETRIEVAL, which provides a more optimized search and not to verify the similarity between documents."
  },
  "docs/en/getting-started.html": {
    "href": "docs/en/getting-started.html",
    "title": "Welcome | Open Indexer",
    "keywords": "Welcome Welcome to Open Indexer. Our service makes it easier to develop intelligent AI models that use a knowledge base provided by you to converse with the user, answer questions, provide real-time information, and more. To get started, all endpoints must be made to the Open Indexer production URL: https://open-indexer-api.proj.pw/ Concepts and definitions Understand the concepts used by the API below: Account: represents a user account, which has an authentication token. Collection: represents a collection of knowledge documents. A user can have multiple document collections. Document: represents a fact, a single piece of knowledge, and an item in a collection. A collection can have multiple documents. AI Gateway: represents an AI gateway that benefits from or does not use a knowledge collection, such as a plug-and-play knowledge middleware for a model. Embedded model: represents an AI model that Open Indexer provides to the user. Chat client: represents a user interface that makes the AI gateway available through an interactive online chat. Chat session: hosts a conversation and context of a chat client. Handling errors All API errors return an HTTP response with a non-OK status (never 2xx or 3xx), and always follow the JSON format: { \"error\": \"An error explanation message\", \"data\": {} // an object containing relevant error information. Most of the time it is null }"
  },
  "docs/en/models.html": {
    "href": "docs/en/models.html",
    "title": "Models | Open Indexer",
    "keywords": "Models The Open Indexer provides models from different providers to make development even faster, eliminating the need to configure an account for each provider to access their latest models. See the list below of available models and their pricing. All prices consider the total input and output of tokens, with or without cache. All prices are in United States dollars. DeepSeek Model Name Price/1m tokens Description @deepseekai/r1-distill-llama-70b $ 2.76 Model with reasoning and deep thinking, better for more demanding tasks. Thinking Function calls Google Model Name Price/1m tokens Description @google/gemini-2.5-pro $ 12.25 One of the most powerful models currently available. Thinking Input: accepts images, videos, and audio Function calls @google/gemini-2.5-flash-think $ 4.65 Model from the latest generation with integrated reasoning and thinking. Thinking Input: accepts images, videos, and audio Function calls @google/gemini-2.5-flash $ 1.31 Model from the latest generation, without deep thinking. Input: accepts images, videos, and audio Function calls @google/gemma2-9b $ 0.70 Fast model, Google's open-source study to perform most tasks. Function calls @google/gemini-2.0-flash-lite $ 0.67 General-purpose model, with image recognition, smart, and fast. Ideal for an economic chat. Input: accepts images, videos, and audio Function calls @google/gemini-1.5-flash-8b $ 0.33 General-purpose model from the previous generation, optimized for less demanding and simple tasks. Input: accepts images, videos, and audio Function calls OpenAI Model Name Price/1m tokens Description @openai/o1-mini $ 6.50 A small and smart model with reasoning. Thinking @openai/gpt-4o-mini $ 1.31 Fast and cheap for focused tasks. Input: accepts images Function calls @openai/gpt-4.1-nano $ 0.88 The fastest and cheapest model of GPT 4.1. Input: accepts images Function calls Meta AI Model Name Price/1m tokens Description @metaai/llama-3.3-70b $ 2.40 Model from the previous generation with many parameters and surprisingly fast speed. Function calls @metaai/llama-4-maverick-17b $ 1.40 Fast model, with 17 billion parameters activated and 128 experts. Input: accepts images Function calls @metaai/llama-4-scout-17b $ 0.79 Smaller version of the Llama 4 family with 17 billion parameters activated and 16 experts. Input: accepts images Function calls @metaai/llama-3.1-8b $ 0.23 Cheap and fast model for less demanding tasks. Function calls Groq Model Name Price/1m tokens Description @groq/compound-beta $ 3.25 Conversation agent that searches the internet for contextualization and real-time information. Live data Input: accepts images Function calls @groq/compound-beta-mini $ 2.60 Smaller version of the Compound family, with fewer experts. Live data Input: accepts images Function calls Qwen Model Name Price/1m tokens Description @qwen/qwq-32b $ 1.23 Conversation model with thinking and reasoning for solving complex tasks. Thinking Function calls"
  },
  "docs/entities/ai-gateway.html": {
    "href": "docs/entities/ai-gateway.html",
    "title": "AI Gateway | Open Indexer",
    "keywords": "AI Gateway Os gateways de AI é um serviço que a Open Indexer fornece para criar um túnel de inferência entre um modelo de LLM e uma base de conhecimento. Nele é possível: Criar um modelo com instruções personalizadas Usar um modelo provido por você através de um endpoint OpenAI compatível, ou usar um modelo disponibilizado pela Open Indexer Personalizar parâmetros de inferência, como temperatura, top_p, prefill Usar uma coleção de conhecimento como fundação de respostas para IA Dentre outros recursos. Com o AI Gateway, você cria um modelo pronto para uso, parametrizado e fundamentado nas instruções que você definir. Modelos Você pode trazer um modelo de IA compatível com a interface OpenAI para o gateway de IA. Se você trazer seu modelo de IA, iremos cobrar apenas pela pesquisa de documentos anexada na IA. Você também pode usar um dos modelos abaixo que já estão prontos para começar com o Open Indexer. Ao usar um modelo, você perceberá que alguns são mais inteligentes que outros para determinadas tarefas. Alguns modelos são melhores com certas estratégias de obtenção de dados do que outros. Realize testes para encontrar o melhor modelo. Você pode ver os modelos disponíveis na página de modelos. Escolhendo uma estratégia de busca Se você for usar uma coleção de conhecimento com um modelo de IA, você poderá escolher uma estratégia que a IA usará para realizar uma busca por informação. Cada estratégia é mais refinada que a outra. Algumas criam resultados melhores que as demais, mas é importante realizar testes práticos com várias estratégias para entender qual se ajusta melhor no modelo, conversa e tom do usuário. Talvez seja necessário realizar ajustes no prompt do sistema para informar melhor como a IA deverá considerar os documentos anexados na conversa. Os documentos são anexados como uma mensagem do usuário, limitados aos parâmetros que você define na estratégia de obtenção. Estratégias sem custo de reescrita: Plain: a estratégia padrão. É a menos otimizada e não possui custo de reescrita: a última mensagem do usuário é usada como termo de busca para pesquisar na coleção anexada do gateway. Concatenate: Concatena em linhas as últimas N mensagens do usuário, e então o resultado da concatenação é usada como termo de busca. Estratégias com custo de reescrita (os tokens de inferência são cobrados): UserRewrite: reescreve as últimas N mensagens do usuário usando um modelo menor, criando uma pergunta contextualizada no que o usuário quer dizer. FullRewrite: reescreve as últimas N*2 mensagens do chat usando um modelo menor. Similar ao UserRewrite, mas considera também as mensagens da assistente na formulação da nova pergunta. Geralmente cria as melhores perguntas, com um custo um pouco maior. É a estratégia mais estável e consistente. Funciona com qualquer modelo. Estratégias com reescrita normalmente geram os melhores resultados à um baixo custo de latência e custo. O modelo de reescrita usado sempre o com menor custo, escolhido normalmente por um pool interno que decide o modelo que está com menor latência no momento. Usando funções (tools) de IA No momento, não é possível especificar chamadas de função através da nossa API, seja pelo AI-Gateway ou pela API OpenAI compatível. Esse recurso está no nosso radar para implementação futura. Se isso é crítico para seu modelo de IA funcionar, você pode usar a API de busca de documentos no seu modelo. Criando um gateway de IA Se for usar um modelo providenciado por você, tenha em mãos: O base address compatível com a API OpenAI A chave de API do endpoint (se aplicável) O nome do modelo de inferência. Não é necessário ter uma coleção para vincular no seu gateway de IA. Você pode criar um gateway de IA e vincular uma base de conhecimento nela posteriormente. Requisição POST /api/v1/ai-gateways { // Nome do gateway para identificá-lo posteriormente. \"name\": \"my-gateway-model\", \"parameters\": { // Endpoint compatível com chat/completions da OpenAI, ou use @integrated // para usar um modelo provido pela Open Indexer. \"baseAddress\": \"@integrated\", // ID da coleção que será usada como base de conhecimento pela IA. // Pode ser nulo. \"knowledgeCollectionId\": \"01965b62-17c4-7258-9aa8-af5139799527\", // Opcional. Especifica quantos documentos devem ser anexados no contexto da IA. \"knowledgeBaseMaximumResults\": 16, // Opcional. Especifica a pontuação mínima de similaridade que a busca de documentos deve anexar no contexto da IA. \"knowledgeBaseMinimumScore\": 0.55, // Opcional. Especifica se referências de documentos devem ser anexadas no contexto da IA. \"knowledgeUseReferences\": false, // Opcional. Especifica a estratégia de obtenção de documentos. Leia \"Escolhendo uma estratégia de busca\" para saber mais. \"queryStrategy\": \"UserRewrite\", // Parâmetros da estratégia de obtenção. \"queryStrategyParameters\": { // Opcional. Especifica a quantidade de mensagens que devem ser consideradas para as estratégias UserRewrite e FullRewrite. Nota: para FullRewrite, o valor sempre é multiplicado por 2 para considerar mensagens da assistente. \"rewriteContextSize\": 3, // Opcional. Especifica a quantidade de mensagens do usuário que devem ser concatenadas no termo da busca. \"concatenateContextSize\": 3 }, // Opcional. Especifica a chave de api \"Authorization: Bearer ...\" usado na inferência. Deixe nulo se usar um modelo embutido da Open Indexer. \"apiKey\": null, // Obrigatório. Especifica o nome do modelo que será usado na inferência. \"modelName\": \"@groq/compound-beta\", // Opcional. Especifica a temperatura do modelo. \"temperature\": 1.25, // Opcional. Especifica o nucleos sampling do modelo. \"topP\": null, // Opcional. Especifica a penalidade de presença de tokens do modelo. \"presencePenalty\": null, // Opcional. Especifica um termo de \"stop\" para o modelo. \"stop\": null, // Opcional. Especifica o máximo de tokens de resposta do modelo. \"maxCompletionTokens\": 4096, // Opcional. Especifica o system-prompt usado no modelo. \"systemInstruction\": \"Você é uma assistente amigável.\", // Opcional. Transforma a pergunta do usuário para o formato indicado abaixo, onde \"{prompt}\" é o prompt original do usuário. \"userPromptTemplate\": null, // Opcional. Especifica um prefill (inicialização) da mensagem da assistente. \"assistantPrefill\": null, // Opcional. Especifica se o assistantPrefill e o stop devem ser incluídos na mensagem gerada pela assistente. \"includePrefillingInMessages\": false, // Opcional. Especifica flags especiais para o modelo. Deixe como \"0\" para não usar nenhuma flag. As flags permitidas são: // NoSystemInstruct: ao invés de usar system prompt, insere as instruções do system em uma mensagem de usuário \"flags\": \"0\", // Opcional. Passa um array de funções para a IA. \"tools\": null } } Resposta { \"message\": null, \"data\": { \"aiGatewayId\": \"01965b64-a8eb-716c-892d-880159a9f12d\" } } Editar um gateway de IA O corpo da requisição é basicamente o mesmo do endpoint de criar um ai-gateway. Ao invés de usar POST, use PATCH. Requisição PATCH /api/v1/ai-gateways/{ai-gateway-id} Resposta { \"message\": \"Gateway editted.\", \"data\": null } Usar um gateway de IA O endpoint de conversação com um gateway de IA é simples: ele espera apenas a conversa. Você pode receber a resposta de uma vez ou por streaming. Requisição POST /api/v1/ai-gateways/{ai-gateway-id}/inference { \"messages\": [ { \"role\": \"user\", \"content\": \"Como eu posso ligar meu Civic 2015?\" } ], \"stream\": true } Resposta para stream=true A resposta de streaming é baseada em server-sent events. A primeira linha sempre é uma resposta com informações de depuração. data: {\"content\":\"\",\"isFirstChunkMetadata\":true,\"embeddedDocuments\":[],\"debugInfo\":[{\"name\":\"EmbeddingTimeMs\",\"value\":7.5045},{\"name\":\"InferenceTimeMs\",\"value\":0},{\"name\":\"ElapsedTotalMs\",\"value\":8.3489},{\"name\":\"KnowledgeQueryText\",\"value\":null}]} data: {\"content\":\"[...]\",\"isFirstChunkMetadata\":false,\"embeddedDocuments\":[],\"debugInfo\":[]} data: {\"content\":\"[...]\",\"isFirstChunkMetadata\":false,\"embeddedDocuments\":[],\"debugInfo\":[]} data: {\"content\":\"[...]\",\"isFirstChunkMetadata\":false,\"embeddedDocuments\":[],\"debugInfo\":[]} data: {\"content\":\"[...]\",\"isFirstChunkMetadata\":false,\"embeddedDocuments\":[],\"debugInfo\":[]} ... data: [END] Resposta para stream=false { \"message\": null, \"data\": { \"generatedMessage\": \"[...]\", \"embeddedDocuments\": [], \"debugInfo\": [ { \"name\": \"EmbeddingTimeMs\", \"value\": 4140.8628 }, { \"name\": \"InferenceTimeMs\", \"value\": 4140.803 }, { \"name\": \"ElapsedTotalMs\", \"value\": 4141.4771 }, { \"name\": \"KnowledgeQueryText\", \"value\": null } ] } } Ver um gateway de IA A requisição abaixo traz detalhes de um AI gateway. Requisição GET /api/v1/ai-gateways/{ai-gateway-id} Resposta { \"message\": null, \"data\": { \"name\": \"my-gateway-client\", \"parameters\": { \"baseAddress\": \"@integrated\", \"knowledgeCollectionId\": \"01965b54-7fbd-70cd-982b-604de002ac0a\", \"knowledgeBaseMaximumResults\": 16, \"knowledgeBaseMinimumScore\": 0.55, \"knowledgeUseReferences\": false, \"queryStrategy\": \"ToolCall\", \"queryStrategyParameters\": { \"rewriteContextSize\": 3, \"concatenateContextSize\": 3 }, \"apiKey\": null, \"modelName\": \"@google/gemini-2.0-flash-lite\", \"temperature\": 1.25, \"topP\": null, \"presencePenalty\": null, \"stop\": null, \"maxCompletionTokens\": 4096, \"systemInstruction\": \"[...]\", \"userPromptTemplate\": null, \"assistantPrefill\": null, \"includePrefillingInMessages\": false, \"flags\": \"0\", \"tools\": null } } } Excluir um gateway de IA Permanentemente remove um gateway de IA. Warning Ao remover um gateway de IA, todos os chat clients associados também são removidos. Coleções não são removidas. Requisição DELETE /api/v1/ai-gateways/{ai-gateway-id} Resposta { \"message\": \"AI gateway deleted.\", \"data\": null } Endpoint OpenAI A Open Indexer provê um endpoint compatível com a interface OpenAI através de um AI-gateway, o que facilita a integração do modelo criado pela Open Indexer com aplicações existentes. Vale ressaltar que somente algumas propriedades são suportadas. Em um gateway de IA, você já configura os parâmetros do modelo, como System Prompt, temperatura e nome do modelo. Ao usar esse endpoint, alguns valores do gateway podem ser sobrescritos pela requisição. Requisição POST /api/v1/ai-gateways/{ai-gateway-id}/open-ai/v1/chat/completions { // O campo \"model\" é obrigatório, mas não faz nada nessa requisição. Ele só existe para ser compatível com a API Open AI. Você pode deixar ele vazio ou escrever qualquer coisa no lugar, pois o modelo considerado é o definido no AI Gateway. \"model\": \"foobar\", // As mensagens devem seguir o formato da Open AI. Somente \"system\" e \"user\" são suportados como \"roles\" da conversa. \"messages\": [ { \"role\": \"system\", \"content\": \"You are a helpful assistant.\" }, { \"role\": \"user\", \"content\": \"Hello!\" } ], // Ambas propriedades são equivalentes e opcionais e vão substituir o campo maxCompletionTokens se forem enviadas na requisição. \"max_completion_tokens\": 1024, \"max_tokens\": 1024, // Opcional. Substitui o parâmetro do gateway. \"stop\": \"\\n\", // Opcional. Por padrão a resposta não é por streaming. \"stream\": true } Resposta para não-streaming { \"id\": \"019672f3-699c-7d45-8484-7a23f4cdc079\", \"object\": \"chat.completion\", \"created\": 1745685277, \"model\": \"gemini-2.0-flash-lite\", \"choices\": [ { \"index\": 0, \"message\": { \"role\": \"assistant\", \"content\": \"Hi there! How can I help you today?\\n\", \"refusal\": null, \"annotations\": [] }, \"logprobs\": null, \"finish_reason\": \"stop\" } ], \"usage\": { \"prompt_tokens\": 0, \"completion_tokens\": 0, \"total_tokens\": 0 }, \"service_tier\": \"default\" } Resposta para streaming data: {\"id\":\"019672f4-9a58-7932-82f0-022e457a2e63\",\"object\":\"chat.completion.chunk\",\"created\":1745685355,\"model\":\"gemini-2.0-flash-lite\",\"system_fingerprint\":\"fp_2i0nmn\",\"choices\":[{\"index\":0,\"finish_reason\":null,\"delta\":{\"role\":\"assistant\",\"content\":\"Hi\"}}]} data: {\"id\":\"019672f4-9ab9-73a2-bdb8-23c4481453a8\",\"object\":\"chat.completion.chunk\",\"created\":1745685355,\"model\":\"gemini-2.0-flash-lite\",\"system_fingerprint\":\"fp_ar1qol\",\"choices\":[{\"index\":0,\"finish_reason\":null,\"delta\":{\"content\":\" there! How can I help you today?\\n\"}}]} ... data: {\"id\":\"019672f4-9ac0-7ddf-a76a-e7f8043dd082\",\"object\":\"chat.completion.chunk\",\"created\":1745685355,\"model\":\"gemini-2.0-flash-lite\",\"system_fingerprint\":\"fp_3e84ge\",\"choices\":[{\"index\":0,\"finish_reason\":\"stop\",\"delta\":{}}]} ```'"
  },
  "docs/entities/chat-clients.html": {
    "href": "docs/entities/chat-clients.html",
    "title": "Chat Clients | Open Indexer",
    "keywords": "Chat Clients Um cliente de chat provê uma interface de usuário através de um AI Gateway que permite o usuário conversar com sua assistente. Um chat client é integrado à inferência do AI gateway e dá suporte para pensamento profundo, pesquisa e conversa por texto. Recursos multi-modais, como envio de imagens e áudio estão em desenvolvimento. Note A Open Indexer nunca armazena o conteúdo de um chat entre um cliente e o usuário. Você pode usar JavaScript para essa tarefa, mas sob sua responsabilidade de uso e armazenamento. Você pode personalizar a interface do seu chat client com CSS e JavaScript personalizado, além de poder escolher a linguagem dos recursos do chat. Criando um chat client Cria um novo chat client. POST /api/v1/web-chat-client/ { // Especifica o nome público do seu chat client \"name\": \"Minha assistente\", // Especifica o ID do gateway de IA que será usado pelo chat \"aiGatewayId\": \"01965b64-a8eb-716c-892d-880159a9f12d\", \"clientParameters\": { // Opcional. Especifica o código da linguagem que será usada no chat para maioria dos elementos, como mensagens de erro, botões, etc. // Valores: pt-BR, en \"languageCode\": \"pt-BR\" | \"en\", // Opcional. Especifica um código JavaScript para executar no chat. \"customScripts\": null, // Opcional. Especifica um código CSS para aplicar estilos customizados no chat. \"customStyles\": null, // Opcional. Especifica a cor de realce dos elementos do chat client. \"primaryColor\": \"#eabe44\", // Opcional. Especifica o título da página de chat. \"pageTitle\": \"Assistente\", // Opcional. Especifica o título ao entrar no chat pela primeira vez. \"helloLabel\": \"É ótimo ver você aqui.\", // Opcional. Especifica o sub-título ao entrar no chat pela primeira vez. \"helloSubLabel\": \"Sou a sua assistente.\", // Opcional. Especifica o placeholder do campo de enviar mensagem. \"textAreaPlaceholder\": \"Falar com a assistente\", // Opcional. Especifica uma imagem/logo para exibir no chat pela primeira vez. \"logoImageUrl\": null, // Opcional. Ativa recursos de depuração. \"debug\": true, // Opcional. Especifica quais origens devem ser permitidas para embutir o cliente de chat em um iframe. Se esse campo estiver vazio, qualquer origem será aceita. \"allowedFrameOrigins\": [\"https://my-domain.com.br\"], // Opcional. Especifica botões de sugestão de conversa ao iniciar uma nova sessão de chat. Você pode adicionar quantos botões quiser, mas o aconselhável é até 3 botões. \"suggestionButtons\": [ { // Título que será exibido no botão. \"label\": \"Como comprar um carro?\", // Prompt que será enviado para o modelo. \"prompt\": \"Onde e como posso comprar um carro na sua loja?\" }, ... ] }, \"limitingParameters\": { // Opcional. Especifica quantas mensagens o usuário pode enviar por hora no chat. Essa opção é rastreada pelo userTag da sessão. \"messagesPerHour\": 30, // Opcional. Especifica o máximo de tokens que uma mensagem do usuário pode conter. Esse campo só é válido quando usado em modelos integrados ao Open Indexer. \"userInputMaxTokens\": 1024, // Opcional. Especifica o limite de mensagens (para o usuário e IA) que uma sessão pode ter. \"maxMessages\": 300 } } Resposta { \"message\": null, \"data\": { \"id\": \"01965b65-e95e-7795-848c-ff0919ef1436\" } } Editando um chat client O corpo dessa requisição é exatamente igual ao de criar um chat client. PUT /api/v1/web-chat-client/{chat-client-id} Resposta { \"message\": \"Web client updated successfully.\", \"data\": null } Listando os chat clients Obtém uma lista dos chat clients criados. GET /api/v1/web-chat-client/ Resposta { \"message\": null, \"data\": [ { \"id\": \"01965b59-daf6-7809-94c8-2a65b7264dba\", \"name\": \"Meu chat client\" }, ... ] } Vendo um chat client específico Obtém detalhes de um chat client existente. GET /api/v1/web-chat-client/{chat-client-id} Resposta { \"message\": null, \"data\": { \"name\": \"Meu chat client\", \"aiGateway\": { \"id\": \"01965b59-49ff-7753-8327-b3b6a6a871f2\", \"name\": \"gateway-t1\", \"knowledgeCollection\": { \"id\": \"01965b54-7fbd-70cd-982b-604de002ac0a\", \"name\": \"Informações sobre carros\" } }, \"limitingParameters\": { \"messagesPerHour\": 30, \"userInputMaxTokens\": 1024, \"maxMessages\": 500 }, \"clientParameters\": { \"languageCode\": \"pt-BR\", \"customScripts\": null, \"customStyles\": null, \"primaryColor\": \"#f011d2\", \"pageTitle\": \"Lyra\", \"helloLabel\": \"É ótimo ver você aqui.\", \"helloSubLabel\": \"Sou sua assistente.\", \"textAreaPlaceholder\": \"Falar com a assistente\", \"logoImageUrl\": null, \"debug\": true, \"allowedFrameOrigins\": [] } } } Criar uma sessão de chat Uma sessão de chat é onde você cria uma conversa entre seu chat client e o usuário. Você pode chamar esse endpoint informando contexto adicional para conversa, como o nome do usuário, onde ele está, etc. Uma sessão de chat expira após algum tempo por segurança do token de acesso gerado. Quando você chama esse endpoint informando uma tag você pode chamar o mesmo endpoint várias vezes e obter a sessão de chat que está ativa para a tag informada, ou criar um chat novo se não existir uma sessão em andamento. Uma sessão de chat também restaura todas as mensagens da conversa da mesma sessão após desconexão. O usuário pode limpar a conversa ao clicar no botão de limpar conversa no canto superior direito do cliente de chat. Essa sessão usa os limites definidos pelo cliente de chat, como máximo de mensagens e tokens na conversa. Uma sessão é automaticamente renovada por mais 3 dias ao receber uma mensagem do usuário. Important Só é possível determinar a quantidade de tokens usados em uma mensagem ao usar um modelo provido pela Open Indexer. Se você usar um modelo externo, a propriedade limitingParameters.userInputMaxTokens será ignorada. POST /api/v1/web-chat-client/{chat-client-id}/sessions { // Opcional. Contexto adicional para a IA sobre o chat. \"extraContext\": \"# Contexto adicional\\r\\n\\r\\nVocê está falando com Eduardo.\", // Tempo em segundos para o chat expirar. O mínimo é 10 minutos. O máximo é 30 dias. \"expires\": 3600, // Opcional (recomendado). Um id externo para identificar a sessão posteriormente e reaproveitá-la sempre que chamar o mesmo endpoint. Pode ser o ID do usuário do seu banco de dados ou uma string que facilite a identificação desse chat posteriormente. \"tag\": \"my-user-tag\" } Resposta { \"message\": null, \"data\": { // ID da sessão de chat criada. \"sessionId\": \"01966f0b-172d-7bbc-9393-4273b86667d2\", // Chave pública de acesso do chat. \"accessKey\": \"wky_gr5uepjsgrhuqcj3aaat1iagrsmozwr9gghusnnu6zjhrsyures5xoe\", // A URL pública para conversar com o chat. \"talkUrl\": \"https://preview-s01.proj.pw/www/web-chat-clients/wky_gr5uepjsgrhuqcj3aaat1iagrsmozwr9gghusnnu6zjhrsyures5xoe\" } }"
  },
  "docs/entities/collections.html": {
    "href": "docs/entities/collections.html",
    "title": "Coleções | Open Indexer",
    "keywords": "Coleções Uma coleção é uma biblioteca de conhecimento: ela abriga vários documentos de conhecimento. Use coleções para agrupar documentos por finalidade, como documentar um produto, uma empresa, um serviço ou fluxo. Coleções não produzem custo. Não há limite de coleções por conta. Criar uma coleção Para criar uma coleção vazia, informe apenas o nome dela: Requisição POST /api/v1/collections { // O nome da coleção não pode ser vazio. \"collectionName\": \"Minha primeira coleção\" } Resposta { \"message\": null, \"data\": { // ID único da coleção criada. \"collectionId\": \"01965b62-17c4-7258-9aa8-af5139799527\", // Uma chave privada usada para realizar consulta semântica na coleção. \"queryKey\": \"cky_gr5uepj18yhuop3zcsa4c7b8stdmpgg7kk4jaf4iug6x3hg7umyhk3o\" } } Listar coleções Lista as coleções disponíveis na sua conta. Requisição GET /api/v1/collections Resposta { \"message\": null, \"data\": { \"pageInfo\": { \"currentPage\": 1, \"hasMoreItems\": true }, \"items\": [ { \"id\": \"01965b62-17c4-7258-9aa8-af5139799527\", \"createdAt\": \"2025-04-22T02:44:37\", \"name\": \"Minha coleção\" }, { \"id\": \"01965b54-7fbd-70cd-982b-604de002ac0a\", \"createdAt\": \"2025-04-22T02:29:46\", \"name\": \"Outra coleção\" } ] } } Ver uma coleção Obtém detalhes de uma coleção, como seu progresso de indexação e informações como data de criação. Requisição GET /api/v1/collections/{collection-id}/ Resposta { \"message\": null, \"data\": { \"name\": \"Minha coleção\", \"createdAt\": \"2025-04-22T02:29:46\", \"queryKey\": \"cky_gr5uepj18yhd1qbshep7bki5e83hftbp6hbep97r8di9n4tta9ykswo\", \"state\": { // traz a quantidade de documentos aguardando indexação \"queuedDocuments\": 0, // quantidade de documentos pronto para consulta \"indexedDocuments\": 227 } } } Excluir uma coleção Exclui uma coleção e todos os documentos nela. Essa ação é irreversível. Requisição DELETE /api/v1/collections/{collection-id}/ Resposta { \"message\": \"Collection deleted successfully.\", \"data\": null } Limpar uma coleção Diferente da exclusão de coleção, essa operação remove todos os documentos da coleção, incluindo os indexados e os em fila. Requisição DELETE /api/v1/collections/{collection-id}/reset-only Resposta { \"message\": \"Collection cleaned successfully.\", \"data\": null }"
  },
  "docs/entities/documents.html": {
    "href": "docs/entities/documents.html",
    "title": "Documentos | Open Indexer",
    "keywords": "Documentos Um documento representa um pedaço de um conhecimento. É um trecho limitado, autosuficiente e que faça sentido de forma isolada. Um documento é o componente que é indexado pelo modelo interno para ser recuperado posteriormente através de um termo de busca semântico. Considere um manual sobre um carro: ele não é um documento mas sim vários documentos. Cada um destes documentos fala, de forma isolada, sobre um determinado assunto sobre esse carro, de forma que esse documento não dependa de um contexto ou informação externa para fazer sentido. Cada documento deste manual irá falar de um assunto: um irá falar sobre como ligar o carro, outro de como desligá-lo, outro de como sua pintura é feita e outro de como trocar o óleo periodicamente. Não é uma boa ideia reservar um documento para falar de várias coisas ao mesmo tempo, pois isso irá reduzir a objetividade e escopo da inferência e reduzir a qualidade de obtenção. Exemplos de criação de documentos: ❌ Não faça Não crie documentos muito curtos (com 10 ou menos palavras). Não crie documentos muito grandes (com 700) ou mais palavras. Não fale sobre mais de uma coisa em um documento. Não misture linguas diferentes em documentos. Não seja implícito em documentos. Nâo escreva documentos usando linguagem técnica, como códigos ou estruturas como JSON. ✅ Faça Seja explícito sobre o objetivo do seu documento. Foque documentos em assuntos individuais, que resumam o que deve ser feito ou explicado. Sempre repita termos que são palavras-chave para a busca do documento. Exemplo: prefira usar \"A cor do Honda Civic 2015 é amarela\" ao invés de \"a cor do carro é amarelo\". Restrinja o conteúdo do documento para falar de apenas um tópico ou assunto. Use uma linguagem humana, simples e fácil de entender. Uso da API Como todos os documentos são entidades que pertencem à uma coleção, sempre tenha em mãos a coleção de onde o documento está/será localizado. Enviar documentos em lote Para enviar uma lista em massa de documentos para uma coleção, estruture-os seguindo o formato JSONL. A estrutura do arquivo de indexação é: {\"docid\":\"Carros/HondaCivic2015.rmd:1\",\"text\":\"O Honda Civic 2015 está disponível em [...]\",\"__ref\":null,\"__tags\":[\"Carros\",\"Honda-Civic-2015\"]} {\"docid\":\"Carros/HondaCivic2015.rmd:2\",\"text\":\"O motor do Honda Civic 2015 é [...]\",\"__ref\":null,\"__tags\":[\"Carros\",\"Honda-Civic-2015\"]} {\"docid\":\"Carros/HondaCivic2015.rmd:3\",\"text\":\"A cor do Honda Civic 2015 é Amarela [...]\",\"__ref\":null,\"__tags\":[\"Carros\",\"Honda-Civic-2015\"]} ... A estrutura é compsta pelas propriedades: Propriedade Tipo Descrição docid string Especifica o nome do documento. Útil para depuração e identificação. text string O conteúdo \"cru\" do documento que será indexado. __ref string Opcional. Especifica um ID de referência do documento. __tags string[] Opcional. Especifica um array de tags do documento. Útil para gestão de documentos. A referência de um documento é um ID que pode ser especificado em vários documentos que precisam estar vinculados em uma busca quando um dos mesmos for correspondido em uma busca de similaridade. Por exemplo, se uma busca encontrar um documento que possui um ID de referência, todos os outros documentos da mesma coleção que compartilham o mesmo ID de referência do documento correspondido também serão incluídos na resposta da busca. O uso de referências pode ser útil para quando um documento depende de outro ou mais documentos para fazer sentido. Não há exigência de formato para o ID de referência: qualquer formato é aceito. Você pode enviar até 1.000 linhas de documentos por requisição. Se precisar enviar mais documentos, separe o envio em mais requisições. Se você enviar um documento com mais de 1.000 linhas, as linhas seguintes serão ignoradas. Vale notar que documentos muito longos, que excede a quantidade de tokens permitida no modelo de embedding interno, terão seu conteúdo truncado e a qualidade de indexação poderá ser gravemente afetada. Para evitar esse problema, envie documentos que contenham entre 20 e 700 palavras. Warning Atenção: esse endpoint gera custo. O custo é calculado em cima dos tokens do conteúdo de cada documento. O conteúdo de cada documento é tokenizado de acordo com o modelo usado na indexação dos documentos. Requisição O envio deve ser feito usando multipart form data. POST /api/v1/collections/{collection-id}/documents documents=[documents.jsonl] Resposta { \"message\": null, \"data\": [ { \"name\": \"Institucional/Empresa.rmd:1\", \"documentId\": \"01965f93-a36b-7fc2-9e6a-c733f4955927\" }, { \"name\": \"Institucional/Empresa.rmd:2\", \"documentId\": \"01965f93-a390-79d3-9b3d-338d407f6b64\" }, { \"name\": \"Institucional/Empresa.rmd:3\", \"documentId\": \"01965f93-a391-79ef-adcf-737d98303a78\" }, { \"name\": \"Produtos/Agendamentos.rmd:1\", \"documentId\": \"01965f93-a391-712e-9292-c4d8e010bf42\" }, ... ] } Criar ou modificar documento Esse endpoint cria ou modifica um documento a partir do seu nome. Quando um documento é modificado, seus vetores de indexação são resetados, isto é, o documento entrará em fila novamente para ser indexado pelo motor de indexação. Essa indexação não é isenta de custo. O custo é relativo à quantidade de tokens do conteúdo enviado. Warning Atenção: esse endpoint gera custo. O custo é calculado em cima dos tokens do conteúdo do arquivo. O conteúdo do arquivo é tokenizado de acordo com o modelo usado na indexação dos documentos. Requisição PUT /api/v1/collections/{collection-id}/documents { // o nome do documento que será modificado \"name\": \"document-name\", // o conteúdo do documento que será criado ou sobreposto caso o nome já exista \"contents\": \"Conteúdo do meu documento\", // parâmetros explicados anteriormente \"reference\": null, \"tags\": [\"products\", \"my-product\"] } Resposta { \"message\": null, \"data\": { \"documentId\": \"0196663c-3a15-72c7-98e6-b496f8e8bb8c\", // o estado da operação indica se o documento foi modificado \"Modified\" ou criado \"Created\". \"state\": \"Modified\" } } Listar documentos Esse endpoint lista todos os documentos disponíveis em uma coleção. Requisição GET /api/v1/collections/{collection-id}/documents Resposta { \"message\": null, \"data\": { \"pageInfo\": { \"currentPage\": 1, \"hasMoreItems\": true }, \"items\": [ { \"id\": \"01965b54-b31c-7184-9f5c-60b2648106d9\", \"name\": \"Institucional/Empresa.rmd:1\", \"reference\": null, \"tags\": [] }, { \"id\": \"01965b54-b32b-7433-b90b-73d71d21ae38\", \"name\": \"Institucional/Empresa.rmd:2\", \"reference\": null, \"tags\": [] }, { \"id\": \"01965b54-b32b-79bb-ac5e-729dfec701a8\", \"name\": \"Produtos/Agendamentos.rmd:1\", \"reference\": null, \"tags\": [] }, ... ] } } Ver documento Vê detalhes sobre um documento específico. Requisição GET /api/v1/collections/{collection-id}/documents/{document-id} Resposta { \"message\": null, \"data\": { \"id\": \"01965f93-a36b-7fc2-9e6a-c733f4955927\", \"name\": \"Institucional/Empresa.rmd:1\", // representa a situação de indexação do documento. // valores válidos: Queud, Indexed, Cancelled \"state\": \"Indexed\", // conteúdo do documento indexado \"contents\": \"...\", // id da referência do documento \"reference\": \"institucional-empresa\", // traz todos os documentos que compartilham a mesma referência \"references\": [ { \"id\": \"01965b54-b32b-7433-b90b-73d71d21ae38\", \"name\": \"Institucional/Empresa.rmd:2\" }, { \"id\": \"01965b54-b31c-7184-9f5c-60b2648106d9\", \"name\": \"Institucional/Empresa.rmd:3\" } ] } } Excluir documento Permanentemente exclui um documento através do seu ID. Requisição DELETE /api/v1/collections/{collection-id}/documents/{document-id} Resposta { \"message\": \"Document removed.\", \"data\": null }"
  },
  "docs/entities/functions.html": {
    "href": "docs/entities/functions.html",
    "title": "Funções | Open Indexer",
    "keywords": "Funções Funções é uma forma de forçar seu modelo à processamento de informações usando JSON como intermédio de comunicação. Com as funções, você consegue fazer qualquer modelo responder no formato JSON que você quiser. Pode ser útil para categorizar comentários, aplicar moderação em avaliações ou processar informações com auxílio da IA. No momento, só é possível usar funções com modelos providos pela Open Indexer. Chamar uma função Para chamar uma função de IA, você precisará informar o que a IA deverá responder e fornecer um esquema JSON que ela deverá seguir. Modelos menos inteligentes tendem a falhar a geração de JSON, gerando um documento inválido ou problemático. Para isso, ajuste seu modelo, a instrução e o parâmetro de tentativas se for necessário. Você é cobrado por cada tentativa que a IA tentar gerar. Modelos um pouco mais inteligentes tendem a gerar resultados corretos na primeira tentativa. É garantido que um JSON válido será gerado, mas não é garantido que o modelo seguirá os nomes e tipos fornecidos pelo seu esquema JSON. Requisição POST /api/v1/functions/json { // Especifique o nome do modelo integrado que será usado para realizar a ação. \"modelName\": \"@metaai/llama-3.1-8b\", // Explique o que seu modelo deverá fazer com a entrada e como ele deve trazer a resposta. \"instructions\": \"Classifique o comentário do usuário, indicando se é positivo ou negativo, e se possui alguma informação relevante (número entre 0 (pouco relevante) e 10 (muito relevante))\", // O objeto JSON que o modelo deverá gerar. Você pode fornecer exemplos de geração no campo de instruções. Esse objeto deve ser um JSON válido na API. // Esse objeto deve ser um objeto, um array ou uma string. \"responseSchema\": { \"feedbackType\": \"neutral | positive | negative\", \"informationScore\": 5 }, // Opcional. Define uma entrada JSON para o modelo. Pode ser qualquer tipo de valor JSON. \"inputData\": { \"userComment\": \"Pessimo mercado. Tem guarda dentro te vigiando pra vc nao roubar e os acougueiros te ignoram e atendem mocinhas bonitinhas na tua frente. Mas graças a Deus tem outros mercados chegando e o fim dessa palhaçada vai chegar\" }, // Opcional. Define quantas tentativas o modelo deve tentar antes da API retornar um erro. Deve ser um número entre 1 e 30. \"maxAttempts\": 10, // Opcional. Define o tempo limite em segundos para obter um JSON válido antes da API retornar um erro. Deve ser um número entre 1 e 3600 (uma hora). \"timeout\": 300 } Resposta { \"message\": null, \"data\": { // o resultado contém o objeto definido em \"responseSchema\", com os campos preenchidos pela IA \"result\": { \"feedbackType\": \"negative\", \"informationScore\": 8 }, // em qual tentativa a IA conseguiu um JSON válido \"attempt\": 1, // o tempo em milissegundos para obter um JSON válido \"elapsedMilliseconds\": 527 } } Exemplos Confira exemplos de funções de IA para várias tarefas cotidianas: Resumir pedido e classificar se requer atenção ou não POST /api/v1/functions/json { \"modelName\": \"@metaai/llama-4-scout-17b\", \"instructions\": \"Resuma o comentário do usuário, criando uma descrição curta, com no máximo de 10 palavras indicando o que ele quer fazer. Indique também se esse comentário requer atenção ou não.\", \"responseSchema\": { \"shortSummary\": \"...\", \"requiresAttention\": false }, \"inputData\": \"O cliente fernando de castro está tentando entrar em contato com o suporte desde sexta-feira e diz q vai cancelar se nao falar com alguém hoje. ele tbm disse que é amigo da rebeca do comercial e está ameaçando falar mal da empresa no tiktok. por favor alguém atende esse cara??\" } { \"message\": null, \"data\": { \"result\": { \"shortSummary\": \"Cliente quer contato com suporte para evitar cancelamento e ameaça\", \"requiresAttention\": true }, \"attempt\": 1, \"elapsedMilliseconds\": 639 } }"
  },
  "docs/entities/search.html": {
    "href": "docs/entities/search.html",
    "title": "Pesquisa | Open Indexer",
    "keywords": "Pesquisa A API de pesquisa, através da query key obtida das coleções, realiza uma busca semântica na mesma, realizando uma comparação inteligente para cada documento indexado em uma coleção. Após criar uma coleção, você obterá uma query key, o que usará para realizar a busca semântica em sua coleção. As rotas de pesquisa não precisam serem identificadas por um cabeçalho Authorization. Use os endpoints dessa API para embutir a pesquisa semântica de documentos no seu modelo de IA ou chatbot. Pesquisando documentos Esse endpoint espera uma requisição GET com os parâmetros: key: obrigatório. Especifica a Query Key da coleção que será consultada. term: obrigatório. Especifica o termo de pesquisa que será pesquisado nos documentos. top: Especifica o máximo de documentos que deverão ser retornados na busca. min: Especifica o score mínimo para obtenção dos documentos. Warning Atenção: esse endpoint gera custo. O custo é calculado em cima dos tokens do termo de busca. O termo de busca é tokenizado de acordo com o modelo usado na indexação dos documentos. Requisição GET /api/v1/search key=cky_gr5uepj18yhd1qbshep7&term=Qual a cor do honda CIVIC? Resposta { \"message\": null, \"data\": [ { \"documentId\": \"01965f93-a391-71a8-968a-47ccd4949de0\", \"documentName\": \"Produtos/Honda Civic 2015.rmd:1\", \"documentContent\": \"[...]\", \"score\": 0.7972834229469299, \"referencedDocuments\": [] }, { \"documentId\": \"01965f93-a391-76b3-bbf5-3fb74d10d412\", \"documentName\": \"Produtos/Honda Civic 2015.rmd:2\", \"documentContent\": \"[...]\", \"score\": 0.5693517327308655, \"referencedDocuments\": [] }, { \"documentId\": \"01965f93-a391-7026-b7aa-1cc6c63cd7d1\", \"documentName\": \"Produtos/Honda Civic 2015.rmd:5\", \"documentContent\": \"[...]\", \"score\": 0.5475733876228333, \"referencedDocuments\": [] }, ... ] } Para o resultado da busca, quanto maior o score, mais semelhante é o documento para o termo da busca. O Open Indexer utiliza modelos de embedding que permitem a orientação da tarefa. Para a busca, o termo é vetorizado com uma orientação DOCUMENT_QUERY. Para indexação dos documentos, a orientação é DOCUMENT_RETRIEVAL, o que fornece uma busca mais otimizada e não para averiguar a similaridade entre documentos."
  },
  "docs/getting-started.html": {
    "href": "docs/getting-started.html",
    "title": "Bem-vindo | Open Indexer",
    "keywords": "Bem-vindo Boas vindas ao Open Indexer. Nosso serviço torna mais fácil o desenvolvimento de modelos de IA inteligentes que usam uma base de conhecimento providenciada por você para conversar com o usuário, responder perguntas, fornecer informações em tempo real e mais. Para começar, todos os endpoints devem ser feitos na URL de produção do Open Indexer: https://open-indexer-api.proj.pw/ Conceitos e definições Entenda os conceitos usados pela API abaixo: Conta: representa uma conta do usuário, que possui um token de autenticação. Coleção: representa uma coleção de documentos de conhecimento. Um usuário pode ter várias coleções de documentos. Documento: representa um fato, um único conhecimento e um item de uma coleção. Uma coleção pode ter vários documentos. AI Gateway: representa um gateway de IA que se beneficia ou não de uma coleção de conhecimento, como um middleware de conhecimento plug-and-play para um modelo. Modelo embutido: representa um modelo de IA que o Open Indexer provê para o usuário. Chat client: representa uma interface de usuário que disponibiliza o AI gateway através de um chat interagível online. Sessão de chat: abriga uma conversa e contexto de um cliente de chat. Lidando com erros Todos os erros da API retornam uma resposta HTTP com um status não OK (nunca 2xx ou 3xx), e sempre seguindo o formato JSON: { \"error\": \"Uma mensagem explicando o erro\", \"data\": {} // um objeto contendo informações relevantes sobre o erro. Na maioria das vezes é nulo }"
  },
  "docs/models.html": {
    "href": "docs/models.html",
    "title": "Modelos | Open Indexer",
    "keywords": "Modelos O Open Indexer provê modelos de diferentes provedores para tornar o desenvolvimento ainda mais rápido, dispensando a necessidade de ter que configurar uma conta para cada provedor para ter acessos aos seus modelos mais recentes. Veja a lista abaixo dos modelos disponíveis e suas precificações. Todos os preços consideram o total de entrada e saída de tokens, com ou sem cache. Todos os preços estão em dólares dos Estados Unidos. DeepSeek Nome do modelo Preço/1m tokens Descrição @deepseekai/r1-distill-llama-70b $ 2,76 Modelo com raciocínio e pensamento profundo, melhor para tarefas mais exigentes. Pensamento Chamadas de função Google Nome do modelo Preço/1m tokens Descrição @google/gemini-2.5-pro $ 12,25 Um dos modelos mais poderosos da atualidade. Pensamento Entrada: aceita imagens, vídeos e áudios Chamadas de função @google/gemini-2.5-flash-think $ 4,65 Modelo da geração mais recente com raciocínio e pensamento integrado. Pensamento Entrada: aceita imagens, vídeos e áudios Chamadas de função @google/gemini-2.5-flash $ 1,31 Modelo da geração mais recente, sem pensamento profundo. Entrada: aceita imagens, vídeos e áudios Chamadas de função @google/gemini-2.0-flash $ 0,88 Oferece recursos da nova geração, com velocidade melhorada e geração multi-modal. Entrada: aceita imagens, vídeos e áudios Chamadas de função @google/gemma2-9b $ 0,70 Modelo rápido, estudo de código aberto da Google para realizar a maioria das tarefas. Chamadas de função @google/gemini-2.0-flash-lite $ 0,67 Modelo de uso geral, com reconhecimento de imagens, esperto e rápido. Ótimo para um chat econômico. Entrada: aceita imagens, vídeos e áudios Chamadas de função @google/gemini-1.5-flash-8b $ 0,33 Modelo de uso geral da geração anterior, otimizado para tarefas menos exigentes e simples. Entrada: aceita imagens, vídeos e áudios Chamadas de função OpenAI Nome do modelo Preço/1m tokens Descrição @openai/gpt-4o $ 13,50 Versátil, altamente inteligente e top de linha. Um dos modelos mais capazes atualmente. Entrada: aceita imagens Chamadas de função @openai/gpt-4.1 $ 11,00 Versátil, altamente inteligente e top de linha. Um dos modelos mais capazes atualmente. Entrada: aceita imagens Chamadas de função @openai/o1-mini $ 6,50 Um pequeno e esperto modelo com raciocínio. Pensamento @openai/gpt-4o-mini $ 1,31 Rápido e barato para tarefas focadas. Entrada: aceita imagens Chamadas de função @openai/gpt-4.1-nano $ 0,88 O mais rápido e barato modelo do GPT 4.1. Entrada: aceita imagens Chamadas de função Meta AI Nome do modelo Preço/1m tokens Descrição @metaai/llama-3.3-70b $ 2,40 Modelo de geração anterior com bastantes parâmetros e velocidade surpreendentemente rápida. Chamadas de função @metaai/llama-4-maverick-17b $ 1,40 Modelo rápido, com 17 bilhões de parâmetros ativados e 128 especialistas. Entrada: aceita imagens Chamadas de função @metaai/llama-4-scout-17b $ 0,79 Menor versão da família Llama 4 com 17 bilhões de parâmetros ativados e 16 especialistas. Entrada: aceita imagens Chamadas de função @metaai/llama-3.1-8b $ 0,23 Modelo barato e rápido para tarefas menos exigentes. Chamadas de função Groq Nome do modelo Preço/1m tokens Descrição @groq/compound-beta $ 3,25 Agente de conversação que pesquisa na internet para contextualização e informação em tempo real. Live data Entrada: aceita imagens Chamadas de função @groq/compound-beta-mini $ 2,60 Versão menor da família Compound, que possui menos especialistas. Live data Entrada: aceita imagens Chamadas de função Qwen Nome do modelo Preço/1m tokens Descrição @qwen/qwq-32b $ 1,23 Modelo de conversação com pensamento e raciocínio para resolução de tarefas complexas. Pensamento Chamadas de função"
  },
  "index.html": {
    "href": "index.html",
    "title": "Bem-vindo! | Open Indexer",
    "keywords": "Bem-vindo! Bem-vindo à documentação do Open Indexer."
  },
  "readme.html": {
    "href": "readme.html",
    "title": "Sisk Documentation | Open Indexer",
    "keywords": "Sisk Documentation This repository contains the source code of the Sisk Documentation website. Building Firstly, make sure you have docfx installed in your machine. You'll need .NET SDK to install it. Clone this repository. Build the Sisk Framework project and put the .DLL binaries and XML documentation file at the ref/ directory, on the repository root. Run docfx, then docfx serve. Warning Please, do not use the docfx version 2.78.0 or later. This version has a bug that changes the documentation navigation layout. See the tracking issue. Prefer the version 2.76.0: dotnet tool install -g docfx --version 2.76.0 Then you're ready to go and you'll have the static website files at /_site. Contributing Contributions are always welcome. Contribute with spelling corrections, fixing broken links and more. Please, only edit english documentation files. Documentation files for another languages are AI-generated from english files through. Note Please do not edit API specification files (XML). These files are generated. If you want to edit any API documentation, edit it in the repository where the code is hosted."
  }
}