{
  "docs/authentication.html": {
    "href": "docs/authentication.html",
    "title": "Autenticação | AIVAX",
    "keywords": "Autenticação Quando tiver sua conta em mãos, use sua chave de autenticação única para se autenticar na nossa API através do cabeçalho Authorization: curl https://inference.aivax.net/api/v1/information/models.txt \\ -H 'Authorization: Bearer oky_gr5uepj...' Você também pode enviar o seu token de autorização pelo parâmetro da query ?api-key, exemplo: curl https://inference.aivax.net/api/v1/information/models.txt?api-key=oky_gr5uepj... Não há necessidade de enviar o esquema de autenticação Bearer em ambos cabeçalhos, mas é possível por questões de compatibilidade. Autenticando hooks Requisições da AIVAX para seus serviços, seja workers de gateways de IA ou chamadas de função server-side, um cabeçalho X-Request-Nonce é encaminhado em todas as requisições conténdo um hash BCrypt sendo um salto da chave de hook definida em sua conta. A validação é simples: verifique se o hash em X-Request-Nonce é um produto da chave de salto definida em sua conta. Dessa forma, você poderá autenticar se as requisições da AIVAX para seus serviços são genuínas através desse token. Se sua conta não tiver definido uma chave de hook, esse cabeçalho não será enviado. Veja os exemplos abaixo para validação da chave de hook: C# (com Sisk) Python (com Flask) JavaScript (com Express.js) using BCrypt.Net; [RoutePrefix(\"/api/aivax-protocol-functions\")] internal class MyController : Controller { public MyController() { this.HasRequestHandler(RequestHandler.Create( execute: (req, ctx) => { // Obtém o nonce enviado da requisição var hash = this.Request.Headers [\"X-Request-Nonce\"]; if (hash == null) { return new HttpResponse(HttpStatusInformation.Unauthorized); } // Valida o hook usando a biblioteca BCrypt.Net var secretWord = Environment.GetEnvironmentVariable (\"AIVAX_HOOK_SECRET\"); if (!BCrypt.Net.BCrypt.Verify(secretWord, hash, enhancedEntropy: false)) { return new HttpResponse(HttpStatusInformation.Forbidden); } // Continua a requisição após hook validado return null; })); } ... } from flask import Flask, request, abort import os import bcrypt app = Flask(__name__) @app.before_request def autenticar_token(): # 1. Lê o cabeçalho que contém o hash do token token_hash = request.headers.get(\"X-Request-Nonce\") if not token_hash: abort(401) # 2. Carrega o segredo em texto puro das variáveis de ambiente secret = os.getenv(\"AIVAX_HOOK_SECRET\") if secret is None: abort(500) # 3. Verifica se o hash recebido corresponde ao segredo if not bcrypt.checkpw(secret.encode(\"utf-8\"), token_hash.encode(\"utf-8\")): abort(403) @app.route(\"/api/aivax-protocol-functions/some-action\", methods=[\"POST\"]) def some_action(): return \"\", 204 if __name__ == \"__main__\": app.run(host=\"0.0.0.0\", port=5000) require('dotenv').config() const express = require('express') const bcrypt = require('bcrypt') const app = express() app.use(async (req, res, next) => { const tokenHash = req.header('X-Request-Nonce') if (!tokenHash) { return res.sendStatus(401) } // 2. Carrega o segredo em texto puro das variáveis de ambiente const secret = process.env.AIVAX_HOOK_SECRET if (!secret) { return res.sendStatus(500) } try { // 3. Verifica se o hash recebido corresponde ao segredo const match = await bcrypt.compare(secret, tokenHash) if (!match) { return res.sendStatus(403) } next() } catch (err) { return res.sendStatus(500) } }) app.post( '/api/aivax-protocol-functions/some-action', (req, res) => { res.sendStatus(204) } ) const PORT = process.env.PORT || 3000 app.listen(PORT, () => { console.log(`Server running on port ${PORT}`) })"
  },
  "docs/builtin-tools.html": {
    "href": "docs/builtin-tools.html",
    "title": "Ferramentas embutidas | AIVAX",
    "keywords": "Ferramentas embutidas A AIVAX fornece uma lista de ferramentas embutidas para você habilitar em seu modelo. Essas ferramentas podem ser usadas em conjunto com as funções do lado do servidor. Algumas funções possuem custo. Esse custo é aplicado em modelos usados pela AIVAX e os que você fornece através do BYOK (bring-your-own-key), portanto, é importante adicionar saldo se você pretende usar essas ferramentas. Note que cada modelo decide qual função chamar e seus parâmetros. Nem todos os modelos podem obedecer as regras de chamadas. Pesquisa na internet Essa função habilita a pesquisa na internet no seu modelo. Com isso, o modelo pode consultar por informações específicas ou em tempo real, como dados meteorológicos, notícias, resultados de jogos, etc. A pesquisa na internet é feita por vários provedores, escolhido conforme disponibilidade de rede e latência. Os provedores atuais usados pela AIVAX é linkup e Exa. A AIVAX fornece dois tipos de pesquisa configuráveis pelo seu dashboard: Full: a pesquisa realizada é completa, inserindo no contexto da conversa o conteúdo inteiro de cada resultado encontrado. Summarized: a pesquisa realizada é resumida, inserindo no contexto da conversa um resumo feito por IA pelo próprio provedor de pesquisa. O custo dos dois modos é de $5 à cada 1.000 pesquisas realizadas. O modo Full pode consumir mais tokens de entrada da conversa, mas pode proporcionar resultados mais precisos. Execução de código Essa função permite que o modelo execute código JavaScript e inspecione o resultado da execução. Com isso, o modelo consegue avaliar através de algoritmos resultados de expressões matemáticas e outras situações que são melhores representadas através de código. O código é executado em um ambiente protegido com pouquíssimas funções disponíveis. O modelo não conseguirá acessar I/O, acesso à internet ou importar scripts por essa ferramenta. Essa função não tem custo. Contexto de URL Essa função permite que o modelo acesse conteúdo externo em URLs e links providos pelo usuário. Com essa função, o modelo consegue acessar links e avaliar seu conteúdo. Note que, alguns destinos podem identificar o acesso como bot e barrar o acesso, desde que essa função não é um crawling e sim um simples GET feito no destino. O modelo consegue acessar até 5 links de uma vez. Somente os primeiros 10MB dos links são lidos. Ao obter o conteúdo do link, o sistema verifica o conteúdo de retorno e lida com eles de acordo com cada tipo: Conteúdos de HTML são renderizados: as tags HTML, scripts, CSS e \"ruídos\" são removidos do resultado do acesso, mantendo somente o texto puro do link. Outros conteúdos textuais: o conteúdo é lido diretamente e nenhuma transformação é realizada. Conteúdos não textuais: quando o link responde com um conteúdo não textual e a resposta indica um nome de arquivo (seja pelo caminho ou pelo cabeçalho Content-Disposition), o sistema tenta converter o arquivo baixado para uma versão textual. Essa função não tem custo. Memória Essa função permite que o modelo armazene conteúdo relevante para ser usado por várias conversas. No momento, essa função só está disponível quando usada em chat clients e quando a sessão está identificada por uma tag. Através da tag da sessão, o modelo armazena um dado relevante da conversa, como preferência de nomes, lembretes ou ações que a assistente deve realizar. A instrução dessa memória instrui o modelo à não salvar dados sensíveis ou pessoais, no entanto, não é garantido que o modelo sempre irá seguir essa regra. Os dados são armazenados por um ano nos bancos de dados da AIVAX e podem ser excluídos à qualquer momento pela plataforma. Para toda conversa por um chat client, esses dados são obtidos e anexados na conversa. Essa função não tem custo. Geração de imagens Essa função permite que o modelo crie imagens de IA. As imagens geradas por IA são anexadas no contexto da conversa, mas não são visíveis diretamente para a assistente. Atualmente, existem quatro categorias de imagens geradas: Qualidade baixa: gera imagens rapidamente com um custo baixo, no entanto, pode gerar bastante artefato, como dedos à mais, olhos distorcidos, braços fora do lugar. Qualidade média: equilíbrio entre boa qualidade e velocidade, mas ainda pode gerar artefatos. Qualidade alta: maior qualidade nas imagens e menor chance de existir artefatos na imagem. Qualidade altíssima: a maior qualidade na geração de imagens. Após a geração, um modelo de upscaling realiza o reajuste na imagem criada. Essa função possui custo. O custo varia do tempo de processamento de cada imagem, o que é interferido com o consumo do processamento, tamanho da fila de processamento, modelos usados, etc. A geração de imagens ocorre em um provedor externo, o que o custo pode mudar conforme vários fatores. A imagem de exemplo acima mostra uma previsão do preço de cada qualidade de imagem. Você também pode ativar a geração de imagens explícitas e adultas na geração de imagem. Ao ativar esse recurso, o modelo será permitido gerar material adulto. Para isso ocorrer, o modelo também deve \"concordar\" em gerar esse conteúdo. Certos modelos possuem um filtro de segurança menor que outros. Por exemplo, os modelos Gemini são os com o menor filtro de segurança, sendo uma opção viável para role-play e geração desse tipo de material. Você é sempre responsável pelo material que gera e o material gerado deve ser compatível com nossos termos de serviço. Pesquisa de posts no X Essa função permite o modelo pesquisar por posts no X (antigo Twitter). É uma alternativa direta ao web_search, pois pode ser usada para procurar por informações atualizadas em tempo real, como notícias, informações, resultados de jogos, etc. Essa ferramenta traz resultados muito mais recentes que a ferramenta de pesquisa na internet convencional. Não é recomendado usar as duas funções em conjunto pois elas possuem o mesmo objetivo. No momento, os últimos 20 posts de um determinado assunto é inserido no contexto da conversa, contendo link e autor. No momento, não é possível acessar posts de perfis específicos. O custo dessa função é de $5 à cada 1.000 pesquisas realizadas."
  },
  "docs/en/authentication.html": {
    "href": "docs/en/authentication.html",
    "title": "Authentication | AIVAX",
    "keywords": "Authentication When you have your account ready, use your unique authentication key to authenticate to our API via the Authorization header: curl https://inference.aivax.net/api/v1/information/models.txt \\ -H 'Authorization: Bearer oky_gr5uepj...' You can also send your authorization token via the query parameter ?api-key, for example: curl https://inference.aivax.net/api/v1/information/models.txt?api-key=oky_gr5uepj... There is no need to send the Bearer authentication scheme in both headers, but it is possible for compatibility reasons. Authenticating hooks AIVAX requests to your services, whether AI gateway workers or server‑side function calls, include a X-Request-Nonce header in all requests containing a BCrypt hash that is a derived value of the hook key defined in your account. The validation is simple: check that the hash in X-Request-Nonce is a product of the hook key defined in your account. In this way, you can authenticate whether the AIVAX requests to your services are genuine using this token. If your account has not defined a hook key, this header will not be sent. See the examples below for validating the hook key: C# (with Sisk) Python (with Flask) JavaScript (with Express.js) using BCrypt.Net; [RoutePrefix(\"/api/aivax-protocol-functions\")] internal class MyController : Controller { public MyController() { this.HasRequestHandler(RequestHandler.Create( execute: (req, ctx) => { // Retrieves the nonce sent from the request var hash = this.Request.Headers[\"X-Request-Nonce\"]; if (hash == null) { return new HttpResponse(HttpStatusInformation.Unauthorized); } // Validates the hook using the BCrypt.Net library var secretWord = Environment.GetEnvironmentVariable(\"AIVAX_HOOK_SECRET\"); if (!BCrypt.Net.BCrypt.Verify(secretWord, hash, enhancedEntropy: false)) { return new HttpResponse(HttpStatusInformation.Forbidden); } // Continue the request after hook validated return null; })); } ... } from flask import Flask, request, abort import os import bcrypt app = Flask(__name__) @app.before_request def authenticate_token(): # 1. Read the header containing the token hash token_hash = request.headers.get(\"X-Request-Nonce\") if not token_hash: abort(401) # 2. Load the plain‑text secret from environment variables secret = os.getenv(\"AIVAX_HOOK_SECRET\") if secret is None: abort(500) # 3. Verify that the received hash matches the secret if not bcrypt.checkpw(secret.encode(\"utf-8\"), token_hash.encode(\"utf-8\")): abort(403) @app.route(\"/api/aivax-protocol-functions/some-action\", methods=[\"POST\"]) def some_action(): return \"\", 204 if __name__ == \"__main__\": app.run(host=\"0.0.0.0\", port=5000) require('dotenv').config() const express = require('express') const bcrypt = require('bcrypt') const app = express() app.use(async (req, res, next) => { const tokenHash = req.header('X-Request-Nonce') if (!tokenHash) { return res.sendStatus(401) } // 2. Load the plain‑text secret from environment variables const secret = process.env.AIVAX_HOOK_SECRET if (!secret) { return res.sendStatus(500) } try { // 3. Verify that the received hash matches the secret const match = await bcrypt.compare(secret, tokenHash) if (!match) { return res.sendStatus(403) } next() } catch (err) { return res.sendStatus(500) } }) app.post( '/api/aivax-protocol-functions/some-action', (req, res) => { res.sendStatus(204) } ) const PORT = process.env.PORT || 3000 app.listen(PORT, () => { console.log(`Server running on port ${PORT}`) })"
  },
  "docs/en/builtin-tools.html": {
    "href": "docs/en/builtin-tools.html",
    "title": "Built-in Tools | AIVAX",
    "keywords": "Built-in Tools AIVAX provides a list of built-in tools for you to enable in your model. These tools can be used in conjunction with server-side functions. Some functions have a cost. This cost is applied to models used by AIVAX and those you provide through BYOK (bring-your-own-key), so it's essential to add balance if you intend to use these tools. Note that each model decides which function to call and its parameters. Not all models can follow the calling rules. Internet Search This function enables internet search in your model. With this, the model can query specific information or real-time data, such as weather, news, game results, etc. The internet search is performed by multiple providers, chosen based on network availability and latency. The current providers used by AIVAX are linkup and Exa. AIVAX provides two types of configurable search through your dashboard: Full: the search performed is complete, inserting the entire content of each result found into the conversation context. Summarized: the search performed is summarized, inserting a summary made by AI by the search provider into the conversation context. The cost of both modes is $5 per 1,000 searches performed. The Full mode may consume more conversation input tokens, but it can provide more accurate results. Code Execution This function allows the model to execute JavaScript code and inspect the execution result. With this, the model can evaluate mathematical expression results and other situations that are better represented through code. The code is executed in a protected environment with very few available functions. The model will not be able to access I/O, internet access, or import scripts through this tool. This function has no cost. URL Context This function allows the model to access external content in URLs and links provided by the user. With this function, the model can access links and evaluate their content. Note that some destinations may identify access as a bot and block access, since this function is not a crawl but a simple GET request to the destination. The model can access up to 5 links at a time. Only the first 10MB of the links are read. When obtaining the link content, the system checks the return content and handles it according to each type: HTML content is rendered: HTML tags, scripts, CSS, and \"noise\" are removed from the access result, keeping only the pure text of the link. Other textual content: the content is read directly, and no transformation is performed. Non-textual content: when the link responds with non-textual content and the response indicates a file name (either by path or by the Content-Disposition header), the system attempts to convert the downloaded file to a textual version. This function has no cost. Memory This function allows the model to store relevant content for use in multiple conversations. Currently, this function is only available when used in chat clients and when the session is identified by a tag. Through the session tag, the model stores relevant conversation data, such as name preferences, reminders, or actions the assistant should perform. The instruction of this memory instructs the model not to save sensitive or personal data; however, it is not guaranteed that the model will always follow this rule. The data is stored for one year in AIVAX's databases and can be deleted at any time by the platform. For every conversation by a chat client, this data is obtained and attached to the conversation. This function has no cost. Image Generation This function allows the model to create AI-generated images. The AI-generated images are attached to the conversation context but are not directly visible to the assistant. Currently, there are four categories of generated images: Low quality: generates images quickly with a low cost, but may generate many artifacts, such as extra fingers, distorted eyes, or misplaced arms. Medium quality: balances good quality and speed, but may still generate artifacts. High quality: higher quality in images and lower chance of artifacts in the image. Very high quality: the highest quality in image generation. After generation, an upscaling model performs the adjustment on the created image. This function has a cost. The cost varies depending on the processing time of each image, which is affected by processing consumption, queue size, models used, etc. Image generation occurs on an external provider, so the cost may change according to various factors. The example image above shows a forecast of the price of each image quality. You can also activate the generation of explicit and adult images in image generation. When activating this feature, the model will be allowed to generate adult material. For this to happen, the model must also \"agree\" to generate this content. Certain models have a lower security filter than others. For example, Gemini models have the lowest security filter, making them a viable option for role-playing and generating this type of material. You are always responsible for the generated material, and the generated material must be compatible with our terms of service. Post Search on X This function allows the model to search for posts on X (formerly Twitter). It is a direct alternative to web_search, as it can be used to search for up-to-date information in real-time, such as news, information, game results, etc. This tool brings much more recent results than the conventional internet search tool. It is not recommended to use both functions together, as they have the same objective. Currently, the last 20 posts on a specific topic are inserted into the conversation context, containing a link and author. Currently, it is not possible to access posts from specific profiles. The cost of this function is $5 per 1,000 searches performed."
  },
  "docs/en/entities/ai-gateways/ai-gateway.html": {
    "href": "docs/en/entities/ai-gateways/ai-gateway.html",
    "title": "AI Gateway | AIVAX",
    "keywords": "AI Gateway AI gateways are a service that AIVAX provides to create an inference tunnel between an LLM model and a knowledge base. With it you can: Create a model with custom instructions Use a model provided by you through a compatible OpenAI endpoint, or use a model made available by AIVAX Customize inference parameters, such as temperature, top_p, prefill Use a knowledge collection as the foundation for AI responses Among other features. With the AI Gateway, you create a ready‑to‑use model, parametrized and grounded in the instructions you define. Models You can bring an AI model compatible with the OpenAI interface to the AI gateway. If you bring your own AI model, we will charge only for the document search attached to the AI. You can also use one of the models below that are already ready to start with AIVAX. When using a model, you will notice that some are smarter than others for certain tasks. Some models perform better with certain data‑retrieval strategies than others. Run tests to find the best model. You can see the available models on the models page. Using an AI gateway AIVAX provides an endpoint compatible with the OpenAI interface through an AI‑gateway, which makes it easy to integrate the model created by AIVAX with existing applications and SDKs. Note that only a subset of properties are supported. In an AI gateway, you already configure the model parameters, such as System Prompt, temperature, and model name. When using this endpoint, some gateway values can be overridden by the request. Request POST /api/v1/chat-completions { \"model\": \"0198683a-2b6d-7066-9598-6ea119c219f2\", \"messages\": [ { \"role\": \"user\", \"content\": \"Qual a capital da França?\" } ], \"stream\": false, \"metadata\": { \"foo\": \"bar\" } } Response for non‑streaming { \"id\": \"0198d24c-c9ce-70fe-9cf3-00644ef5f2e2\", \"object\": \"chat.completion\", \"created\": 1755874904, \"model\": \"@openai/gpt-5-mini\", \"choices\": [ { \"index\": 0, \"message\": { \"role\": \"assistant\", \"content\": \"A capital da França é Paris.\", \"refusal\": null, \"annotations\": [], \"tool_calls\": [] }, \"logprobs\": null, \"finish_reason\": \"stop\" } ], \"usage\": { \"prompt_tokens\": 84, \"completion_tokens\": 16, \"total_tokens\": 1892, \"prompt_tokens_details\": { \"cached_tokens\": 1792 } }, \"service_tier\": \"default\", \"generation_context\": { \"generated_usage\": [ { \"sku\": \"inference.resolving.routing_complexity.in\", \"amount\": 0.0000207, \"unit_price\": 7.5e-8, \"quantity\": 276, \"description\": \"Inference for model routing\" }, { \"sku\": \"inference.resolving.routing_complexity.out\", \"amount\": 3e-7, \"unit_price\": 3e-7, \"quantity\": 1, \"description\": \"Inference for model routing\" }, { \"sku\": \"inference.chat_completions.in\", \"amount\": 0.000021, \"unit_price\": 2.5e-7, \"quantity\": 84, \"description\": \"Inference for AI model '@openai/gpt-5-mini'\" }, { \"sku\": \"inference.chat_completions.out\", \"amount\": 0.000032, \"unit_price\": 0.000002, \"quantity\": 16, \"description\": \"Inference for AI model '@openai/gpt-5-mini'\" }, { \"sku\": \"inference.chat_completions.in.cached\", \"amount\": 0.0000448, \"unit_price\": 2.5e-8, \"quantity\": 1792, \"description\": \"Inference for AI model '@openai/gpt-5-mini'\" } ], \"runned_functions\": [] } } Streaming response data: {\"id\":\"chatcmpl-0198d263-fd80-7645-98b0-3966004e11df\",\"object\":\"chat.completion.chunk\",\"created\":1755876425,\"model\":\"@openai\\/gpt-5-mini\",\"system_fingerprint\":\"fp_2su4hm\",\"choices\":[{\"index\":0,\"finish_reason\":\"stop\",\"logprobs\":null,\"delta\":{\"role\":\"assistant\",\"content\":\"\"}}],\"usage\":null} ... data: {\"id\":\"chatcmpl-0198d263-ff5a-7f53-99e2-b59d5cdae470\",\"object\":\"chat.completion.chunk\",\"created\":1755876425,\"model\":\"@openai\\/gpt-5-mini\",\"system_fingerprint\":\"fp_7ibly5\",\"choices\":[{\"index\":0,\"finish_reason\":\"stop\",\"logprobs\":null,\"delta\":{\"content\":\"\"}}],\"usage\":null} data: {\"id\":\"chatcmpl-0198d263-ff80-7d8f-91e7-c61ac2a9e870\",\"object\":\"chat.completion.chunk\",\"created\":1755876425,\"model\":\"@openai\\/gpt-5-mini\",\"system_fingerprint\":\"fp_552km8\",\"choices\":[{\"index\":0,\"finish_reason\":\"stop\",\"logprobs\":null,\"delta\":{}}],\"usage\":{\"prompt_tokens\":1873,\"completion_tokens\":41,\"total_tokens\":1914}} data: [END] Usage with SDKs By providing endpoints compatible with the OpenAI interface, AIVAX is fully compatible with existing SDKs, making plug‑and‑play integration easy. See the example below: from openai import OpenAI client = OpenAI( base_url=\"https://inference.aivax.net/api/v1\", api_key=\"oky_gr5u...oqbfd3d9y\" ) response = client.chat.completions.create( model=\"my-gateway:50c3\", # you can also provide your ai-gateway full ID here messages=[ {\"role\": \"user\", \"content\": \"Explain why AI-gateways are useful.\"} ] ) print(response.choices[0].message.content) Currently, AIVAX only supports the chat/completions format. In the future, we plan to add support for the API Responses."
  },
  "docs/en/entities/ai-gateways/pipelines.html": {
    "href": "docs/en/entities/ai-gateways/pipelines.html",
    "title": "AI Pipelines | AIVAX",
    "keywords": "AI Pipelines AIVAX provides several pipelines to use in your AI gateway. You can use multiple pipelines to run in the context of your gateway. RAG Through collections, you can link a collection of documents to your AI gateway. You can set the embedding parameters, such as number of documents, minimum score, and embedding strategy. Each embedding strategy is more refined than the other. Some produce better results than others, but it is important to conduct practical tests with various strategies to understand which fits best with the model, conversation, and user tone. It may be necessary to adjust the system prompt to better inform how the AI should consider the attached documents in the conversation. The documents are attached as a user message, limited by the parameters you define in the retrieval strategy. Rewrite strategies usually generate the best results at low latency and cost. The rewrite model used is always the one with the lowest cost, usually chosen by an internal pool that decides which model has the lowest latency at the moment. Strategies without rewrite cost: Plain: the default strategy. It is the least optimized and has no rewrite cost: the last user message is used as the search term to query the gateway's attached collection. Concatenate: concatenates the last N user messages in lines, and then the result of the concatenation is used as the search term. Strategies with rewrite cost (inference tokens are charged): UserRewrite: rewrites the last N user messages using a smaller model, creating a contextual question about what the user wants to say. FullRewrite: rewrites the last N*2 chat messages using a smaller model. Similar to UserRewrite, but also considers the assistant's messages when formulating the new question. Usually creates the best questions, with a slightly higher cost. It is the most stable and consistent strategy. Works with any model. Function strategies: QueryFunction: provides a search function in the integrated collection for the AI model. You should adjust the system instructions with ideal scenarios for the model to call this function when necessary. May not work as well on smaller models. When defining a RAG collection in your gateway's pipeline, the first message in the conversation context will be the result of the RAG embedding as a user message (except when used as tools where the embedding result is attached as a tool response). Defining many RAG response documents increases input token consumption and may increase the final inference cost. Fixing instructions The instruction pipeline allows prefixing instructions in various places of the model, guiding and restricting the model's response format. The current ways to define instructions are: System instructions: inserts a fixed text into the system prompt of the context. User prompt template: reformats the user's question to follow a specific question format. Assistant initialization (prefill): initializes the assistant's message with initial generation tokens. These parameters can be very useful for prompt engineering, however, they may not be compatible with all models. Attention: prefixing instructions, templates, and initializations can remove the model's reasoning, multi‑modal interpretation, and tool‑calling capabilities. Parameterization The parameterization pipeline configures the initial inference hyperparameters, such as temperature, nucleus sampling, presence penalty, and other inference hyperparameters. Truncating The truncating pipeline allows setting the size of a conversation in tokens before it is trimmed. When this pipeline is enabled, before each inference, it calculates whether num_of_chars / 4 is greater than the maximum input tokens for the conversation. If the context is larger, the pipeline starts removing messages from the beginning of the conversation until the messages fit within the specified context. At least one user message (commonly the last message) is kept in the conversation. All other messages are removed, except system instructions. Alternatively, you can define that when the limit is reached, an error is thrown in the API instead of truncating the context. Tool message truncating The tool message counting pipeline is similar to truncating: it removes older tool responses and preserves only the newest. This can be useful when previous tool responses are no longer useful in newer messages and occupy space in the context, but can be detrimental when using agentic models that call tools in a chain. This pipeline is configured in the number of tool messages to be preserved instead of tokens. When a tool message is considered old, it is not removed, but its content is removed. Server‑side tools This pipeline allows execution of AIVAX server‑side tools, similar to the MCP protocol. Read more about this pipeline here. Built‑in tools You can add tools provided by AIVAX to your gateway, such as internet search, image generation, and link access. See all available tools here. Workers Workers define the behavior of your gateway remotely, used to control when certain events should be aborted or continued. Read more about this pipeline here."
  },
  "docs/en/entities/ai-gateways/workers.html": {
    "href": "docs/en/entities/ai-gateways/workers.html",
    "title": "AI Workers | AIVAX",
    "keywords": "AI Workers The AI gateway workers are resources of the AI Gateways that allow you to control the behavior of your resources remotely through events. With an external controller configured, events are sent to it, and the response from your controller determines whether that action should continue, be aborted, or be configured. When an event is triggered on the AIVAX side, a POST request is sent to the configured worker with information about the triggered event. Based on its response, the action can be cancelled or configured. There is no caching – the request is made for every event that occurs in your AI gateway. The processing time of the response adds latency to each gateway action, however, it adds a layer of control and moderation that you can manage at any time. Creating an AI Worker When an event is triggered, a POST request is sent to your worker following the format below: { \"gatewayId\": \"0197dda5-985f-7d76-96e5-0d0451c539f6\", \"moment\": \"2025-08-09T00:21:40\", \"event\": { \"name\": \"message.received\", \"data\": { \"message\": { \"role\": \"user\", \"content\": \"Bom dia!\" }, \"origin\": [ \"SessionsApi\" ], \"externalUserId\": \"mini-app-session@lot1xc9k03g2my3j4w2y1\" } } } The example above illustrates a message.received event message with its event arguments. After sending the request, AIVAX waits for the response from your worker, and with it: OK response (2xx): continues and proceeds with the normal execution of the event. Other responses: aborts and stops the execution of the event. List of events Currently, the events that can be sent to your worker are: message.received – sent when a message is received by the gateway. This event is triggered with the last message received in the context, which may be from the user or not. { \"name\": \"message.received\", \"data\": { \"message\": {}, // chat/completions message entity \"origin\": [ \"SessionsApi\" // message origin ], \"externalUserId\": \"mini-app-session@lot1xc9k03g2my3j4w2y1\" } } Example The example below illustrates a Cloudflare Worker that authenticates a Telegram conversation based on the username of the conversation: export default { async fetch(request, env, ctx) { // The ID of the gateway we are expecting to handle const CHECKING_GATEWAY_ID = \"0197dda5-985f-7c76-96e5-0d0451c596e5\"; const ALLOWED_USERNAMES = [ \"myusername\" ]; if (request.method == \"POST\") { const requestData = await request.json(); const { event, gatewayId } = requestData; // Checks if it is a message received event, if it is the gateway we are // managing in the worker, and if this message comes from a Telegram chat if (gatewayId === CHECKING_GATEWAY_ID && event.name == \"message.received\" && event.data.externalUserId?.startsWith(\"zp_telegram:\")) { // obtains the Telegram username, which is between the ':' and '@' of the externalUserId const telegramUsername = event.data.externalUserId.split(':')[0].split('@')[0]; // checks if the user is allowed in the integration if (!ALLOWED_USERNAMES.includes(telegramUsername)) { // the user does not exist in the list of allowed usernames, therefore returns a non-ok response // indicating that the message should not be sent return new Response(\"User is not authed\", { status: 400 }); } } } // continues execution return new Response(); } };"
  },
  "docs/en/entities/chat-clients.html": {
    "href": "docs/en/entities/chat-clients.html",
    "title": "Chat Clients | AIVAX",
    "keywords": "Chat Clients A chat client provides a user interface through an AI Gateway that allows the user to converse with their assistant. A chat client is integrated with the AI gateway inference and supports deep reasoning, research, and text conversation. Multi‑modal features, such as sending images and audio, are under development. You can customize the interface of your chat client with custom CSS and JavaScript, and you can also choose the language of the chat resources. Create a chat session A chat session is where you create a conversation between your chat client and the user. You can call this endpoint providing additional context for the conversation, such as the user’s name, location, etc. A chat session expires after some time for security of the generated access token. When you call this endpoint providing a tag you can call the same endpoint multiple times and obtain the chat session that is active for the given tag, or create a new chat if no session is in progress. When a session is found in the chat client through the provided tag, the session is renewed for the specified period and the context is updated. A chat session also restores all conversation messages from the same session after disconnection. The user can clear the conversation by clicking the clear‑conversation button in the upper‑right corner of the chat client. This session uses the limits defined by the chat client, such as maximum messages and tokens in the conversation. If a session is close to expiring, it is renewed for another 20 minutes on the next user message. POST /api/v1/web-chat-client/{chat-client-id}/sessions { // Time in seconds for the chat to expire. Minimum is 10 minutes. Maximum is 30 days. \"expires\": 3600, // Optional. Additional context for the AI about the chat. \"extraContext\": \"# Additional context\\r\\n\\r\\nYou are talking to Eduardo.\", // Optional. Provides an endpoint for the session to obtain additional context. This endpoint is called on every message sent by the user, updated in real time without any cache. \"contextLocation\": \"https://example.com/context.txt\", // Optional (recommended). An external id to identify the session later and reuse it whenever the same endpoint is called. It can be the user ID from your database or a string that makes it easier to identify this chat later. \"tag\": \"my-user-tag\", // Optional. Additional metadata to store in the client. Not visible to the assistant. \"metadata\": { \"foo\": \"bar\" } } Response { \"message\": null, \"data\": { // ID of the created chat session \"sessionId\": \"01966f0b-172d-7bbc-9393-4273b86667d2\", // Public access key for the chat \"accessKey\": \"wky_gr5uepjsgrhuqcj3aaat1iagrsmozwr9gghusnnu6zjhrsyures5xoe\", // Public URL to talk with the chat \"talkUrl\": \"https://console.aivax.net/chat/wky_gr5uepjsgrhuqcj3aaat1iagrsmozwr9gghusnnu6zjhrsyures5xoe\" } } Integration sessions AIVAX provides two integrations for chat clients: Telegram and WhatsApp (through Z-Api). Each conversation in an app is an individual session, identified by the conversation ID or the user’s phone number. These sessions obey the rules of the original chat client. In addition, chat sessions in these integrations have two special commands: /reset: clears the current session context. /usage: when debug is active in the chat client, displays the current chat usage in tokens."
  },
  "docs/en/entities/collections.html": {
    "href": "docs/en/entities/collections.html",
    "title": "Collections | AIVAX",
    "keywords": "Collections A collection is a knowledge library: it houses several knowledge documents. Use collections to group documents by purpose, such as documenting a product, a company, a service or flow. Collections do not incur costs. There is no limit to the number of collections per account. Create a collection To create an empty collection, simply provide its name: Request POST /api/v1/collections { // The collection name cannot be empty. \"collectionName\": \"My first collection\" } Response { \"message\": null, \"data\": { // Unique ID of the created collection. \"collectionId\": \"01965b62-17c4-7258-9aa8-af5139799527\" } } List collections Lists the collections available in your account. Request GET /api/v1/collections Response { \"message\": null, \"data\": { \"pageInfo\": { \"currentPage\": 1, \"hasMoreItems\": true }, \"items\": [ { \"id\": \"01965b62-17c4-7258-9aa8-af5139799527\", \"createdAt\": \"2025-04-22T02:44:37\", \"name\": \"My collection\" }, { \"id\": \"01965b54-7fbd-70cd-982b-604de002ac0a\", \"createdAt\": \"2025-04-22T02:29:46\", \"name\": \"Another collection\" } ] } } View a collection Obtains details of a collection, such as its indexing progress and information like creation date. Request GET /api/v1/collections/{collection-id}/ Response { \"message\": null, \"data\": { \"name\": \"My collection\", \"createdAt\": \"2025-04-22T02:29:46\", \"state\": { // Returns the number of documents waiting for indexing \"queuedDocuments\": 0, // Number of documents ready for query \"indexedDocuments\": 227 }, \"tags\": [ \"tag1\", \"tag2\", \"tag3\", ... ] } } Delete a collection Deletes a collection and all documents within it. This action is irreversible. Request DELETE /api/v1/collections/{collection-id}/ Response { \"message\": \"Collection deleted successfully.\", \"data\": null } Clear a collection Unlike collection deletion, this operation removes all documents from the collection, including indexed and queued ones. Request DELETE /api/v1/collections/{collection-id}/reset-only Response { \"message\": \"Collection cleaned successfully.\", \"data\": null }"
  },
  "docs/en/entities/documents.html": {
    "href": "docs/en/entities/documents.html",
    "title": "Documents | AIVAX",
    "keywords": "Documents A document represents a piece of knowledge. It is a limited, self-sufficient, and meaningful piece of text on its own. A document is the component that is indexed by the internal model to be retrieved later through a semantic search term. Consider a car manual: it is not a document, but rather several documents. Each of these documents talks, in isolation, about a specific topic related to that car, in such a way that the document does not depend on external context or information to make sense. Each document in this manual will talk about a topic: one will talk about how to turn on the car, another about how to turn it off, another about how its paint is made, and another about how to change the oil periodically. It is not a good idea to reserve a document to talk about several things at the same time, as this will reduce the objectivity and scope of the inference and reduce the quality of acquisition. Examples of document creation: Do not do Do not create very short documents (with 10 or fewer words). Do not create very large documents (with 700 or more words). Do not talk about more than one thing in a document. Do not mix different languages in documents. Do not be implicit in documents. Do not write documents using technical language, such as codes or structures like JSON. Do Be explicit about the purpose of your document. Focus documents on individual topics, summarizing what should be done or explained. Always repeat terms that are keywords for the document search. Example: prefer to use \"The color of the Honda Civic 2015 is yellow\" instead of \"the color of the car is yellow\". Restrict the document content to talk about only one topic or subject. Use simple and easy-to-understand human language. API Usage As all documents are entities that belong to a collection, always have the collection where the document is/will be located at hand. Sending documents in bulk To send a large list of documents to a collection, structure them following the JSONL format. The indexing file structure is: {\"docid\":\"Cars/HondaCivic2015.rmd:1\",\"text\":\"The Honda Civic 2015 is available in [...]\",\"__ref\":null,\"__tags\":[\"Cars\",\"Honda-Civic-2015\"]} {\"docid\":\"Cars/HondaCivic2015.rmd:2\",\"text\":\"The engine of the Honda Civic 2015 is [...]\",\"__ref\":null,\"__tags\":[\"Cars\",\"Honda-Civic-2015\"]} {\"docid\":\"Cars/HondaCivic2015.rmd:3\",\"text\":\"The color of the Honda Civic 2015 is Yellow [...]\",\"__ref\":null,\"__tags\":[\"Cars\",\"Honda-Civic-2015\"]} ... The structure consists of the following properties: Property Type Description docid string Specifies the document name. Useful for debugging and identification. text string The \"raw\" content of the document that will be indexed. __ref string Optional. Specifies a reference ID of the document. __tags string[] Optional. Specifies an array of document tags. Useful for document management. A document reference is an ID that can be specified in several documents that need to be linked in a search when one of them is matched in a similarity search. For example, if a search finds a document that has a reference ID, all other documents in the same collection that share the same reference ID as the matched document will also be included in the search response. The use of references can be useful when a document depends on another or more documents to make sense. There is no format requirement for the reference ID: any format is accepted. You can send up to 1,000 lines of documents per request. If you need to send more documents, separate the sending into more requests. If you send a document with more than 1,000 lines, the following lines will be ignored. Note that very long documents, which exceed the allowed number of tokens in the internal embedding model, will have their content truncated and the indexing quality may be severely affected. To avoid this problem, send documents that contain between 20 and 700 words. Warning Warning: this endpoint generates cost. The cost is calculated based on the tokens of the content of each document. The content of each document is tokenized according to the model used in the indexing of the documents. Request The sending must be done using multipart form data. POST /api/v1/collections/{collection-id}/documents documents=[documents.jsonl] Response { \"message\": null, \"data\": [ { \"name\": \"Institutional/Company.rmd:1\", \"documentId\": \"01965f93-a36b-7fc2-9e6a-c733f4955927\" }, { \"name\": \"Institutional/Company.rmd:2\", \"documentId\": \"01965f93-a390-79d3-9b3d-338d407f6b64\" }, { \"name\": \"Institutional/Company.rmd:3\", \"documentId\": \"01965f93-a391-79ef-adcf-737d98303a78\" }, { \"name\": \"Products/Schedules.rmd:1\", \"documentId\": \"01965f93-a391-712e-9292-c4d8e010bf42\" }, ... ] } Create or modify document This endpoint creates or modifies a document from its name. When a document is modified, its indexing vectors are reset, that is, the document will enter the queue again to be indexed by the indexing engine. This indexing is not exempt from cost. The cost is relative to the number of tokens of the sent content. The cost is only generated when the document is actually changed. Calling this route with the same content as the document does not generate modification, therefore, it does not generate cost. Warning Warning: this endpoint generates cost. The cost is calculated based on the tokens of the content of the file. The content of the file is tokenized according to the model used in the indexing of the documents. Request PUT /api/v1/collections/{collection-id}/documents { // the name of the document that will be modified \"name\": \"document-name\", // the content of the document that will be created or overwritten if the name already exists \"contents\": \"Content of my document\", // parameters explained earlier \"reference\": null, \"tags\": [\"products\", \"my-product\"] } Response { \"message\": null, \"data\": { \"documentId\": \"0196663c-3a15-72c7-98e6-b496f8e8bb8c\", // the state of the operation indicates whether the document was modified \"Modified\" or created \"Created\". \"state\": \"Modified\" } } List documents This endpoint lists all available documents in a collection. You can pass an additional query parameter filter to filter documents by name, tag, or content. This filter supports expressions that help filter what you are looking for: -t \"tag\" - filters documents that have this tag. -r \"reference\" - filters documents that have this reference ID. -c \"content\" - filters documents that have this snippet in their content. -n \"name\" - filters documents that have this snippet in their name. Request GET /api/v1/collections/{collection-id}/documents Response { \"message\": null, \"data\": { \"pageInfo\": { \"currentPage\": 1, \"hasMoreItems\": true }, \"items\": [ { \"id\": \"01968452-69f6-7f00-a497-d14c5b906b79\", \"name\": \"Help/Customers.rmd:1\", \"reference\": null, \"tags\": [ \"Help\", \"Customers\" ], \"contentsPreview\": \"A customer is a registration on your platform...\", \"indexState\": \"Indexed\" }, { \"id\": \"01968452-6a53-7ce3-adad-fad32d508856\", \"name\": \"Help/Customers.rmd:2\", \"reference\": null, \"tags\": [ \"Help\", \"Customers\" ], \"contentsPreview\": \"In the customer registration, it is possible to modify...\", \"indexState\": \"Indexed\" }, ... ] } } View document View details about a specific document. Request GET /api/v1/collections/{collection-id}/documents/{document-id} Response { \"message\": null, \"data\": { \"id\": \"01965f93-a36b-7fc2-9e6a-c733f4955927\", \"name\": \"Institutional/Company.rmd:1\", // represents the indexing situation of the document. // valid values: Queued, Indexed, Cancelled \"state\": \"Indexed\", // content of the indexed document \"contents\": \"...\", // document reference ID \"reference\": \"institutional-company\" } } Delete document Permanently deletes a document through its ID. Request DELETE /api/v1/collections/{collection-id}/documents/{document-id} Response { \"message\": \"Document removed.\", \"data\": null }"
  },
  "docs/en/entities/functions.html": {
    "href": "docs/en/entities/functions.html",
    "title": "Functions | AIVAX",
    "keywords": "Functions Functions are a way to force your model to process information using JSON as an intermediate communication. With functions, you can make any model respond in the JSON format you want. It can be useful for categorizing comments, applying moderation to reviews, or processing information with AI assistance. Currently, functions can only be used with models provided by AIVAX. Calling a function To call an AI function, you need to specify what the AI should respond with and provide a JSON Schema that it must follow. Less intelligent models tend to fail at generating JSON, producing an invalid or problematic document. To address this, adjust your model, the instruction, and the retry parameter if necessary. You are charged for each attempt the AI makes to generate. Slightly smarter models tend to produce correct results on the first try. It is guaranteed that a valid JSON will be generated and that this JSON will follow the same schema provided in the request. Consider using a cache on your application side for data that does not need to be constantly updated, such as weather data, daily statistics, etc. AIVAX does not perform any caching on our side. Request POST /api/v1/functions/json { // Required. Specify the name of the integrated model that will be used to perform the action. \"modelName\": \"@metaai/llama-3.1-8b\", // Required. Explain what your model should do with the input and how it should produce the response. \"instructions\": \"Classify the user's comment, indicating whether it is positive or negative, and whether it contains any relevant information (a number between 0 (not very relevant) and 10 (very relevant))\", // Required. The JSON Schema that the model must follow to generate the response. You can provide generation examples in the instructions field. \"responseSchema\": { \"type\": \"object\", \"properties\": { \"feedbackType\": { \"type\": \"string\", \"enum\": [\"neutral\", \"positive\", \"negative\"] }, \"informationScore\": { \"type\": \"integer\", \"minimum\": 0, \"maximum\": 10 } }, \"required\": [\"feedbackType\", \"informationScore\"] }, // Optional. Defines a JSON input for the model. Can be any type of JSON value. \"inputData\": { \"userComment\": \"Terrible market. There is a guard inside watching you so you don't steal and the butchers ignore you and serve pretty girls in front of you. But thank God other markets are arriving and the end of this nonsense will come\" }, // Optional. Defines how many attempts the model should try before the API returns an error. Must be a number between 1 and 30. \"maxAttempts\": 10, // Optional. Defines the timeout in seconds to obtain a valid JSON before the API returns an error. Must be a number between 1 and 3600 (one hour). \"timeout\": 300, // Optional. Defines the temperature for JSON generation. Higher values tend to be more creative, while lower values are more deterministic. Number from 0 to 2. \"temperature\": 0.4, // Optional. Provides additional context for generation via chat/completions‑style messages. You can also provide multimodal content for compatible models. \"context\": [ { \"role\": \"user\", \"content\": \"Additional context\" } ], // Optional. Provides built‑in AIVAX tools for the generation. \"tools\": [ \"WebSearch\", \"Code\", \"OpenUrl\", \"ImageGeneration\", \"XPostsSearch\" ], // Optional. Defines tool generation parameters. \"toolsOptions\": { \"webSearchMode\": \"Full\" | \"Summarized\", \"webSearchMaxResults\": 10, \"imageGenerationMaxResults\": 2, \"imageGenerationQuality\": \"Low\" | \"Medium\" | \"High\" | \"Highest\", \"imageGenerationAllowMatureContent\": false }, // Optional. Additional function metadata. Not visible to the assistant. \"metadata\": { \"foo\": \"bar\" } } Response { \"result\": { \"requiresAttention\": true, \"shortSummary\": \"Customer threatens cancellation and bad publicity if not contacted today.\" }, \"attempt\": 0, \"elapsedMilliseconds\": 1235, \"warnings\": [], \"context\": { \"generatedUsage\": [ { \"sku\": \"inference.functions.json.in\", \"amount\": 0.0000123, \"unitPrice\": 1e-7, \"quantity\": 123, \"description\": \"JSON function rendering (@google/gemini-2.0-flash)\" }, { \"sku\": \"inference.functions.json.out\", \"amount\": 0.0000116, \"unitPrice\": 4e-7, \"quantity\": 29, \"description\": \"JSON function rendering (@google/gemini-2.0-flash)\" } ], \"runnedFunctions\": [] } } JSON Schema Guidelines The response format must be provided by a JSON Schema. Behind the scenes, AIVAX guides the model to generate a response with the provided JSON schema. When the model generates something invalid, we tell it to try again and correct the errors until the output conforms to the supplied specification. The supported JSON Schema directives of AIVAX are: string: minLength maxLength pattern format Can be date-time, email, time, duration, uri, url, ipv4, ipv6, uuid or guid. enum number and integer: minimum maximum exclusiveMinimum exclusiveMaximum multipleOf array items uniqueItems minItems maxItems object properties required bool and boolean null Additionally, you can specify one or more values in the type of the object, for example: { \"type\": [\"string\", \"number\"] } Note: number and integer are synonyms and integer does not guarantee that the number will be an integer. Functions in tools It is possible to use built‑in tools as JSON functions. This will allow the model to call functions to obtain the necessary context to generate the final JSON. Examples Check out examples of AI functions for various everyday tasks: Classify good or bad comments POST /api/v1/functions/json { \"modelName\": \"@google/gemini-2.0-flash\", \"instructions\": \"Classify the user's comment by providing a rating for the comment.\", \"inputData\": { \"inputText\": \"The food is good, but the environment is very noisy and a bit dirty as well.\" }, \"responseSchema\": { \"type\": \"object\", \"properties\": { \"commentSummary\": { \"type\": \"string\", \"description\": \"Summary of what the user meant.\" }, \"score\": { \"type\": \"integer\", \"min\": 1, \"max\": 5, \"description\": \"The rating extracted from the evaluation, where 1 is very bad and 5 is very good.\" } }, \"required\": [ \"commentSummary\", \"score\" ] } } { \"result\": { \"commentSummary\": \"The food is good, but the environment is noisy and a bit dirty.\", \"score\": 3 }, \"attempt\": 0, \"elapsedMilliseconds\": 788, \"warnings\": [], \"context\": { \"generatedUsage\": [ { \"sku\": \"inference.functions.json.in\", \"amount\": 0.0000083, \"unitPrice\": 1e-7, \"quantity\": 83, \"description\": \"JSON function rendering (@google/gemini-2.0-flash)\" }, { \"sku\": \"inference.functions.json.out\", \"amount\": 0.0000128, \"unitPrice\": 4e-7, \"quantity\": 32, \"description\": \"JSON function rendering (@google/gemini-2.0-flash)\" } ], \"runnedFunctions\": [] } } Evaluate a mathematical expression POST /api/v1/functions/json { \"modelName\": \"@qwen/qwen3-32b\", \"instructions\": \"Evaluate the given math problem and provide the result step-by-step.\", \"inputData\": { \"inputText\": \"what is two plus two minus pi ?\" }, \"responseSchema\": { \"type\": \"object\", \"properties\": { \"steps\": { \"type\": \"array\", \"items\": { \"type\": \"object\", \"properties\": { \"stepDescription\": { \"type\": \"string\", \"description\": \"Current math step description.\" }, \"carry\": { \"type\": \"number\", \"description\": \"The current result.\" } }, \"required\": [ \"stepDescription\", \"carry\" ] }, \"minItems\": 1 }, \"finalResult\": { \"type\": \"number\", \"description\": \"The math operation final result.\" } }, \"required\": [ \"steps\", \"finalResult\" ] }, \"tools\": [ \"Code\" ] } { \"result\": { \"steps\": [ { \"stepDescription\": \"Add 2 and 2\", \"carry\": 4 }, { \"stepDescription\": \"Subtract pi (π) from the result\", \"carry\": 0.858407346410207 } ], \"finalResult\": 0.858407346410207 }, \"attempt\": 0, \"elapsedMilliseconds\": 5775, \"warnings\": [], \"context\": { \"generatedUsage\": [ { \"sku\": \"inference.functions.json.in\", \"amount\": 0.00031001, \"unitPrice\": 2.9e-7, \"quantity\": 1069, \"description\": \"JSON function rendering (@qwen/qwen3-32b)\" }, { \"sku\": \"inference.functions.json.out\", \"amount\": 0.00054162, \"unitPrice\": 5.9e-7, \"quantity\": 918, \"description\": \"JSON function rendering (@qwen/qwen3-32b)\" } ], \"runnedFunctions\": [ { \"functionName\": \"evaluate_code\", \"success\": true, \"context\": { \"arguments\": \"console.log(2 + 2 - Math.PI);\", \"result\": { \"evaluatedCode\": \"console.log(2 + 2 - Math.PI);\", \"result\": \"0.8584073464102069\\nScript evaluation result: undefined\\n\" } } } ] } } Fetch latest news and weather for a given city POST /api/v1/functions/json { \"modelName\": \"@openai/gpt-4o-mini\", \"instructions\": \"Search for the 5 latest news and weather data for the given city.\", \"inputData\": { \"city\": \"Tokyo\" }, \"responseSchema\": { \"type\": \"object\", \"properties\": { \"latestNews\": { \"type\": \"array\", \"items\": { \"type\": \"object\", \"properties\": { \"title\": { \"type\": \"string\" }, \"details\": { \"type\": \"string\" }, \"link\": { \"type\": \"string\", \"format\": \"uri\" } }, \"required\": [ \"title\", \"details\", \"link\" ], \"additionalProperties\": false } }, \"weather\": { \"type\": \"object\", \"properties\": { \"currentTemperature\": { \"type\": \"number\" }, \"currentWeather\": { \"type\": \"string\", \"enum\": [ \"sunny\", \"cloudy\", \"rain\", \"thunderstorm\" ] }, \"forecast\": { \"type\": \"string\", \"enum\": [ \"sunny\", \"cloudy\", \"rain\", \"thunderstorm\" ] } }, \"required\": [ \"currentTemperature\", \"currentWeather\", \"forecast\" ], \"additionalProperties\": false }, \"assistantSummary\": { \"type\": \"string\" } }, \"required\": [ \"latestNews\", \"weather\", \"assistantSummary\" ], \"additionalProperties\": false }, \"tools\": [ \"XPostsSearch\", \"WebSearch\" ] } { \"result\": { \"latestNews\": [ { \"title\": \"Indian Ambassador to Japan Expands Cooperation\", \"details\": \"Indian Ambassador to Japan Sibi George expressed eagerness to expand cooperation between India and Japan in business, technology, and security.\", \"link\": \"https://japannews.yomiuri.co.jp/\" }, { \"title\": \"Emperor Emeritus Akihito Discharged from Hospital\", \"details\": \"Japan’s Emperor Emeritus Akihito was discharged from the University hospital.\", \"link\": \"https://www.japantimes.co.jp/\" }, { \"title\": \"Tokyo Stocks Climb Following Wall Street Gains\", \"details\": \"Tokyo stocks climbed in the morning following Wall Street gains.\", \"link\": \"https://www.independent.co.uk/topic/tokyo\" }, { \"title\": \"Tightening of Business Manager Visa Requirements\", \"details\": \"Tokyo is tightening requirements for popular business manager visas.\", \"link\": \"https://www.japantimes.co.jp/latest-news/\" }, { \"title\": \"ANA Plans Affordable Flying Taxi Service\", \"details\": \"ANA plans to launch an affordable flying taxi service in Japan by 2027.\", \"link\": \"https://www.japantimes.co.jp/\" } ], \"weather\": { \"currentTemperature\": 31, \"currentWeather\": \"cloudy\", \"forecast\": \"rain\" }, \"assistantSummary\": \"The latest news from Tokyo includes diplomatic and economic updates, while the current weather is partly cloudy with a temperature of 31°C.\" }, \"attempt\": 0, \"elapsedMilliseconds\": 19772, \"warnings\": [], \"context\": { \"generatedUsage\": [ { \"sku\": \"serviceusage.web_search\", \"amount\": 0.005, \"unitPrice\": 0.005, \"quantity\": 1, \"description\": \"Web Search request\" }, { \"sku\": \"serviceusage.web_search\", \"amount\": 0.005, \"unitPrice\": 0.005, \"quantity\": 1, \"description\": \"Web Search request\" }, { \"sku\": \"inference.functions.json.in\", \"amount\": 0.000453, \"unitPrice\": 1.5e-7, \"quantity\": 3020, \"description\": \"JSON function rendering (@openai/gpt-4o-mini)\" }, { \"sku\": \"inference.functions.json.out\", \"amount\": 0.0002406, \"unitPrice\": 6e-7, \"quantity\": 401, \"description\": \"JSON function rendering (@openai/gpt-4o-mini)\" } ], \"runnedFunctions\": [ { \"functionName\": \"web_search\", \"success\": true, \"context\": { \"arguments\": { \"search_term\": \"Tokyo weather\" }, \"result\": { \"results\": [ { \"title\": \"Search results\", \"url\": \"\" } ] } } }, { \"functionName\": \"web_search\", \"success\": true, \"context\": { \"arguments\": { \"search_term\": \"latest news in Tokyo\" }, \"result\": { \"results\": [ { \"title\": \"Search results\", \"url\": \"\" } ] } } } ] } } Fetch trending artists by musical genre POST /api/v1/functions/json { \"modelName\": \"@openai/gpt-4.1-mini\", \"instructions\": \"The function should search, using the latest X posts, the music streaming platforms (like Spotify, Apple Music etc.) and identify the 10 most played artists in the genre provided by the user. Then, it should format an object containing an ordered list of 10 artists, including position (1–10), name and estimated number of streams.\", \"inputData\": { \"genre\": \"dubstep\" }, \"responseSchema\": { \"type\": \"object\", \"properties\": { \"artists\": { \"type\": \"array\", \"description\": \"List of the 10 most played artists in the specified genre\", \"items\": { \"type\": \"object\", \"properties\": { \"rank\": { \"type\": \"integer\", \"description\": \"Position in the Top 10\", \"minimum\": 1, \"maximum\": 10 }, \"name\": { \"type\": \"string\", \"description\": \"Artist name\" }, \"monthlyStreams\": { \"type\": \"string\", \"description\": \"Approximate number of monthly streams, formatted, e.g., \\\"150M\\\"\" }, \"source\": { \"type\": \"string\", \"description\": \"Platform or data source\" } }, \"required\": [ \"rank\", \"name\", \"monthlyStreams\", \"source\" ], \"additionalProperties\": false } } }, \"required\": [ \"artists\" ], \"additionalProperties\": false }, \"maxAttempts\": 4, \"temperature\": 1, \"tools\": [ \"XPostsSearch\", \"WebSearch\" ], \"toolsOptions\": {} } { \"result\": { \"artists\": [ { \"rank\": 1, \"name\": \"Skrillex\", \"monthlyStreams\": \"31M\", \"source\": \"Spotify\" }, { \"rank\": 2, \"name\": \"Virtual Riot\", \"monthlyStreams\": \"12M\", \"source\": \"Spotify\" }, { \"rank\": 3, \"name\": \"Excision\", \"monthlyStreams\": \"11M\", \"source\": \"Spotify\" }, { \"rank\": 4, \"name\": \"Zeds Dead\", \"monthlyStreams\": \"10M\", \"source\": \"Spotify\" }, { \"rank\": 5, \"name\": \"Flux Pavilion\", \"monthlyStreams\": \"9M\", \"source\": \"Spotify\" }, { \"rank\": 6, \"name\": \"Illenium\", \"monthlyStreams\": \"8.5M\", \"source\": \"Spotify\" }, { \"rank\": 7, \"name\": \"Rusko\", \"monthlyStreams\": \"7M\", \"source\": \"Spotify\" }, { \"rank\": 8, \"name\": \"Bassnectar\", \"monthlyStreams\": \"6M\", \"source\": \"Spotify\" }, { \"rank\": 9, \"name\": \"Seven Lions\", \"monthlyStreams\": \"5.5M\", \"source\": \"Spotify\" }, { \"rank\": 10, \"name\": \"Getter\", \"monthlyStreams\": \"5M\", \"source\": \"Spotify\" } ] }, \"attempt\": 0, \"elapsedMilliseconds\": 11243, \"warnings\": [], \"context\": { \"generatedUsage\": [ { \"sku\": \"serviceusage.x_api.search\", \"amount\": 0.005, \"unitPrice\": 0.005, \"quantity\": 1, \"description\": \"X Posts search\" }, { \"sku\": \"inference.functions.json.in\", \"amount\": 0.0016448, \"unitPrice\": 4e-7, \"quantity\": 4112, \"description\": \"JSON function rendering (@openai/gpt-4.1-mini)\" }, { \"sku\": \"inference.functions.json.out\", \"amount\": 0.0006272, \"unitPrice\": 0.0000016, \"quantity\": 392, \"description\": \"JSON function rendering (@openai/gpt-4.1-mini)\" } ], \"runnedFunctions\": [ { \"functionName\": \"x_posts_search\", \"success\": true, \"context\": { \"arguments\": { \"search_query\": \"dubstep artists Spotify OR Apple Music OR streaming\" }, \"result\": [ { \"url\": \"https://"
  },
  "docs/en/entities/search.html": {
    "href": "docs/en/entities/search.html",
    "title": "Search | AIVAX",
    "keywords": "Search The search API, through the query key obtained from the collections, performs a semantic search on it, performing an intelligent comparison for each indexed document in a collection. After creating a collection, you will get its ID. Use the ID of your collection to perform the search on the indexed documents of the same. Use the endpoints of this API to embed the semantic search of documents in your AI model or chatbot. Searching documents This endpoint expects a GET request with the following parameters: term: required. Specifies the search term that will be searched in the documents. top: Specifies the maximum number of documents that should be returned in the search. min: Specifies the minimum score for obtaining the documents. Warning Warning: this endpoint generates cost. The cost is calculated based on the tokens of the search term. The search term is tokenized according to the model used in the indexing of the documents. Request GET /api/v1/collections/{collection-id}/query term=What is the color of the Honda CIVIC? Response { \"message\": null, \"data\": [ { \"documentId\": \"01965f93-a391-71a8-968a-47ccd4949de0\", \"documentName\": \"Products/Honda Civic 2015.rmd:1\", \"documentContent\": \"[...]\", \"score\": 0.7972834229469299, \"referencedDocuments\": [] }, { \"documentId\": \"01965f93-a391-76b3-bbf5-3fb74d10d412\", \"documentName\": \"Products/Honda Civic 2015.rmd:2\", \"documentContent\": \"[...]\", \"score\": 0.5693517327308655, \"referencedDocuments\": [] }, { \"documentId\": \"01965f93-a391-7026-b7aa-1cc6c63cd7d1\", \"documentName\": \"Products/Honda Civic 2015.rmd:5\", \"documentContent\": \"[...]\", \"score\": 0.5475733876228333, \"referencedDocuments\": [] }, ... ] } For the search result, the higher the score, the more similar the document is to the search term. AIVAX uses embedding models that allow task orientation. For the search, the term is vectorized with a DOCUMENT_QUERY orientation. For document indexing, the orientation is DOCUMENT_RETRIEVAL, which provides a more optimized search and not to verify the similarity between documents."
  },
  "docs/en/getting-started.html": {
    "href": "docs/en/getting-started.html",
    "title": "Welcome | AIVAX",
    "keywords": "Welcome Welcome to AIVAX. Our service makes it easier to develop intelligent AI models that use a knowledge base provided by you to converse with the user, answer questions, provide real-time information, and more. To get started, all endpoints must be made to the AIVAX production URL: https://inference.aivax.net/ Concepts and definitions Understand the concepts used by the API below: Account: represents a user account, which has an authentication token. Collection: represents a collection of knowledge documents. A user can have multiple document collections. Document: represents a fact, a single piece of knowledge, and an item in a collection. A collection can have multiple documents. AI Gateway: represents an AI gateway that benefits from or does not use a knowledge collection, such as a plug-and-play knowledge middleware for a model. Embedded model: represents an AI model that AIVAX provides to the user. Chat client: represents a user interface that makes the AI gateway available through an interactive online chat. Chat session: hosts a conversation and context of a chat client. Handling errors All API errors return an HTTP response with a non-OK status (never 2xx or 3xx), and always follow the JSON format: { \"error\": \"An explanatory error message\", \"details\": {} // an object containing relevant error information. Most of the time it is null }"
  },
  "docs/en/legal/privacy-policy.html": {
    "href": "docs/en/legal/privacy-policy.html",
    "title": "Privacy Policy | AIVAX",
    "keywords": "Privacy Policy Version: 1.1 Effective date: October 5, 2025 Last previous update: July 30, 2025 Welcome to AIVAX. This Privacy Policy describes how AIVAX collects, uses, stores, shares, and protects information in its AI inference services. Our commitment is to transparency, security, and compliance with the General Data Protection Law (LGPD) and the Internet Civil Framework. By using AIVAX services, the Account Manager acknowledges and agrees to the terms of this policy. This policy does not constitute legal advice; we recommend review by the Account Manager’s legal department. 1. Definitions AIVAX: Company providing the platform and AI model orchestration services. AIVAX Account Manager (\"Manager\"): Natural or legal person who creates and administers the account and integrates the API. End User: Individual who interacts with the Manager’s application that consumes the AIVAX API. Account Data: Registration and administrative data (e.g., name, email, company, role, internal identifiers, preferences, API key settings). Billing Data: Data required for billing and invoices (e.g., CNPJ/CPF, corporate name, address, payment methods through a third‑party processor). Inference Data: Inputs (prompts, text, instructions, metadata) sent to the models and the resulting outputs/inferences. (Equivalent to the terms “Input Content” + “Generated Content” defined in the Terms of Use.) Conversations: Structured set of inference interactions (input + response + context metadata). Technical Metadata: Request logs, IP, timestamp, latency, session identifiers, token usage, response codes, security signatures. Operator: AIVAX when processing data according to the Manager’s instructions (inference data/conversations). Controller: AIVAX when defining purposes for account, billing, security, and compliance data. Sub‑processor: Third party contracted by AIVAX to support processing (infrastructure, monitoring, billing, email, model providers, etc.). 2. Processing Roles Data Type AIVAX Role Manager Role Account Data Controller Data Subject/Controller of its own internal relationship Billing Data Controller (legal and contractual compliance) Provides/Verifies Inference Data / Conversations Operator Controller (defines content and purpose) Technical Metadata Controller (security / improvement) and Operator (technical execution) Controller (origin) When acting as Operator, AIVAX will strictly follow the Manager’s instructions, as defined by API calls and dashboard settings. For contractual consistency, in case of terminological divergence between this policy and the Terms of Use, the equivalence will prevail: Inference Data = Input Content + Generated Content. 3. Categories of Collected Data Provided directly by the Manager: Account Data, credentials (hashes or tokens), preferences, usage settings, organization, generated API keys. Generated by use: Technical metadata (logs, aggregated statistics, token counts, latencies, model usage). Inference Data and Conversations: Textual content and other formats sent to the models and the returns. Support and Communication: Ticket messages, emails sent to support or contact channels. Billing: Fiscal and payment data (partially processed by specialized third parties). Aggregated/Anonymized Data: Derived metrics that do not identify the Manager or end users. We do not deliberately collect special categories of sensitive personal data (art. 5º, II, LGPD) unless the Manager chooses to send them in Inference Data. In that case, the Manager declares having an appropriate legal basis and consent when required. 4. Purposes, Legal Bases, and Retention Category Primary Purpose Legal Basis (LGPD) Indicative Retention Period* Account Data Account creation, management, authentication, operational communications Contract execution (art. 7º, V) While the account is active + up to 6 months after termination (audit) Billing Data Billing, tax invoicing, fraud prevention (includes credit rules, expiration, refunds – see Terms of Use) Legal obligations (art. 7º, II) / Contract execution 5 to 10 years (tax requirements) Technical Metadata Security, abuse prevention, performance monitoring Legitimate interest (art. 7º, IX) + Contract execution 180 days (main logs) / up to 1 year (extended security) Inference Data Execution of the requested inference Contract execution Operational time (standard: up to 30 days) Conversations History for monitoring, technical audit, debugging Legitimate interest (balanced) + Contract execution Up to 30 days (standard) or less if configured; exportable and deletable Support Resolve questions, incidents, compliance Contract execution / Legitimate interest Up to 12 months after resolution Aggregated/Anonymized Data Capacity metrics, reliability improvement Outside LGPD scope (anonymized data) Indeterminate (as long as irreversibly anonymized) *Periods may be shortened upon request, except where legal obligation or rights defense requires longer retention. Encrypted backups may retain data for up to an additional 90 days until full rotation; purged data does not return to production after restoration, with deletion re‑processing applied. 5. No Use for Own Training AIVAX does not use Inference Data or Conversations to train proprietary models, create individualized usage profiles, or monetize data. Use is restricted to providing the contracted service. 6. Storage and Deletion of Conversations The Manager may: (i) adjust retention (when the feature exists), (ii) delete conversations individually or in bulk, (iii) request total purge. Deletion is final and irreversible in production; records may temporarily persist in backups until the technical retention window expires. 7. Data Subject Rights (Art. 18, LGPD) When AIVAX acts as Controller (e.g., account data), data subjects may exercise: confirmation of processing; access; correction; anonymization, blocking or deletion; portability; information about sharing; revocation of consent (if applicable); opposition to processing based on legitimate interest; review of automated decisions. Channel: **privacy@aivax.net** or **wm@aivax.net** (Data Protection Officer). Standard response time: up to 15 days. We may request identity verification. For data where we act as Operator, we will direct the data subject to the Controller Manager. 8. Data Protection Officer (DPO) Data Protection Officer (Art. 41): (Anonymized identity) – Contact: **wm@aivax.net**. Functions: communication channel with data subjects and ANPD, internal compliance guidance, support for impact assessments. 9. Sub‑processors We use sub‑processors for: cloud infrastructure, load balancing, performance monitoring, transactional email, billing, model providers, abuse detection. We will publish (or have already published) an updated list on a dedicated page: (link to be added). Material changes will be notified before taking effect whenever contractually required; continued use after a reasonable objection period constitutes acceptance. 10. Third‑Party Model Providers When selecting a specific model, the Manager also complies with the provider’s policies. Some providers may use inference data for improvement or training. The Manager must validate suitability before sending personal or sensitive data. AIVAX does not control third‑party policies and recommends prior review. 11. International Data Transfers Data may be processed or stored in data centers outside Brazil (e.g., US, EU), using providers that adopt security standards aligned with leading international practices. We apply: (i) contracts with protection clauses; (ii) encryption; (iii) minimization; (iv) logical segregation. If the transfer falls under the specific hypotheses of art. 33, we will adopt appropriate contractual and technical safeguards. 12. Information Security (Layers) Key measures (without disclosing operational secrets): Encryption in transit (TLS 1.2+ / 1.3) and at rest (AES‑256 or equivalent). Role‑based access control and principle of least privilege. Environment segregation (development, staging, production) and pipeline with reviews. Audit logs for administrative actions and access to sensitive data. Integrity monitoring, anomaly alerts, and automatic rate limiting. Periodic vulnerability testing and prioritized remediation. Infrastructure hardening and secure credential rotation. Pseudonymization or truncation of sensitive fields in technical logs. No security measure is absolute; we maintain a continuous improvement program. 13. Incident Management Relevant security incidents will be assessed based on impact, data nature, and risk to data subjects. If required, we will notify affected Managers and the ANPD with: (i) event description; (ii) possibly involved data; (iii) actions already taken and planned mitigation; (iv) guidance to the Manager. Our response plan is reviewed periodically. 14. Automated Decisions We employ automations for abuse detection, request throttling, and fraud prevention. These automations may temporarily restrict access or keys. We do not make solely automated decisions that produce legal effects or significant impacts on individuals. The Manager may request human review via support. 15. Cookies and Tracking Technologies In the dashboard interface we may use strictly necessary cookies (session/authentication) and possibly functional cookies for preferences. We do not use behavioral advertising cookies. If we later employ third‑party analytics, we will update this section and provide a consent mechanism when applicable. The Manager can manage cookies via browser settings; disabling strictly necessary cookies may limit functionality. 16. Children, Adolescents, and Emancipated Minors The services are not intended for persons under 18, except legally emancipated minors aged 16 or older under Brazilian law. We do not intentionally collect personal data of non‑emancipated minors. If we identify improper processing, we will take swift removal measures and notify the Manager. The Manager is responsible for implementing checks when the use involves potentially under‑age audiences. 17. Sensitive Data We do not require the submission of sensitive data. The Manager should avoid sending health, biometric, genetic, religious belief, political opinion, or other special category data unless they have an appropriate legal basis and clearly inform the data subjects. AIVAX may apply filters or blocks for high‑risk content types. 18. Use Limitations and Prohibited Content It is prohibited to use the platform to store or process illegal content, rights‑infringing material, malware, defamatory material, or anything that infringes third‑party rights. We may suspend or block keys upon reasonable suspicion of violation, preserving necessary logs for investigation. Suspension and termination measures also follow the Terms of Use (Sections 2.1 and 5). 19. Anonymization and Aggregated Data We may generate aggregated statistics (e.g., token volume, error rate, model distribution) without direct identification of individuals or specific conversation content. Such data does not revert to an identifiable form. 20. Export and Portability We provide (or will provide) mechanisms to export conversation history and metrics in structured formats (JSON), limited by retention windows and security. For data retained while we act as Operator, data subject requests must be directed to the Controller Manager. 21. Backups and Disaster Recovery Encrypted backups are performed on periodic windows and retained for up to 90 days for operational continuity. After requested deletions, we flag records for logical purge and prevent re‑introduction after restoration by re‑processing the deletion queue. 22. Changes to This Policy Material changes will be notified by email to the Manager or highlighted in the dashboard with reasonable advance (preferably 15 days), unless legal or urgent security requirements apply. Continued use after the effective date constitutes acceptance. 23. Contact Channel and Complaints Questions, rights requests, or complaints: **privacy@aivax.net** / **wm@aivax.net**. If unsatisfied, the data subject may appeal to the ANPD (National Data Protection Authority). 24. Revision History Version Effective Date Main Changes 1.0 30/07/2025 Initial version published 1.1 05/10/2025 Added legal bases, rights, detailed retention, sub‑processors, transfers, expanded security, incidents, automated decisions, cookies, sensitive data, versioning 25. General Contact Legal / Privacy: **legal@aivax.net** – Data Protection Officer: **wm@aivax.net**. Always use official channels to avoid social engineering. 26. Final Provisions If any clause of this policy is deemed invalid, the remaining provisions remain in full force. In case of conflict between this policy and specific product terms, the more protective provision for data subjects will prevail, unless a different legal obligation applies. If any doubts remain about any point of this policy, please get in touch. We remain committed to continuous improvement of privacy and security. Note: This policy may be complemented by a specific Data Processing Agreement (DPA) between AIVAX and the Manager, when applicable."
  },
  "docs/en/legal/terms-of-service.html": {
    "href": "docs/en/legal/terms-of-service.html",
    "title": "Terms of Use | AIVAX",
    "keywords": "Terms of Use Version: 1.1 Effective date: October 5, 2025 Previous last update: July 30, 2025 Welcome to AIVAX. These Terms of Use (\"Terms\") govern your access to and use of our AI inference services, APIs, website, and any associated software (collectively, the \"Services\"). By creating an account, accessing, or using our Services, you (\"AIVAX Account Manager\") agree to be bound by these Terms and our Privacy Policy. If you do not agree with these Terms, do not use our Services. 1. Definitions AIVAX: The company that provides the services. AIVAX Account Manager: The natural or legal person who creates and manages an account on the AIVAX platform and agrees to these Terms. Input Content: The data, text, prompts, or any other information that the AIVAX Account Manager sends to the Services for processing. Generated Content: The responses, text, images, or any other data generated by the AI models as a result of processing the Input Content. (Terminology Mapping): In the Privacy Policy, \"Inference Data\" jointly encompass Input Content and Generated Content; \"Conversations\" represent aggregated sequences of these interactions. 2. Use of Services and Responsibilities 2.1. Responsible Use and Conduct You agree to use AIVAX Services ethically and responsibly. It is strictly prohibited: System Abuse: Engaging in activities that abuse, interfere with, disrupt, or harm the Services, our servers, or networks. This includes, but is not limited to, sending an excessive volume of requests that could be characterized as a denial‑of‑service (DoS) attack, attempting to find and exploit vulnerabilities, or trying to access unauthorized areas of the system. Inappropriate Behavior: Using the Services to harass, threaten, defame, deceive, or violate the legal rights and dignity of third parties. AIVAX values a healthy technological environment and will not tolerate conduct that could reasonably be interpreted as malicious or abusive. 2.2. Legal Compliance You are solely responsible for ensuring that your use of the Services complies fully with all applicable laws and regulations. Brazilian and International Laws: You agree not to use the Services to create or disseminate Generated Content that violates any law in force in Brazil or relevant international jurisdictions. This includes, but is not limited to, laws on copyright, intellectual property, defamation, hate speech, terrorism, and child exploitation. Marco Civil da Internet and LGPD: Your use must respect the principles established by the Marco Civil da Internet (Law No. 12.965/2014) and the General Data Protection Law (LGPD – Law No. 13.709/2018). 2.3. Consent for Use of Personal Data The AIVAX Account Manager is the controller of the data entered into the Services. If the Input Content includes personal data of third parties, you represent and warrant that: You Have the Appropriate Legal Basis: You have obtained the necessary legal basis (such as the explicit and informed consent of the data subject) to collect, process, and send this data to AIVAX for inference purposes. Full Responsibility: You are the sole and exclusive party responsible for complying with all LGPD obligations regarding this data, including responding to data‑subject requests. AIVAX acts only as a processor of this data under your instructions. 2.4. Eligibility To use AIVAX services, you must be legally capable, i.e., at least 18 years old or 16 years old if emancipated. By using our services, you represent that: you have not been suspended, removed, or banned from our service previously; your account is linked to a person without debts and in compliance with local laws and regulations; you meet the minimum age required to use our services. If you are using our services on behalf of another person, organization, or company, you assume that such entity has all necessary responsibility for its actions and accepts these terms of use. 2.5. Balance, Credits, and Refunds To use most AIVAX services, prepaid balance (\"credits\") must be added to your account. By using our services, you agree that: Our payment providers may collect and store deterministic data about you, such as physical addresses, payment data (e.g., credit cards), and any information required to charge for balance addition. This information is not linked to or used by AIVAX and is the responsibility of our payment partners. Before paying for credits, you can view the service fees charged by AIVAX in advance and refuse to pay them, preventing balance addition. Credits added expire one year after addition. After that period, the expired credit will no longer be counted toward your account balance. Refunds are permitted only if both conditions are met at the time of the refund request: the refund is requested within 24 hours of the balance addition and the total account balance is equal to or greater than the requested refund amount. The service fee is non‑refundable. From the amount paid, only the final credit will be refunded by the payment provider. 3. Generated Content and Intellectual Property 3.1. Ownership and Responsibility for Generated Content Subject to these Terms, AIVAX grants you all rights, title, and interest in the Generated Content. In other words: what you create is yours. Consequently, you are the sole and exclusive party responsible for the Generated Content and its subsequent use. You assume all risks associated with it, including legality, accuracy, suitability, and possible third‑party rights infringements. AIVAX has no responsibility or obligation regarding how you use the Generated Content. Non‑Exclusivity and Similarity: Due to the statistical nature of the models, semantically or textually similar content may be generated for different users without cross‑access to the original inputs. We do not guarantee absolute exclusivity of expressions or ideas resulting from the models. You do not acquire any rights to model weights, internal prompts, techniques, or AIVAX trade secrets. Limited License Granted to AIVAX: By submitting Input Content, you grant AIVAX a worldwide, non‑exclusive, royalty‑free license limited to what is necessary to (i) process inferences; (ii) maintain technical logs and security; (iii) detect abuse; (iv) comply with legal obligations. We do not use Input Content or Generated Content to train proprietary models. High‑Risk Sectors: Generated Content must not be used as the sole basis for medical, legal, financial, critical safety engineering, or any context that could generate significant physical or financial risk without qualified human validation. 3.2. Adult, Explicit, and Sensitive Content AIVAX is a tool and, as such, can be used to generate a wide range of content. The generation of explicit, adult, or pornographic content is permitted, provided the following conditions are strictly observed: Full Responsibility: You assume total and complete responsibility for creating, storing, and distributing such material. Undeniable Legality: The material must never violate any applicable law, with zero tolerance for content that depicts or suggests child exploitation, non‑consensual violence, or any other form of illegal abuse. Consent: If the material involves representations of real people, you must have explicit and verifiable consent from those individuals to create and use their images for this purpose. Access Control: You are responsible for implementing your own access‑control and age‑verification mechanisms if you decide to make this content available to third parties. AIVAX does not endorse this type of content and reserves the right to investigate and suspend accounts that violate the above conditions. 4. Third‑Party Model Providers AIVAX Services may route your Input Content to AI models operated by third parties. When using a specific model, you may also be subject to that model provider’s terms of use. It is your responsibility to review and comply with such terms. AIVAX is not liable for the policies or practices of third‑party providers. 5. Suspension and Termination AIVAX reserves the right to suspend, terminate, or ban your access to our services, at its sole discretion and without prior notice, for any violation of these terms. Activities that may lead to suspension include, but are not limited to, legal‑compliance violations, system abuse, or non‑payment. Suspensions may be temporary or permanent, depending on the severity of the breach. 6. Limitation of Liability and Disclaimer of Warranties THE SERVICES ARE PROVIDED \"AS IS\" AND \"AS AVAILABLE,\" WITHOUT WARRANTIES OF ANY KIND, WHETHER EXPRESS OR IMPLIED. AIVAX DOES NOT WARRANT THAT THE SERVICES WILL BE UNINTERRUPTED, SECURE, OR ERROR‑FREE. UNDER NO CIRCUMSTANCES WILL AIVAX BE LIABLE FOR ANY INDIRECT, INCIDENTAL, SPECIAL, CONSEQUENTIAL, OR PUNITIVE DAMAGES ARISING FROM YOUR ACCESS TO OR USE OF THE SERVICES. GENERATED CONTENT MAY CONTAIN INACCURACIES, OMISSIONS, OR “Hallucinations” AND IS PROVIDED FOR INFORMATIONAL PURPOSES ONLY; THE USER IS RESPONSIBLE FOR HUMAN VERIFICATION BEFORE ANY CRITICAL USE. 7. Indemnification You agree to indemnify, defend, and hold harmless AIVAX, its affiliates, administrators, collaborators, and partners from any claims, losses, damages, liabilities, costs, and expenses (including reasonable attorney fees) resulting from: (i) Input Content; (ii) misuse of the Services; (iii) breach of these Terms or applicable law; (iv) infringement of third‑party intellectual property, privacy, or personality rights; (v) improper use or exposure of API keys issued to your account. 8. Termination and Post‑Termination We may terminate or suspend access to the Services (in whole or in part) if: (i) there is a breach of these Terms; (ii) a security risk; (iii) a legal requirement; (iv) repeated default; (v) abuse or fraud. After termination: (a) your access and keys may be deactivated immediately; (b) you may request export of available data (when the functionality exists) within 15 days; (c) data will be deleted or anonymized according to the Privacy Policy, subject to legal obligations and rights defense; (d) outstanding amounts remain payable. 9. Force Majeure No party will be liable for performance failures or delays caused by events beyond its reasonable control, including, but not limited to, natural disasters, governmental actions, widespread internet infrastructure failures, massive cyber‑attacks, pandemics, wars, or large‑scale power outages. Payment obligations are not discharged by completed force‑majeure events. 10. Export Controls and Sanctions You represent that you are not located in, nor acting on behalf of, any entity or person subject to sanctions or trade restrictions imposed by Brazilian or international authorities (including trade restriction lists or economic sanctions). You will not use the services for purposes prohibited by export, anti‑corruption, or anti‑terrorism laws. 11. Confidentiality and Credential Security You must keep API keys, tokens, and credentials associated with your account confidential, implementing appropriate access controls. Any activity performed with your credentials will be presumed authorized by you until a compromise notice is communicated. You commit to promptly notify AIVAX of any suspected unauthorized use. 12. Feedback and Improvements Any comments, suggestions, ideas, or feedback you provide may be freely used by AIVAX to improve or develop products and services, without any obligation of compensation, attribution, or additional confidentiality. 13. Beta Features and Model Discontinuation Features labeled “Beta,” “Experimental,” or similar may exhibit instability, behavior changes, or removal without notice. We may discontinue models or adjust technical limits (latency, throughput, quotas) for performance, cost, compliance, or security reasons. 14. Notice and Takedown Procedure If you believe any output or use of the Services infringes copyright, trademark, or other rights, send a notice to legal@aivax.net containing: (i) precise identification of the material; (ii) basis of the claim; (iii) your contact information; (iv) a good‑faith and truthful statement. We may remove or limit access preemptively and terminate repeat‑offender accounts. 15. Assignment You may not assign or transfer these Terms without prior written consent from AIVAX. AIVAX may assign these Terms, in whole or in part (including in corporate transactions, mergers, acquisitions, or reorganizations), upon simple notice. 16. Survival The following provisions survive termination: Intellectual Property, Limitation of Liability, Indemnification, Confidentiality, Termination (post‑termination obligations), Assignment, Governing Law and Jurisdiction, and any others that by their nature must persist. 17. Entire Agreement These Terms, together with the Privacy Policy and any additional documents expressly referenced, constitute the entire agreement between you and AIVAX, superseding any prior understandings or communications regarding the subject matter. 18. Notices Formal notices may be delivered via: (i) the registered email address; (ii) notices on the dashboard; or (iii) publication on the official Terms page. A notice sent by email is considered received after 24 hours from sending, unless a proven technical error occurs. 19. Price and Limit Updates We may adjust prices, billing models, usage limits, or quota policies. Changes that materially affect future costs will be communicated with reasonable prior notice (except where legal or emergency requirements apply). Continued use after the effective date of changes constitutes acceptance. 20. Language This Portuguese version prevails over any translation provided solely for convenience. 21. Modifications to the Terms We may modify these Terms at any time. We will notify you of changes by publishing an updated version or sending electronic communication. Material changes may require additional acceptance or cessation of use if you do not agree. Continued use after the effective date of the changes constitutes acceptance. 22. General Provisions These Terms are governed by the laws of the Federative Republic of Brazil. The court of the County of São Paulo, State of São Paulo, Brazil, is elected to resolve disputes, with a waiver of any other jurisdiction, however privileged. The possible invalidity of any clause does not affect the validity of the remaining clauses. For any questions about these Terms of Use, contact: **legal@aivax.net**"
  },
  "docs/en/limits.html": {
    "href": "docs/en/limits.html",
    "title": "API Limits | AIVAX",
    "keywords": "API Limits Rate limits regulate the number of requests you can send within a time window. These limits help AIVAX prevent abuse and provide a stable API to everyone. The API limits below are the same for all AIVAX embedded models. These limits are categorized by operations performed by the API. Each account has a tier that defines which limits are applied to the account. Tiers change according to the total invested in AIVAX and the time the account has existed. Tier zero: new account that has never added credits or has test credits. Tier 1: account created at least 48 hours ago and has added any credit value. Tier 2: account created at least 1 month ago and has added at least $100 in credits. Tier 3: account created at least 3 months ago and has added at least $1,000 in credits. The measurement is by credit addition and not by consumption. For example, you don't need to consume $100 in credits to advance to Tier 2. Limit legends: RPM: requests per minute. RPD: requests per day (24 hours). TPM: input tokens per minute. New account Tier 1 Tier 2 Tier 3 Operation RPM RPD TPM Document search 50 - - Document insertion - 100 - Inference 5 300 50,000 Inference (high-end models) - - - Tools (shared) - 100 - web_search tool - 20 - x_posts_search tool - 20 - generate_image tool - 5 - Operation RPM RPD TPM Document search 150 - - Document insertion - 3,000 - Inference 75 10,000 1,000,000 Inference (high-end models) 75 10,000 200,000 Tools (shared) - 1,000 - web_search tool - 300 - x_posts_search tool - 300 - generate_image tool - 30 - Operation RPM RPD TPM Document search 300 - - Document insertion - 10,000 - Inference 200 - 4,000,000 Inference (high-end models) 200 - 1,000,000 Tools (shared) - 10,000 - web_search tool - 1,000 - x_posts_search tool - 1,000 - generate_image tool - 300 - Operation RPM RPD TPM Document search 1,000 - - Document insertion - 30,000 - Inference 1,000 - 10,000,000 Inference (high-end models) 1,000 - 4,000,000 Tools (shared) - 50,000 - web_search tool - 10,000 - x_posts_search tool - 10,000 - generate_image tool - 1,000 - Document search: includes semantic search of documents in a collection by the search endpoint ../collections/{id}/query. Document insertion: includes creation and modification of documents in a collection. Inference: every inference or function call, either by chat client or API. high-end models refer to models that require Tier 1 to be used. Tools (shared): every built-in tool invoked by the assistant. This limit is shared for all tools provided by AIVAX and is not used for tools defined by you or your APIs. Tool (tool name): every use of the mentioned tool. Limits for BYOK (Bring-your-own-key) For models provided by you, the applied limit is 1,500 requests per minute. This limit is separate from the integrated inference limit."
  },
  "docs/en/mcp.html": {
    "href": "docs/en/mcp.html",
    "title": "Support for Model Context Protocol (MCP) | AIVAX",
    "keywords": "Support for Model Context Protocol (MCP) You can bind external tools of the MCP protocol to your AI Gateway. The protocol defines functions that run on the server side and enable the assistant to interact with real‑time services. MCP functions persist the server‑side action calls of AIVAX, removing the need to implement the function on the client side. Choosing the function name The function name should be simple and deterministic about what the function does. Avoid names that are hard to guess or that do not reflect the function’s role, as the assistant may become confused and fail to call the function when appropriate. For example, let's consider a function that looks up a user in an external database. The following names are good examples to consider for the call: search_user query_user Bad names include: search (implicit, possibly ambiguous) search user (name with improper characters) Having the function name, we can think about the function description. Choosing the function description The function description should conceptually explain two things: what it does and when it should be called by the assistant. This description should include the scenarios the assistant should consider calling it and when it should not be called, providing a few one‑shot call examples and/or making the function’s rules explicit. Defining MCP servers You can define your MCP servers in the gateway using a JSON array: [ { \"name\": \"Meu servidor MCP\", \"url\": \"https://example-server.io/mcp\", \"headers\": { \"Authorization\": \"sk-pv-12nbo...\" } } ] Your MCP server must be enabled for SSE or Streamable HTTP to work with AIVAX. You can set custom headers in your MCP server configuration to configure authentication or other requirements. AIVAX calls to the remote MCP server will normally send additional metadata information via the _meta field of the MCP: { \"jsonrpc\": \"2.0\", \"id\": 2, \"method\": \"tools/call\", \"params\": { \"name\": \"get_weather\", \"arguments\": { \"location\": \"New York\" }, \"_meta\": { \"_aiv_nonce\": \"$2a$12$ynC9kC2q6iuEjO8SFDQqVeDxvHPUIZ9jTClE91SJo8VYtt/BSJDUG\", \"_aiv_external_user_id\": \"custom-user-id\", \"_aiv_call_source\": \"WebChatClient\", \"_aiv_conversation_token\": \"iiocc6stxgj5jc75ay4y\", \"_aiv_moment\": \"2025-09-09T16:58:05\", \"custom_metadata_field_1\": \"foo\", \"something\": \"bar\" } } } From the values defined in _meta, you have the inference, client, or function metadata parameters. Values prefixed with _aiv are reserved for AIVAX parameters."
  },
  "docs/en/models.html": {
    "href": "docs/en/models.html",
    "title": "Models | AIVAX",
    "keywords": "Models AIVAX provides models from different providers to make development even faster, eliminating the need to configure an account for each provider to access their latest models. See the list below of available models and their pricing. All prices consider the total input and output tokens, with or without cache. All prices are in United States dollars. amazon Model name Pricing Description @amazon/nova-pro Input: $ 0.80 /1m tokens Output: $ 3.20 /1m tokens A highly capable multimodal model with the best combination of accuracy, speed, and cost for a wide range of tasks. Input: accepts images, videos Function calls Reasoning JSON functions @amazon/nova-lite Input: $ 0.06 /1m tokens Output: $ 0.24 /1m tokens A very low cost multimodal model that is lightning fast for processing image, video, and text inputs. Input: accepts images, videos Function calls Reasoning JSON functions @amazon/nova-micro Input: $ 0.04 /1m tokens Output: $ 0.14 /1m tokens A text-only model that delivers the lowest latency responses at very low cost. Function calls JSON functions anthropic Model name Pricing Description @anthropic/claude-4.5-sonnet Input: $ 3.00 /1m tokens Input (cached): $ 0.30 /1m tokens Output: $ 15.00 /1m tokens Claude Sonnet 4.5 is the newest model in the Sonnet series, offering improvements and updates over Sonnet 4. Input: accepts images Function calls Reasoning JSON functions @anthropic/claude-4-sonnet Input: $ 3.00 /1m tokens Input (cached): $ 0.30 /1m tokens Output: $ 15.00 /1m tokens Anthropic's mid-size model with superior intelligence for high-volume uses in coding, in-depth research, agents, & more. Input: accepts images Function calls Reasoning JSON functions @anthropic/claude-3.5-haiku Input: $ 0.80 /1m tokens Input (cached): $ 0.08 /1m tokens Output: $ 4.00 /1m tokens Claude 3.5 Haiku is the next generation of our fastest model. For a similar speed to Claude 3 Haiku, Claude 3.5 Haiku improves across every skill set and surpasses Claude 3 Opus, the largest model in our previous generation, on many intelligence benchmarks. Input: accepts images Function calls JSON functions @anthropic/claude-3-haiku Input: $ 0.25 /1m tokens Input (cached): $ 0.03 /1m tokens Output: $ 1.25 /1m tokens Claude 3 Haiku is Anthropic's fastest model yet, designed for enterprise workloads which often involve longer prompts. Input: accepts images Function calls JSON functions cohere Model name Pricing Description @cohere/command-a Input: $ 2.50 /1m tokens Output: $ 10.00 /1m tokens Command A is Cohere's most performant model to date, excelling at tool use, agents, retrieval augmented generation (RAG), and multilingual use cases. Command A has a context length of 256K, only requires two GPUs to run, and has 150% higher throughput compared to Command R+ 08-2024. Input: accepts images Function calls JSON functions deepseekai Model name Pricing Description @deepseekai/r1 Input: $ 0.50 /1m tokens Input (cached): $ 0.40 /1m tokens Output: $ 2.15 /1m tokens The DeepSeek R1 model has undergone a minor version upgrade, with the current version being DeepSeek-R1-0528. Function calls Reasoning JSON functions @deepseekai/v3.1-terminus Input: $ 0.27 /1m tokens Input (cached): $ 0.22 /1m tokens Output: $ 1.00 /1m tokens DeepSeek-V3.1 is post-trained on the top of DeepSeek-V3.1-Base, which is built upon the original V3 base checkpoint through a two-phase long context extension approach, following the methodology outlined in the original DeepSeek-V3 report. Function calls Reasoning JSON functions @deepseekai/v3.2 Input: $ 0.27 /1m tokens Output: $ 0.40 /1m tokens DeepSeek-V3.2-Exp is an intermediate step toward the next-generation architecture of the DeepSeek models by introducing DeepSeek Sparse Attention—a sparse attention mechanism designed to explore and validate optimizations for training and inference efficiency in long-context scenarios. Function calls Reasoning JSON functions google Model name Pricing Description @google/gemini-2.5-pro Input: $ 1.25 /1m tokens Input (cached): $ 0.31 /1m tokens Output: $ 10.00 /1m tokens One of the most powerful models today. Input: accepts images, videos, audio Function calls Reasoning @google/gemini-2.5-flash Input: $ 0.30 /1m tokens Input (cached): $ 0.08 /1m tokens Output: $ 2.50 /1m tokens Google's best model in terms of price-performance, offering well-rounded capabilities. 2.5 Flash is best for large scale processing, low-latency, high volume tasks that require thinking, and agentic use cases. Input: accepts images, videos, audio Function calls Reasoning JSON functions @google/gemini-2.5-flash-lite Input: $ 0.10 /1m tokens Input (cached): $ 0.03 /1m tokens Output: $ 0.40 /1m tokens A Gemini 2.5 Flash model optimized for cost efficiency and low latency. Input: accepts images, videos, audio Function calls Reasoning JSON functions @google/gemini-2.0-flash Input: $ 0.10 /1m tokens Input (cached): $ 0.03 /1m tokens Output: $ 0.40 /1m tokens Gemini 2.0 Flash delivers next-gen features and improved capabilities, including superior speed, native tool use, and a 1M token context window. Input: accepts images, videos, audio Function calls JSON functions @google/gemini-2.0-flash-lite Input: $ 0.08 /1m tokens Output: $ 0.30 /1m tokens General-purpose model, with image recognition, smart and fast. Great for an economical chat. Input: accepts images, videos, audio Function calls JSON functions inception Model name Pricing Description @inception/mercury Input: $ 0.25 /1m tokens Output: $ 1.00 /1m tokens Extremely fast model by generative diffusion. Function calls JSON functions metaai Model name Pricing Description @metaai/llama-3.3-70b Input: $ 0.59 /1m tokens Output: $ 0.79 /1m tokens Previous generation model with many parameters and surprisingly fast speed. Function calls JSON functions @metaai/llama-4-maverick-17b-128e Input: $ 0.20 /1m tokens Output: $ 0.60 /1m tokens Fast model, with 17 billion activated parameters and 128 experts. Input: accepts images Function calls JSON functions @metaai/llama-4-scout-17b-16e Input: $ 0.11 /1m tokens Output: $ 0.34 /1m tokens Smaller version of the Llama 4 family with 17 billion activated parameters and 16 experts. Input: accepts images Function calls JSON functions @metaai/llama-3.1-8b Input: $ 0.05 /1m tokens Output: $ 0.08 /1m tokens Cheap and fast model for less demanding tasks. Function calls JSON functions mistral Model name Pricing Description @mistral/pixtral-large Input: $ 2.00 /1m tokens Output: $ 6.00 /1m tokens Pixtral Large is the second model in our multimodal family and demonstrates frontier-level image understanding. Particularly, the model is able to understand documents, charts and natural images, while maintaining the leading text-only understanding of Mistral Large 2. Input: accepts images Function calls JSON functions @mistral/magistral-medium Input: $ 2.00 /1m tokens Output: $ 5.00 /1m tokens Mistral's frontier-class reasoning model update released September 2025 with vision support. Input: accepts images Reasoning JSON functions"
  },
  "docs/en/pricing.html": {
    "href": "docs/en/pricing.html",
    "title": "Pricing | AIVAX",
    "keywords": "Pricing The AIVAX payment model is pre-paid, meaning you use our services with the balance you add to your account. We do not send invoices at the beginning of the month for your usage. This way, it is predictable to know how much you will spend using our inference and agent creation services. AIVAX charges a small fee (variable by payment method) when adding credits to cover taxes, payment provider fees, and our service fee. The pricing of models and inference is provided directly by the inference providers and their models, such as Google and OpenAI. There are no fees or additions on top of these prices. You pay the same value you would pay to these providers directly. We use different services to help you create agentive assistants. Some tools and services have a cost, and these costs are passed on to your account without any additional fees. Inference is charged in US dollars (USD), so there may be currency fluctuations when converting from your local currency to US dollars. Bring-your-own-key (BYOK) You can bring your own OpenAI-compatible API key to use directly on AIVAX. Since we do not know which model you will be using, we do not charge anything on top of the inference you use on your models. Additionally, when using your own model with AIVAX, the rate limits are increased to 3,600 requests per minute, which is equivalent to 60 requests per second. Note that you are still charged for services you use with your own models, such as RAG, internet search, image generation, etc. If your account has a negative balance, you will not be able to use any services, including inference for your own API keys, until you add balance again."
  },
  "docs/en/protocol-functions.html": {
    "href": "docs/en/protocol-functions.html",
    "title": "Server-side Functions | AIVAX",
    "keywords": "Server-side Functions Important Protocol functions are no longer maintained and have been replaced by MCP functions. The AIVAX protocol functions, or server-side functions, are an implementation where the model's tool calls occur on the server side. Similar to MCP, but with native authentication support and optimized to work externally. Protocol functions allow actions to be taken on the AIVAX server side, removing the need to implement the function on the client side and integrating with existing applications and services. These functions expect a callback via a URL, and when the model decides to call the function, the callback is accessed with the parameters provided by the assistant itself. The assistant does not know which URL it is calling, as it remains invisible to both the assistant and the user. Choosing the function name The function name should be simple and deterministic about what the function does. Avoid hard-to-guess names or names that do not reflect the function's role, as the assistant may get confused and not call the function when appropriate. As an example, let's think of a function that queries a user in an external database. The following names are good examples to consider for the call: search_user query_user Bad names include: search (too generic) query-user-in-database-data (name too long) pesquisa-usuario (name not in English) search user (name with improper characters) Having the function name, we can think about the function description. Choosing the function description The function description should conceptually explain two situations: what it does and when it should be called by the assistant. This description should include the scenarios the assistant should consider calling it and when it should not be called, providing a few one‑shot call examples and/or making the function rules explicit. Defining protocol functions These functions are defined in the AI‑gateway, which enables the creation of intelligent agents that perform actions without human intervention. They follow a simple syntax, expecting the function name, a description of what it does, and the invocation parameters. Protocol functions are defined in the AI gateway using JSON: POST /api/v1/ai-gateways { \"name\": \"my-ai-gateway\", \"parameters\": { ... \"protocolFunctions\": [ { \"name\": \"list_clients\", \"description\": \"Use this tool to list and search for the user's clients.\", \"callbackUrl\": \"https://my-external-api.com/api/scp/users\", \"contentFormat\": null }, { \"name\": \"view_client\", \"description\": \"Use this tool to get details and orders of a client by its ID.\", \"callbackUrl\": \"https://my-external-api.com/api/scp/users\", \"contentFormat\": { \"type\": \"object\", \"properties\": { \"user_id\": { \"type\": \"string\", \"format\": \"uuid\" } }, \"required\": [\"user_id\"] } } ] } } In the snippet above, you are providing two functions for your AI model: list_clients and view_client, which the model will decide which to execute during its reasoning. You can also provide a JSON content format that the model will use when calling your API with the supplied content. You can also define the list of supported functions via an endpoint. Every time the model receives a message, it will query the provided endpoint to obtain a list of functions it can execute. Define the function‑listing endpoints in your AI gateway: POST /api/v1/ai-gateways { \"name\": \"my-ai-gateway\", \"parameters\": { ... \"protocolFunctionSources\": [ \"https://my-external-api.com/api/scp/listings\" ] } } The function‑provision endpoint must respond using the following format: GET https://my-external-api.com/api/scp/listings { \"functions\": [ { \"name\": \"list_clients\", \"description\": \"Use this tool to list and search for the user's clients.\", \"callbackUrl\": \"https://my-external-api.com/api/scp/users\", \"contentFormat\": null }, { \"name\": \"view_client\", \"description\": \"Use this tool to get details and orders of a client by its ID.\", \"callbackUrl\": \"https://my-external-api.com/api/scp/users\", \"contentFormat\": { \"type\": \"object\", \"properties\": { \"user_id\": { \"type\": \"string\", \"format\": \"uuid\" } }, \"required\": [\"user_id\"] } } ] } These functions are cached for 10 minutes before a new request is made to the supplied endpoint. Handling function calls Functions are invoked at the callbackUrl endpoint via an HTTP POST request, with the body: { \"function\": { \"name\": \"view_client\", \"content\": { \"user_id\": \"3e5a2823-98fa-49a1-831a-0c4c5d33450e\" } }, \"context\": { \"externalUserId\": \"...\", \"moment\": \"2025-05-18T03:36:27\" } } The response to this action must always return an HTTP OK status (2xx or 3xx), even for errors the assistant may have made. A non‑OK response will indicate to the assistant that the function could not be called, and it will not continue with what it was planning to do. Response format Successful responses should be textual and will be attached as the function's response exactly as returned by the endpoint. There is no JSON format or structure required for this response, but it is advisable to provide a simple, human‑readable answer so the assistant can read the result of the action. Errors can be common, such as not finding a client by ID or a field not being in the desired format. In these cases, respond with an OK status and include a human‑readable description of the error and how the assistant can work around it in the response body. It is guaranteed that the request will strictly follow the JSON Schema of the content defined by the function definition. Functions that do not expect arguments should not specify a content format for that function. Important The more functions you define, the more input tokens you will consume during the reasoning process. The function definition, as well as its format, consumes tokens in the reasoning process. Authentication Request authentication is performed via the X-Aivax-Nonce header sent with all protocol function requests, including listing requests. See the authentication manual to understand how to authenticate reverse requests from AIVAX. User authentication Function calls send a $.context.externalUserId field containing the user tag created in a chat session. This tag can be used to authenticate the user who invoked the function. Security considerations For the AI model, only the name, description, and format of the function are visible. It cannot see the endpoint to which the function points. Additionally, it does not have access to the user tag authenticated in a chat client. Specialist functions In addition to the built‑in tools, you can define specialist functions that perform specific tasks in your AIVAX account. You define specialist functions using the aivax:// URL scheme, as shown in the example below: { \"name\": \"my-ai-gateway\", \"parameters\": { ... \"protocolFunctions\": [ { \"name\": \"search_disease\", \"description\": \"Use this tool to search for diseases, treatments, and symptoms.\", \"callbackUrl\": \"aivax://query-collection?collection-id=0196f5ef-9334-742b-a988-f913bb3be5ba&top=5&min=0.4\", \"contentFormat\": { \"type\": \"object\", \"properties\": { \"query\": { \"type\": \"string\", \"description\": \"Name of the disease, treatment, or symptoms.\" } }, \"required\": [ \"query\" ] } } ] } } The function above creates a tool for the AI to query a specific document collection, guiding the assistant on what to search for in that collection and what to expect in a response. This way, you can link multiple RAG collections so an assistant can retrieve specialist content. You can customize the description of the JSON Schema properties for specialist functions but not their structure, as our backend expects a specific format to call the functions. Specialist function parameters are supplied in the URL via query parameters. Currently, only one specialist function exists: query-collection: performs a RAG search on a specified collection. Query parameters: collection-id: the UUID of the collection to be searched. top: a number indicating how many documents should be returned in the search. min: a decimal indicating the minimum similarity score for the search. JSON format of the function: { \"type\": \"object\", \"properties\": { \"query\": { \"type\": \"string\", \"description\": \"Search content.\" } }, \"required\": [ \"query\" ] }"
  },
  "docs/entities/ai-gateways/ai-gateway.html": {
    "href": "docs/entities/ai-gateways/ai-gateway.html",
    "title": "AI Gateway | AIVAX",
    "keywords": "AI Gateway Os gateways de AI é um serviço que a AIVAX fornece para criar um túnel de inferência entre um modelo de LLM e uma base de conhecimento. Nele é possível: Criar um modelo com instruções personalizadas Usar um modelo provido por você através de um endpoint OpenAI compatível, ou usar um modelo disponibilizado pela AIVAX Personalizar parâmetros de inferência, como temperatura, top_p, prefill Usar uma coleção de conhecimento como fundação de respostas para IA Dentre outros recursos. Com o AI Gateway, você cria um modelo pronto para uso, parametrizado e fundamentado nas instruções que você definir. Modelos Você pode trazer um modelo de IA compatível com a interface OpenAI para o gateway de IA. Se você trazer seu modelo de IA, iremos cobrar apenas pela pesquisa de documentos anexada na IA. Você também pode usar um dos modelos abaixo que já estão prontos para começar com o AIVAX. Ao usar um modelo, você perceberá que alguns são mais inteligentes que outros para determinadas tarefas. Alguns modelos são melhores com certas estratégias de obtenção de dados do que outros. Realize testes para encontrar o melhor modelo. Você pode ver os modelos disponíveis na página de modelos. Usar um gateway de IA A AIVAX provê um endpoint compatível com a interface OpenAI através de um AI-gateway, o que facilita a integração do modelo criado pela AIVAX com aplicações e SDKs existentes. Vale ressaltar que somente algumas propriedades são suportadas. Em um gateway de IA, você já configura os parâmetros do modelo, como System Prompt, temperatura e nome do modelo. Ao usar esse endpoint, alguns valores do gateway podem ser sobrescritos pela requisição. Requisição POST /api/v1/chat-completions { \"model\": \"0198683a-2b6d-7066-9598-6ea119c219f2\", \"messages\": [ { \"role\": \"user\", \"content\": \"Qual a capital da França?\" } ], \"stream\": false, \"metadata\": { \"foo\": \"bar\" } } Resposta para não-streaming { \"id\": \"0198d24c-c9ce-70fe-9cf3-00644ef5f2e2\", \"object\": \"chat.completion\", \"created\": 1755874904, \"model\": \"@openai/gpt-5-mini\", \"choices\": [ { \"index\": 0, \"message\": { \"role\": \"assistant\", \"content\": \"A capital da França é Paris.\", \"refusal\": null, \"annotations\": [], \"tool_calls\": [] }, \"logprobs\": null, \"finish_reason\": \"stop\" } ], \"usage\": { \"prompt_tokens\": 84, \"completion_tokens\": 16, \"total_tokens\": 1892, \"prompt_tokens_details\": { \"cached_tokens\": 1792 } }, \"service_tier\": \"default\", \"generation_context\": { \"generated_usage\": [ { \"sku\": \"inference.resolving.routing_complexity.in\", \"amount\": 0.0000207, \"unit_price\": 7.5e-8, \"quantity\": 276, \"description\": \"Inference for model routing\" }, { \"sku\": \"inference.resolving.routing_complexity.out\", \"amount\": 3e-7, \"unit_price\": 3e-7, \"quantity\": 1, \"description\": \"Inference for model routing\" }, { \"sku\": \"inference.chat_completions.in\", \"amount\": 0.000021, \"unit_price\": 2.5e-7, \"quantity\": 84, \"description\": \"Inference for AI model '@openai/gpt-5-mini'\" }, { \"sku\": \"inference.chat_completions.out\", \"amount\": 0.000032, \"unit_price\": 0.000002, \"quantity\": 16, \"description\": \"Inference for AI model '@openai/gpt-5-mini'\" }, { \"sku\": \"inference.chat_completions.in.cached\", \"amount\": 0.0000448, \"unit_price\": 2.5e-8, \"quantity\": 1792, \"description\": \"Inference for AI model '@openai/gpt-5-mini'\" } ], \"runned_functions\": [] } } Resposta streaming data: {\"id\":\"chatcmpl-0198d263-fd80-7645-98b0-3966004e11df\",\"object\":\"chat.completion.chunk\",\"created\":1755876425,\"model\":\"@openai\\/gpt-5-mini\",\"system_fingerprint\":\"fp_2su4hm\",\"choices\":[{\"index\":0,\"finish_reason\":\"stop\",\"logprobs\":null,\"delta\":{\"role\":\"assistant\",\"content\":\"\"}}],\"usage\":null} ... data: {\"id\":\"chatcmpl-0198d263-ff5a-7f53-99e2-b59d5cdae470\",\"object\":\"chat.completion.chunk\",\"created\":1755876425,\"model\":\"@openai\\/gpt-5-mini\",\"system_fingerprint\":\"fp_7ibly5\",\"choices\":[{\"index\":0,\"finish_reason\":\"stop\",\"logprobs\":null,\"delta\":{\"content\":\"\"}}],\"usage\":null} data: {\"id\":\"chatcmpl-0198d263-ff80-7d8f-91e7-c61ac2a9e870\",\"object\":\"chat.completion.chunk\",\"created\":1755876425,\"model\":\"@openai\\/gpt-5-mini\",\"system_fingerprint\":\"fp_552km8\",\"choices\":[{\"index\":0,\"finish_reason\":\"stop\",\"logprobs\":null,\"delta\":{}}],\"usage\":{\"prompt_tokens\":1873,\"completion_tokens\":41,\"total_tokens\":1914}} data: [END] Uso com SDKs Por prover endpoints compatíveis com a interface OpenAI, a AIVAX é totalmente compatível com SDKs existentes, facilitando a integração plug-and-play. Veja o exemplo abaixo: from openai import OpenAI client = OpenAI( base_url=\"https://inference.aivax.net/api/v1\", api_key=\"oky_gr5u...oqbfd3d9y\" ) response = client.chat.completions.create( model=\"my-gateway:50c3\", # you can also provide your ai-gateway full ID here messages=[ {\"role\": \"user\", \"content\": \"Explain why AI-gateways are useful.\"} ] ) print(response.choices[0].message.content) No momento, a AIVAX só suporta o formato chat/completions. No futuro, pretendemos criar suporte para a API Responses."
  },
  "docs/entities/ai-gateways/pipelines.html": {
    "href": "docs/entities/ai-gateways/pipelines.html",
    "title": "Pipelines de IA | AIVAX",
    "keywords": "Pipelines de IA A AIVAX fornece vários pipelines para usar em seu gateway de IA. Você pode usar vários pipelines para executarem no contexto do seu gateway. RAG Através de coleções, você pode vincular uma coleção de documentos para seu gateway de IA. Você pode definir os parâmetros de incorporação, como quantidade de documentos, pontuação mínima e estratégia de incorporação. Cada estratégia de incorporação é mais refinada que a outra. Algumas criam resultados melhores que as demais, mas é importante realizar testes práticos com várias estratégias para entender qual se ajusta melhor no modelo, conversa e tom do usuário. Talvez seja necessário realizar ajustes no prompt do sistema para informar melhor como a IA deverá considerar os documentos anexados na conversa. Os documentos são anexados como uma mensagem do usuário, limitados aos parâmetros que você define na estratégia de obtenção. Estratégias com reescrita normalmente geram os melhores resultados à um baixo custo de latência e custo. O modelo de reescrita usado sempre o com menor custo, escolhido normalmente por um pool interno que decide o modelo que está com menor latência no momento. Estratégias sem custo de reescrita: Plain: a estratégia padrão. É a menos otimizada e não possui custo de reescrita: a última mensagem do usuário é usada como termo de busca para pesquisar na coleção anexada do gateway. Concatenate: Concatena em linhas as últimas N mensagens do usuário, e então o resultado da concatenação é usada como termo de busca. Estratégias com custo de reescrita (os tokens de inferência são cobrados): UserRewrite: reescreve as últimas N mensagens do usuário usando um modelo menor, criando uma pergunta contextualizada no que o usuário quer dizer. FullRewrite: reescreve as últimas N*2 mensagens do chat usando um modelo menor. Similar ao UserRewrite, mas considera também as mensagens da assistente na formulação da nova pergunta. Geralmente cria as melhores perguntas, com um custo um pouco maior. É a estratégia mais estável e consistente. Funciona com qualquer modelo. Estratégias de função: QueryFunction: fornece uma função de pesquisa na coleção integrada para o modelo de IA. Você deverá ajustar nas instruções do sistema os cenários ideais para o modelo chamar essa função quando necessário. Pode não funcionar tão bem em modelos menores. Ao definir uma coleção de RAG no pipeline de seu gateway, a primeira mensagem do contexto da conversa será o resultado da incorporação do RAG como uma mensagem do usuário (exceto para quando usado como ferramentas onde o resultado da incorporação é anexado como uma resposta de ferramenta). Definir muitos documentos de resposta do RAG aumenta o consumo de tokens de entrada e pode aumentar o preço final da inferência. Fixando instruções O pipeline de instruções permite prefixar instruções em diversos lugares do modelo, guiando e restrigindo o formato de resposta do modelo. As formas atuais de definir instruções são: Instruções do sistema: insire um texto fixo no prompt de sistema do contexto. Template de prompt do usuário: reformata a pergunta do usuário para seguir um formato específico de pergunta. Inicialização de assistente (prefill): inicializa a mensagem da assistente com tokens iniciais de geração. Esses parâmetros podem ser muito úteis para prompt engineering, no entanto, podem não ser compatível com todos os modelos. Atenção: prefixando instruções, templates e inicializações podem remover a capacidade de raciocínio, interpretação multi-modalidades e chamadas de ferramentas do modelo. Parametrização O pipeline de parametrização configura os hiper-parâmetros iniciais da inferência, como temperatura, nucleus sampling, presence penalty e demais hiperparâmetros de inferência. Truncating O pipeline de truncating permite definir o tamanho de uma conversa em tokens antes dela ser recortada. Quando esse pipeline está ativado, antes de toda inferência, é calculado se num_of_chars / 4 é maior que o máximo de tokens de entrada da conversa. Se o contexto for maior, o pipeline começa a remover mensagens do começo da conversa até que as mensagens caibam no contexto especificado. Ao menos uma mensagem do usuário (comumente a última mensagem) é mantida na conversa. Todas as demais mensagens são removidas, exceto as instruções do sistema. Alternativamente, você pode definir que ao atingir o limite um erro é disparado na API ao invés de recortar o contexto. Tool message truncating O pipeline de contagem de mensagens de ferramentas é similar ao de truncating: ele remove a resposta de ferramentas mais antigas e preserva somente as mais novas. Isso pode ser útil para quando respostas de ferramentas anteriores não sejam mais úteis em mensagens mais recentes e ocupam espaço no contexto, mas pode ser prejudicial ao usar com modelos agênticos que chamam ferramentas em cadeia. Esse pipeline é configurado em quantidade de mensagens de ferramentas à serem preservadas ao invés de tokens. Quando uma mensagem de ferramenta é considerada antiga, ela não é removida, mas tem seu conteúdo removido. Ferramentas do lado do servidor Esse pipeline permite a execução de ferramentas do lado do servidor da AIVAX, similar ao protocolo MCP. Leia mais sobre esse pipeline aqui. Ferramentas embutidas Você pode adicionar ferramentas providas pela AIVAX em seu gateway, como pesquisa na internet, geração de imagens e acesso de links. Consulte todas as ferramentas disponíveis aqui. Workers Workers definem o comportamento do seu gateway remotamente, usado para controlar quando certos eventos devem ser abortados ou continuados. Leia mais sobre esse pipeline aqui."
  },
  "docs/entities/ai-gateways/workers.html": {
    "href": "docs/entities/ai-gateways/workers.html",
    "title": "Workers de IA | AIVAX",
    "keywords": "Workers de IA Os workers do gateway de IA são recursos do Gateways de IA que permitem controlar o comportamento de seus recursos remotamente através de eventos. Com um controlador externo configurado, eventos são enviados para ele, e a resposta do seu controlador define se aquela ação deve continuar, ser abortada ou configurada. Quando um evento é acionado no lado da AIVAX, uma requisição POST é disparada ao worker configurado com informações do evento disparado. Com base em sua resposta, a ação pode ser anulada ou configurada. Não há nenhum cache - a requisição é feita em todos os eventos que ocorrem no seu gateway de IA. O tempo de processamento da resposta acrescenta uma latência entre toda ação do gateway, no entanto, adiciona uma camada de controle e moderação que você pode controlar à qualquer momento. Criando um worker de IA Quando um evento é acionado, uma requisição POST é disparada ao seu worker seguindo o formato abaixo: { \"gatewayId\": \"0197dda5-985f-7d76-96e5-0d0451c539f6\", \"moment\": \"2025-08-09T00:21:40\", \"event\": { \"name\": \"message.received\", \"data\": { \"message\": { \"role\": \"user\", \"content\": \"Bom dia!\" }, \"origin\": [ \"SessionsApi\" ], \"externalUserId\": \"mini-app-session@lot1xc9k03g2my3j4w2y1\" } } } O exemplo acima ilustra uma mensagem do evento message.received com os seus argumentos do evento. Após o envio da requisição, a AIVAX aguarda a resposta do seu worker, e com ela: Resposta OK (2xx): continua e prossegue com a execução normal do evento. Outras respostas: aborta e interrompe a execução do evento. Lista de eventos Atualmente, os eventos que podem ser enviados para seu worker são: message.received - enviado quando uma mensagem é recebida pelo gateway. Esse evento é acionado com a última mensagem recebida no contexto, o que pode ser do usuário ou não. { \"name\": \"message.received\", \"data\": { \"message\": {}, // chat/completions message entity \"origin\": [ \"SessionsApi\" // message origin ], \"externalUserId\": \"mini-app-session@lot1xc9k03g2my3j4w2y1\" } } Exemplo O exemplo abaixo ilustra um Cloudflare Worker que autentica uma conversa no Telegram com base no nome de usuário da converça: export default { async fetch(request, env, ctx) { // O ID do gateway que estamos esperando lidar const CHECKING_GATEWAY_ID = \"0197dda5-985f-7c76-96e5-0d0451c596e5\"; const ALLOWED_USERNAMES = [ \"myusername\" ]; if (request.method == \"POST\") { const requestData = await request.json(); const { event, gatewayId } = requestData; // Verifica se é um evento de mensagem recebida, se é o gateway que estamos // gerenciando no worker e se essa mensagem vem de um chat do Telegram if (gatewayId === CHECKING_GATEWAY_ID && event.name == \"message.received\" && event.data.externalUserId?.startsWith(\"zp_telegram:\")) { // obtém o username do telegram, que está entre o ':' e o '@' do externalUserId const telegramUsername = event.data.externalUserId.split(':')[0].split('@')[0]; // verifica se o usuário é permitido na integração if (!ALLOWED_USERNAMES.includes(telegramUsername)) { // o usuário não existe na lista de usernames permitidos, logo, retorna uma resposta não-ok // indicando que a mensagem não deve ser enviada return new Response(\"User is not authed\", { status: 400 }); } } } // continua com a execução return new Response(); } };"
  },
  "docs/entities/chat-clients.html": {
    "href": "docs/entities/chat-clients.html",
    "title": "Chat Clients | AIVAX",
    "keywords": "Chat Clients Um cliente de chat provê uma interface de usuário através de um AI Gateway que permite o usuário conversar com sua assistente. Um chat client é integrado à inferência do AI gateway e dá suporte para pensamento profundo, pesquisa e conversa por texto. Recursos multi-modais, como envio de imagens e áudio estão em desenvolvimento. Você pode personalizar a interface do seu chat client com CSS e JavaScript personalizado, além de poder escolher a linguagem dos recursos do chat. Criar uma sessão de chat Uma sessão de chat é onde você cria uma conversa entre seu chat client e o usuário. Você pode chamar esse endpoint informando contexto adicional para conversa, como o nome do usuário, onde ele está, etc. Uma sessão de chat expira após algum tempo por segurança do token de acesso gerado. Quando você chama esse endpoint informando uma tag você pode chamar o mesmo endpoint várias vezes e obter a sessão de chat que está ativa para a tag informada, ou criar um chat novo se não existir uma sessão em andamento. Quando uma sessão é encontrada no cliente de chat através da tag informada, a sessão é renovada pelo período informado e o contexto é atualizado. Uma sessão de chat também restaura todas as mensagens da conversa da mesma sessão após desconexão. O usuário pode limpar a conversa ao clicar no botão de limpar conversa no canto superior direito do cliente de chat. Essa sessão usa os limites definidos pelo cliente de chat, como máximo de mensagens e tokens na conversa. Se uma sessão estiver próxima de expirar, ela é renovada por mais 20 minutos na próxima mensagem do usuário. POST /api/v1/web-chat-client/{chat-client-id}/sessions { // Tempo em segundos para o chat expirar. O mínimo é 10 minutos. O máximo é 30 dias. \"expires\": 3600, // Opcional. Contexto adicional para a IA sobre o chat. \"extraContext\": \"# Contexto adicional\\r\\n\\r\\nVocê está falando com Eduardo.\", // Opcional. Fornece um endpoint para a sessão obter contexto adicional. Esse endpoint é chamado em toda mensagem enviada pelo usuário, atualizada em tempo real sem qualquer cache. \"contextLocation\": \"https://example.com/context.txt\", // Opcional (recomendado). Um id externo para identificar a sessão posteriormente e reaproveitá-la sempre que chamar o mesmo endpoint. Pode ser o ID do usuário do seu banco de dados ou uma string que facilite a identificação desse chat posteriormente. \"tag\": \"my-user-tag\", // Opcional. Metadata adicional para armazenar no cliente. Não visível para a assistente. \"metadata\": { \"foo\": \"bar\" } } Resposta { \"message\": null, \"data\": { // ID da sessão de chat criada \"sessionId\": \"01966f0b-172d-7bbc-9393-4273b86667d2\", // Chave pública de acesso do chat \"accessKey\": \"wky_gr5uepjsgrhuqcj3aaat1iagrsmozwr9gghusnnu6zjhrsyures5xoe\", // A URL pública para conversar com o chat \"talkUrl\": \"https://console.aivax.net/chat/wky_gr5uepjsgrhuqcj3aaat1iagrsmozwr9gghusnnu6zjhrsyures5xoe\" } } Sessões de integrações A AIVAX fornece duas integrações para clientes de chat: Telegram e WhatsApp (através do Z-Api). Cada conversa em um aplicativo é uma sessão individual, identificada pelo ID da conversa ou número de telefone do usuário. Essas sessões obedecem as regras do chat client original. Além disso, sessões de chat nessas integrações possuem dois comandos especiais: /reset: limpa o contexto atual da sessão. /usage: quando debug está ativo no chat client, exibe o uso atual do chat em tokens."
  },
  "docs/entities/collections.html": {
    "href": "docs/entities/collections.html",
    "title": "Coleções | AIVAX",
    "keywords": "Coleções Uma coleção é uma biblioteca de conhecimento: ela abriga vários documentos de conhecimento. Use coleções para agrupar documentos por finalidade, como documentar um produto, uma empresa, um serviço ou fluxo. Coleções não produzem custo. Não há limite de coleções por conta. Criar uma coleção Para criar uma coleção vazia, informe apenas o nome dela: Requisição POST /api/v1/collections { // O nome da coleção não pode ser vazio. \"collectionName\": \"Minha primeira coleção\" } Resposta { \"message\": null, \"data\": { // ID único da coleção criada. \"collectionId\": \"01965b62-17c4-7258-9aa8-af5139799527\" } } Listar coleções Lista as coleções disponíveis na sua conta. Requisição GET /api/v1/collections Resposta { \"message\": null, \"data\": { \"pageInfo\": { \"currentPage\": 1, \"hasMoreItems\": true }, \"items\": [ { \"id\": \"01965b62-17c4-7258-9aa8-af5139799527\", \"createdAt\": \"2025-04-22T02:44:37\", \"name\": \"Minha coleção\" }, { \"id\": \"01965b54-7fbd-70cd-982b-604de002ac0a\", \"createdAt\": \"2025-04-22T02:29:46\", \"name\": \"Outra coleção\" } ] } } Ver uma coleção Obtém detalhes de uma coleção, como seu progresso de indexação e informações como data de criação. Requisição GET /api/v1/collections/{collection-id}/ Resposta { \"message\": null, \"data\": { \"name\": \"Minha coleção\", \"createdAt\": \"2025-04-22T02:29:46\", \"state\": { // traz a quantidade de documentos aguardando indexação \"queuedDocuments\": 0, // quantidade de documentos pronto para consulta \"indexedDocuments\": 227 }, \"tags\": [ \"tag1\", \"tag2\", \"tag3\", ... ] } } Excluir uma coleção Exclui uma coleção e todos os documentos nela. Essa ação é irreversível. Requisição DELETE /api/v1/collections/{collection-id}/ Resposta { \"message\": \"Collection deleted successfully.\", \"data\": null } Limpar uma coleção Diferente da exclusão de coleção, essa operação remove todos os documentos da coleção, incluindo os indexados e os em fila. Requisição DELETE /api/v1/collections/{collection-id}/reset-only Resposta { \"message\": \"Collection cleaned successfully.\", \"data\": null }"
  },
  "docs/entities/documents.html": {
    "href": "docs/entities/documents.html",
    "title": "Documentos | AIVAX",
    "keywords": "Documentos Um documento representa um pedaço de um conhecimento. É um trecho limitado, autosuficiente e que faça sentido de forma isolada. Um documento é o componente que é indexado pelo modelo interno para ser recuperado posteriormente através de um termo de busca semântico. Considere um manual sobre um carro: ele não é um documento mas sim vários documentos. Cada um destes documentos fala, de forma isolada, sobre um determinado assunto sobre esse carro, de forma que esse documento não dependa de um contexto ou informação externa para fazer sentido. Cada documento deste manual irá falar de um assunto: um irá falar sobre como ligar o carro, outro de como desligá-lo, outro de como sua pintura é feita e outro de como trocar o óleo periodicamente. Não é uma boa ideia reservar um documento para falar de várias coisas ao mesmo tempo, pois isso irá reduzir a objetividade e escopo da inferência e reduzir a qualidade de obtenção. Exemplos de criação de documentos: ❌ Não faça Não crie documentos muito curtos (com 10 ou menos palavras). Não crie documentos muito grandes (com 700) ou mais palavras. Não fale sobre mais de uma coisa em um documento. Não misture linguas diferentes em documentos. Não seja implícito em documentos. Nâo escreva documentos usando linguagem técnica, como códigos ou estruturas como JSON. ✅ Faça Seja explícito sobre o objetivo do seu documento. Foque documentos em assuntos individuais, que resumam o que deve ser feito ou explicado. Sempre repita termos que são palavras-chave para a busca do documento. Exemplo: prefira usar \"A cor do Honda Civic 2015 é amarela\" ao invés de \"a cor do carro é amarelo\". Restrinja o conteúdo do documento para falar de apenas um tópico ou assunto. Use uma linguagem humana, simples e fácil de entender. Uso da API Como todos os documentos são entidades que pertencem à uma coleção, sempre tenha em mãos a coleção de onde o documento está/será localizado. Enviar documentos em lote Para enviar uma lista em massa de documentos para uma coleção, estruture-os seguindo o formato JSONL. A estrutura do arquivo de indexação é: {\"docid\":\"Carros/HondaCivic2015.rmd:1\",\"text\":\"O Honda Civic 2015 está disponível em [...]\",\"__ref\":null,\"__tags\":[\"Carros\",\"Honda-Civic-2015\"]} {\"docid\":\"Carros/HondaCivic2015.rmd:2\",\"text\":\"O motor do Honda Civic 2015 é [...]\",\"__ref\":null,\"__tags\":[\"Carros\",\"Honda-Civic-2015\"]} {\"docid\":\"Carros/HondaCivic2015.rmd:3\",\"text\":\"A cor do Honda Civic 2015 é Amarela [...]\",\"__ref\":null,\"__tags\":[\"Carros\",\"Honda-Civic-2015\"]} ... A estrutura é compsta pelas propriedades: Propriedade Tipo Descrição docid string Especifica o nome do documento. Útil para depuração e identificação. text string O conteúdo \"cru\" do documento que será indexado. __ref string Opcional. Especifica um ID de referência do documento. __tags string[] Opcional. Especifica um array de tags do documento. Útil para gestão de documentos. A referência de um documento é um ID que pode ser especificado em vários documentos que precisam estar vinculados em uma busca quando um dos mesmos for correspondido em uma busca de similaridade. Por exemplo, se uma busca encontrar um documento que possui um ID de referência, todos os outros documentos da mesma coleção que compartilham o mesmo ID de referência do documento correspondido também serão incluídos na resposta da busca. O uso de referências pode ser útil para quando um documento depende de outro ou mais documentos para fazer sentido. Não há exigência de formato para o ID de referência: qualquer formato é aceito. Você pode enviar até 1.000 linhas de documentos por requisição. Se precisar enviar mais documentos, separe o envio em mais requisições. Se você enviar um documento com mais de 1.000 linhas, as linhas seguintes serão ignoradas. Vale notar que documentos muito longos, que excede a quantidade de tokens permitida no modelo de embedding interno, terão seu conteúdo truncado e a qualidade de indexação poderá ser gravemente afetada. Para evitar esse problema, envie documentos que contenham entre 20 e 700 palavras. Warning Atenção: esse endpoint gera custo. O custo é calculado em cima dos tokens do conteúdo de cada documento. O conteúdo de cada documento é tokenizado de acordo com o modelo usado na indexação dos documentos. Requisição O envio deve ser feito usando multipart form data. POST /api/v1/collections/{collection-id}/documents documents=[documents.jsonl] Resposta { \"message\": null, \"data\": [ { \"name\": \"Institucional/Empresa.rmd:1\", \"documentId\": \"01965f93-a36b-7fc2-9e6a-c733f4955927\" }, { \"name\": \"Institucional/Empresa.rmd:2\", \"documentId\": \"01965f93-a390-79d3-9b3d-338d407f6b64\" }, { \"name\": \"Institucional/Empresa.rmd:3\", \"documentId\": \"01965f93-a391-79ef-adcf-737d98303a78\" }, { \"name\": \"Produtos/Agendamentos.rmd:1\", \"documentId\": \"01965f93-a391-712e-9292-c4d8e010bf42\" }, ... ] } Criar ou modificar documento Esse endpoint cria ou modifica um documento a partir do seu nome. Quando um documento é modificado, seus vetores de indexação são resetados, isto é, o documento entrará em fila novamente para ser indexado pelo motor de indexação. Essa indexação não é isenta de custo. O custo é relativo à quantidade de tokens do conteúdo enviado. O custo somente é gerado quando o documento é de fato alterado. Chamar essa rota com o mesmo conteúdo do documento não gera modificação, portanto, não gera custo. Warning Atenção: esse endpoint gera custo. O custo é calculado em cima dos tokens do conteúdo do arquivo. O conteúdo do arquivo é tokenizado de acordo com o modelo usado na indexação dos documentos. Requisição PUT /api/v1/collections/{collection-id}/documents { // o nome do documento que será modificado \"name\": \"document-name\", // o conteúdo do documento que será criado ou sobreposto caso o nome já exista \"contents\": \"Conteúdo do meu documento\", // parâmetros explicados anteriormente \"reference\": null, \"tags\": [\"products\", \"my-product\"] } Resposta { \"message\": null, \"data\": { \"documentId\": \"0196663c-3a15-72c7-98e6-b496f8e8bb8c\", // o estado da operação indica se o documento foi modificado \"Modified\" ou criado \"Created\". Sempre virá apenas um valor no array. \"state\": [\"Modified\"] } } Listar documentos Esse endpoint lista todos os documentos disponíveis em uma coleção. Você pode passar um parâmetro da query adicional filter para filtrar documentos por nome, tag ou conteúdo. Esse filtro suporta expressões que auxiliam a filtrar o que você está procurando: -t \"tag\" - filtra documentos que possuem essa tag. -r \"reference\" - filtra documentos que possuem esse ID de referência. -c \"content\" - filtra documentos que possuem esse trecho em seu conteúdo. -n \"name\" - filtra documentos que possuem esse trecho em seu nome. Requisição GET /api/v1/collections/{collection-id}/documents Resposta { \"message\": null, \"data\": { \"pageInfo\": { \"currentPage\": 1, \"hasMoreItems\": true }, \"items\": [ { \"id\": \"01968452-69f6-7f00-a497-d14c5b906b79\", \"name\": \"Ajuda/Clientes.rmd:1\", \"reference\": null, \"tags\": [ \"Ajuda\", \"Clientes\" ], \"contentsPreview\": \"Um cliente é um cadastro na sua platafor...\", \"indexState\": [\"Indexed\"] }, { \"id\": \"01968452-6a53-7ce3-adad-fad32d508856\", \"name\": \"Ajuda/Clientes.rmd:2\", \"reference\": null, \"tags\": [ \"Ajuda\", \"Clientes\" ], \"contentsPreview\": \"No cadastro do cliente, é possível modif...\", \"indexState\": [\"Indexed\"] }, ... ] } } Ver documento Vê detalhes sobre um documento específico. Requisição GET /api/v1/collections/{collection-id}/documents/{document-id} Resposta { \"message\": null, \"data\": { \"id\": \"01965f93-a36b-7fc2-9e6a-c733f4955927\", \"name\": \"Institucional/Empresa.rmd:1\", // representa a situação de indexação do documento. // valores válidos: Queud, Indexed, Cancelled \"state\": [\"Indexed\"], // conteúdo do documento indexado \"contents\": \"...\", // id da referência do documento \"reference\": \"institucional-empresa\" } } Excluir documento Permanentemente exclui um documento através do seu ID. Requisição DELETE /api/v1/collections/{collection-id}/documents/{document-id} Resposta { \"message\": \"Document removed.\", \"data\": null }"
  },
  "docs/entities/functions.html": {
    "href": "docs/entities/functions.html",
    "title": "Funções | AIVAX",
    "keywords": "Funções Funções é uma forma de forçar seu modelo ao processamento de informações usando JSON como intermédio de comunicação. Com as funções, você consegue fazer qualquer modelo responder no formato JSON que você quiser. Pode ser útil para categorizar comentários, aplicar moderação em avaliações ou processar informações com auxílio da IA. No momento, só é possível usar funções com modelos providos pela AIVAX. Chamar uma função Para chamar uma função de IA, você precisará informar o que a IA deverá responder e fornecer um JSON Schema que ela deverá seguir. Modelos menos inteligentes tendem a falhar a geração de JSON, gerando um documento inválido ou problemático. Para isso, ajuste seu modelo, a instrução e o parâmetro de tentativas se for necessário. Você é cobrado por cada tentativa que a IA tentar gerar. Modelos um pouco mais inteligentes tendem a gerar resultados corretos na primeira tentativa. É garantido que um JSON válido será gerado e que esse JSON seguirá o mesmo esquema fornecido na requisição. Considere usar um cache do lado da sua aplicação para dados que não precisam ser constantementes atualizados, como dados meteorológicos, estatísticas diárias, etc. A AIVAX não realiza nenhum cache pelo nosso lado. Requisição POST /api/v1/functions/json { // Obrigatório. Especifique o nome do modelo integrado que será usado para realizar a ação. \"modelName\": \"@metaai/llama-3.1-8b\", // Obrigatório. Explique o que seu modelo deverá fazer com a entrada e como ele deve trazer a resposta. \"instructions\": \"Classifique o comentário do usuário, indicando se é positivo ou negativo, e se possui alguma informação relevante (número entre 0 (pouco relevante) e 10 (muito relevante))\", // Obrigatório. O JSON Schema que o modelo deverá seguir para gerar a resposta. Você pode fornecer exemplos de geração no campo de instruções. \"responseSchema\": { \"type\": \"object\", \"properties\": { \"feedbackType\": { \"type\": \"string\", \"enum\": [\"neutral\", \"positive\", \"negative\"] }, \"informationScore\": { \"type\": \"integer\", \"minimum\": 0, \"maximum\": 10 } }, \"required\": [\"feedbackType\", \"informationScore\"] }, // Opcional. Define uma entrada JSON para o modelo. Pode ser qualquer tipo de valor JSON. \"inputData\": { \"userComment\": \"Pessimo mercado. Tem guarda dentro te vigiando pra vc nao roubar e os acougueiros te ignoram e atendem mocinhas bonitinhas na tua frente. Mas graças a Deus tem outros mercados chegando e o fim dessa palhaçada vai chegar\" }, // Opcional. Define quantas tentativas o modelo deve tentar antes da API retornar um erro. Deve ser um número entre 1 e 30. \"maxAttempts\": 10, // Opcional. Define o tempo limite em segundos para obter um JSON válido antes da API retornar um erro. Deve ser um número entre 1 e 3600 (uma hora). \"timeout\": 300, // Opcional. Define a temperatura de geração do JSON. Valores maiores tendem a serem mais criativos, enquanto menores mais determinísticos. Número de 0 à 2. \"temperature\": 0.4, // Opcional. Fornece contexto adicional para a geração através de mensagens no formato chat/completions. Você pode fornecer conteúdo multi-modalidades também para modelos compatíveis. \"context\": [ { \"role\": \"user\", \"content\": \"Additional context\" } ], // Opcional. Fornece funções embutidas da AIVAX para a geração da ferramenta. \"tools\": [ \"WebSearch\", \"Code\", \"OpenUrl\", \"ImageGeneration\", \"XPostsSearch\" ], // Opcional. Define parâmetros de geração de ferramentas. \"toolsOptions\": { \"webSearchMode\": \"Full\" | \"Summarized\", \"webSearchMaxResults\": 10, \"imageGenerationMaxResults\": 2, \"imageGenerationQuality\": \"Low\" | \"Medium\" | \"High\" | \"Highest\", \"imageGenerationAllowMatureContent\": false }, // Opcional. Metadata adicional da função. Não visível para a assistente. \"metadata\": { \"foo\": \"bar\" } } Resposta { \"result\": { \"requiresAttention\": true, \"shortSummary\": \"Customer threatens cancellation and bad publicity if not contacted today.\" }, \"attempt\": 0, \"elapsedMilliseconds\": 1235, \"warnings\": [], \"context\": { \"generatedUsage\": [ { \"sku\": \"inference.functions.json.in\", \"amount\": 0.0000123, \"unitPrice\": 1e-7, \"quantity\": 123, \"description\": \"JSON function rendering (@google/gemini-2.0-flash)\" }, { \"sku\": \"inference.functions.json.out\", \"amount\": 0.0000116, \"unitPrice\": 4e-7, \"quantity\": 29, \"description\": \"JSON function rendering (@google/gemini-2.0-flash)\" } ], \"runnedFunctions\": [] } } Diretrizes do JSON Schema O formato de resposta deve ser fornecido por um JSON Schema. Por trás dos panos, a AIVAX guia o modelo para gerar uma resposta com o esquema JSON fornecido. Quando o modelo gera algo inválido, indicamos à ele tentar novamente e corrigir os erros até que a saída esteja conforme a especificação fornecida. As diretrizes suportadas do JSON Schema da AIVAX são: string: minLength maxLength pattern format Pode ser date-time, email, time, duration, uri, url, ipv4, ipv6, uuid ou guid. enum number e integer: minimum maximum exclusiveMinimum exclusiveMaximum multipleOf array items uniqueItems minItems maxItems object properties required bool e boolean null Além disso, é possível informar um ou mais valores no type do objeto, exemplo: { \"type\": [\"string\", \"number\"] } Nota: number e integer são sinônimos e integer não garante que o número será um inteiro. Funções em ferramentas É possível usar ferramentas embutidas as funções JSON. Isso irá permitir que o modelo chame funções para obter contexto necessário para gerar o JSON final. Exemplos Confira exemplos de funções de IA para várias tarefas cotidianas: Classificar comentários bons ou ruins POST /api/v1/functions/json { \"modelName\": \"@google/gemini-2.0-flash\", \"instructions\": \"Classifique o comentário do usuário fornecendo uma nota para seu comentário.\", \"inputData\": { \"inputText\": \"A comida é boa, mas o ambiente é muito barulhento e um pouco sujo também.\" }, \"responseSchema\": { \"type\": \"object\", \"properties\": { \"commentSummary\": { \"type\": \"string\", \"description\": \"Resumo do que o usuário quis dizer.\" }, \"score\": { \"type\": \"integer\", \"min\": 1, \"max\": 5, \"description\": \"A nota extraída da avaliação, sendo 1 muito ruim e 5 muito bom.\" } }, \"required\": [ \"commentSummary\", \"score\" ] } } { \"result\": { \"commentSummary\": \"The food is good, but the environment is noisy and a bit dirty.\", \"score\": 3 }, \"attempt\": 0, \"elapsedMilliseconds\": 788, \"warnings\": [], \"context\": { \"generatedUsage\": [ { \"sku\": \"inference.functions.json.in\", \"amount\": 0.0000083, \"unitPrice\": 1e-7, \"quantity\": 83, \"description\": \"JSON function rendering (@google/gemini-2.0-flash)\" }, { \"sku\": \"inference.functions.json.out\", \"amount\": 0.0000128, \"unitPrice\": 4e-7, \"quantity\": 32, \"description\": \"JSON function rendering (@google/gemini-2.0-flash)\" } ], \"runnedFunctions\": [] } } Avaliar uma expressão matemática POST /api/v1/functions/json { \"modelName\": \"@qwen/qwen3-32b\", \"instructions\": \"Evaluate the given math problem and provide the result step-by-step.\", \"inputData\": { \"inputText\": \"what is two plus two minus pi ?\" }, \"responseSchema\": { \"type\": \"object\", \"properties\": { \"steps\": { \"type\": \"array\", \"items\": { \"type\": \"object\", \"properties\": { \"stepDescription\": { \"type\": \"string\", \"description\": \"Current math step description.\" }, \"carry\": { \"type\": \"number\", \"description\": \"The current result.\" } }, \"required\": [ \"stepDescription\", \"carry\" ] }, \"minItems\": 1 }, \"finalResult\": { \"type\": \"number\", \"description\": \"The math operation final result.\" } }, \"required\": [ \"steps\", \"finalResult\" ] }, \"tools\": [ \"Code\" ] } { \"result\": { \"steps\": [ { \"stepDescription\": \"Add 2 and 2\", \"carry\": 4 }, { \"stepDescription\": \"Subtract pi (π) from the result\", \"carry\": 0.858407346410207 } ], \"finalResult\": 0.858407346410207 }, \"attempt\": 0, \"elapsedMilliseconds\": 5775, \"warnings\": [], \"context\": { \"generatedUsage\": [ { \"sku\": \"inference.functions.json.in\", \"amount\": 0.00031001, \"unitPrice\": 2.9e-7, \"quantity\": 1069, \"description\": \"JSON function rendering (@qwen/qwen3-32b)\" }, { \"sku\": \"inference.functions.json.out\", \"amount\": 0.00054162, \"unitPrice\": 5.9e-7, \"quantity\": 918, \"description\": \"JSON function rendering (@qwen/qwen3-32b)\" } ], \"runnedFunctions\": [ { \"functionName\": \"evaluate_code\", \"success\": true, \"context\": { \"arguments\": \"console.log(2 + 2 - Math.PI);\", \"result\": { \"evaluatedCode\": \"console.log(2 + 2 - Math.PI);\", \"result\": \"0.8584073464102069\\nScript evaluation result: undefined\\n\" } } } ] } } Trazer últimas notícias e clima de uma determinada cidade POST /api/v1/functions/json { \"modelName\": \"@openai/gpt-4o-mini\", \"instructions\": \"Search for the 5 latest news and weather data for the given city.\", \"inputData\": { \"city\": \"Tokyo\" }, \"responseSchema\": { \"type\": \"object\", \"properties\": { \"latestNews\": { \"type\": \"array\", \"items\": { \"type\": \"object\", \"properties\": { \"title\": { \"type\": \"string\" }, \"details\": { \"type\": \"string\" }, \"link\": { \"type\": \"string\", \"format\": \"uri\" } }, \"required\": [ \"title\", \"details\", \"link\" ], \"additionalProperties\": false } }, \"weather\": { \"type\": \"object\", \"properties\": { \"currentTemperature\": { \"type\": \"number\" }, \"currentWeather\": { \"type\": \"string\", \"enum\": [ \"sunny\", \"cloudy\", \"rain\", \"thunderstorm\" ] }, \"forecast\": { \"type\": \"string\", \"enum\": [ \"sunny\", \"cloudy\", \"rain\", \"thunderstorm\" ] } }, \"required\": [ \"currentTemperature\", \"currentWeather\", \"forecast\" ], \"additionalProperties\": false }, \"assistantSummary\": { \"type\": \"string\" } }, \"required\": [ \"latestNews\", \"weather\", \"assistantSummary\" ], \"additionalProperties\": false }, \"tools\": [ \"XPostsSearch\", \"WebSearch\" ] } { \"result\": { \"latestNews\": [ { \"title\": \"Indian Ambassador to Japan Expands Cooperation\", \"details\": \"Indian Ambassador to Japan Sibi George expressed eagerness to expand cooperation between India and Japan in business, technology, and security.\", \"link\": \"https://japannews.yomiuri.co.jp/\" }, { \"title\": \"Emperor Emeritus Akihito Discharged from Hospital\", \"details\": \"Japan’s Emperor Emeritus Akihito was discharged from the University hospital.\", \"link\": \"https://www.japantimes.co.jp/\" }, { \"title\": \"Tokyo Stocks Climb Following Wall Street Gains\", \"details\": \"Tokyo stocks climbed in the morning following Wall Street gains.\", \"link\": \"https://www.independent.co.uk/topic/tokyo\" }, { \"title\": \"Tightening of Business Manager Visa Requirements\", \"details\": \"Tokyo is tightening requirements for popular business manager visas.\", \"link\": \"https://www.japantimes.co.jp/latest-news/\" }, { \"title\": \"ANA Plans Affordable Flying Taxi Service\", \"details\": \"ANA plans to launch an affordable flying taxi service in Japan by 2027.\", \"link\": \"https://www.japantimes.co.jp/\" } ], \"weather\": { \"currentTemperature\": 31, \"currentWeather\": \"cloudy\", \"forecast\": \"rain\" }, \"assistantSummary\": \"The latest news from Tokyo includes diplomatic and economic updates, while the current weather is partly cloudy with a temperature of 31°C.\" }, \"attempt\": 0, \"elapsedMilliseconds\": 19772, \"warnings\": [], \"context\": { \"generatedUsage\": [ { \"sku\": \"serviceusage.web_search\", \"amount\": 0.005, \"unitPrice\": 0.005, \"quantity\": 1, \"description\": \"Web Search request\" }, { \"sku\": \"serviceusage.web_search\", \"amount\": 0.005, \"unitPrice\": 0.005, \"quantity\": 1, \"description\": \"Web Search request\" }, { \"sku\": \"inference.functions.json.in\", \"amount\": 0.000453, \"unitPrice\": 1.5e-7, \"quantity\": 3020, \"description\": \"JSON function rendering (@openai/gpt-4o-mini)\" }, { \"sku\": \"inference.functions.json.out\", \"amount\": 0.0002406, \"unitPrice\": 6e-7, \"quantity\": 401, \"description\": \"JSON function rendering (@openai/gpt-4o-mini)\" } ], \"runnedFunctions\": [ { \"functionName\": \"web_search\", \"success\": true, \"context\": { \"arguments\": { \"search_term\": \"Tokyo weather\" }, \"result\": { \"results\": [ { \"title\": \"Search results\", \"url\": \"\" } ] } } }, { \"functionName\": \"web_search\", \"success\": true, \"context\": { \"arguments\": { \"search_term\": \"latest news in Tokyo\" }, \"result\": { \"results\": [ { \"title\": \"Search results\", \"url\": \"\" } ] } } } ] } } Trazer artistas em alta por gênero musical POST /api/v1/functions/json { \"modelName\": \"@openai/gpt-4.1-mini\", \"instructions\": \"A função deve pesquisar, usando os últimos posts do X, as plataformas de streaming musical (como Spotify, Apple Music etc.) e identificar os 10 artistas mais tocados no gênero informado pelo usuário. Em seguida, deve formatar um objeto contendo uma lista ordenada de 10 artistas, incluindo posição (1–10), nome e número estimado de streams.\", \"inputData\": { \"genre\": \"dubstep\" }, \"responseSchema\": { \"type\": \"object\", \"properties\": { \"artists\": { \"type\": \"array\", \"description\": \"Lista dos 10 artistas mais tocados no gênero especificado\", \"items\": { \"type\": \"object\", \"properties\": { \"rank\": { \"type\": \"integer\", \"description\": \"Posição no Top 10\", \"minimum\": 1, \"maximum\": 10 }, \"name\": { \"type\": \"string\", \"description\": \"Nome do artista\" }, \"monthlyStreams\": { \"type\": \"string\", \"description\": \"Número aproximado de streams mensais, formatado, ex: \\\"150M\\\"\" }, \"source\": { \"type\": \"string\", \"description\": \"Plataforma ou fonte de dados\" } }, \"required\": [ \"rank\", \"name\", \"monthlyStreams\", \"source\" ], \"additionalProperties\": false } } }, \"required\": [ \"artists\" ], \"additionalProperties\": false }, \"maxAttempts\": 4, \"temperature\": 1, \"tools\": [ \"XPostsSearch\", \"WebSearch\" ], \"toolsOptions\": {} } { \"result\": { \"artists\": [ { \"rank\": 1, \"name\": \"Skrillex\", \"monthlyStreams\": \"31M\", \"source\": \"Spotify\" }, { \"rank\": 2, \"name\": \"Virtual Riot\", \"monthlyStreams\": \"12M\", \"source\": \"Spotify\" }, { \"rank\": 3, \"name\": \"Excision\", \"monthlyStreams\": \"11M\", \"source\": \"Spotify\" }, { \"rank\": 4, \"name\": \"Zeds Dead\", \"monthlyStreams\": \"10M\", \"source\": \"Spotify\" }, { \"rank\": 5, \"name\": \"Flux Pavilion\", \"monthlyStreams\": \"9M\", \"source\": \"Spotify\" }, { \"rank\": 6, \"name\": \"Illenium\", \"monthlyStreams\": \"8.5M\", \"source\": \"Spotify\" }, { \"rank\": 7, \"name\": \"Rusko\", \"monthlyStreams\": \"7M\", \"source\": \"Spotify\" }, { \"rank\": 8, \"name\": \"Bassnectar\", \"monthlyStreams\": \"6M\", \"source\": \"Spotify\" }, { \"rank\": 9, \"name\": \"Seven Lions\", \"monthlyStreams\": \"5.5M\", \"source\": \"Spotify\" }, { \"rank\": 10, \"name\": \"Getter\", \"monthlyStreams\": \"5M\", \"source\": \"Spotify\" } ] }, \"attempt\": 0, \"elapsedMilliseconds\": 11243, \"warnings\": [], \"context\": { \"generatedUsage\": [ { \"sku\": \"serviceusage.x_api.search\", \"amount\": 0.005, \"unitPrice\": 0.005, \"quantity\": 1, \"description\": \"X Posts search\" }, { \"sku\": \"inference.functions.json.in\", \"amount\": 0.0016448, \"unitPrice\": 4e-7, \"quantity\": 4112, \"description\": \"JSON function rendering (@openai/gpt-4.1-mini)\" }, { \"sku\": \"inference.functions.json.out\", \"amount\": 0.0006272, \"unitPrice\": 0.0000016, \"quantity\": 392, \"description\": \"JSON function rendering (@openai/gpt-4.1-mini)\" } ], \"runnedFunctions\": [ { \"functionName\": \"x_posts_search\", \"success\": true, \"context\": { \"arguments\": { \"search_query\": \"dubstep artists Spotify OR Apple Music OR streaming\" }, \"result\": [ { \"url\": \"https://x.com/nathanielblow/status/1867148757466304607\", \"text\": \"NOW LIVE ON APPLE MUSIC. SPOTIFY. YOUTUBE MUSIC.\\n\\nEnjoy. https://t.co/apUxnXc7IE\", \"authorUserName\": \"nathanielblow\", \"createdAt\": \"2024-12-12T10:05:28\" }, { \"url\": \"https://x.com/yobrxxzy/status/1754800896041505222\", \"text\": \"MOST STREAMED ARTISTS ON THESE STREAMING PLATFORMS 🇳🇬\\n\\nApple Music — WIZKID\\nSpotify — WIZKID\\nYouTube — BURNA BOY\\nPandora — WIZKID\\nTidal — WIZKID\\nLine Music — WIZKID\\nAudiomack — ASAKE\\nDeezer — WIZKID\\nBoomplay — BURNA BOY\\nSoundCloud — BURNA BOY\\nShazam — WIZKID https://t.co/Nm2jO5R5P6\", \"authorUserName\": \"yobrxxzy\", \"createdAt\": \"2024-02-06T09:35:10\" }, { \"url\": \"https://x.com/yobrxxzy/status/1922763266549301642\", \"text\": \"MOST STREAMED ARTISTS ON THESE DSP:\\n\\nApple Music — WIZKID\\nSpotify — WIZKID\\nPandora — WIZKID\\nYouTube — BURNA BOY\\nTidal — WIZKID\\nLine Music — WIZKID\\nAudiomack — ASAKE\\nDeezer — WIZKID\\nBoomplay — BURNA BOY\\nDeezer — WIZKID\\nAnghami — REMA\\nSoundCloud — BURNA BOY\\nShazam — WIZKID\\n\\n🐐 https://t.co/3aUCGbYiEO\", \"authorUserName\": \"yobrxxzy\", \"createdAt\": \"2025-05-14T21:17:40\" }, { \"url\": \"https://x.com/yobrxxzy/status/1856816512524587343\", \"text\": \"MOST STREAMED ARTISTS ON THESE DSP:\\n\\nApple Music — WIZKID\\nSpotify — WIZKID\\nYouTube — BURNA BOY\\nPandora — WIZKID\\nTidal — WIZKID\\nLine Music — WIZKID\\nAudiomack — ASAKE\\nDeezer — WIZKID\\nBoomplay — BURNA BOY\\nDeezer — WIZKID\\nAnghami — REMA\\nSoundCloud — BURNA BOY\\nShazam — WIZKID\\n\\n🐐 https://t.co/yL2tmJJpHM\", \"authorUserName\": \"yobrxxzy\", \"createdAt\": \"2024-11-13T21:48:49\" }, { \"url\": \"https://x.com/hourjinnie/status/1858756269902881208\", \"text\": \"PLAYLISTS! Let’s get to streaming and utilize all our tools! More pl coming tomorrow!!!\\n\\nSPOTIFY\\n\\nhttps://t.co/L0HRMpYEQG\\n\\nhttps://t.co/HmhdB859e5\\n\\nhttps://t.co/FA4eDmvvkS\\n\\nhttps://t.co/ZOedbxiKmO\\n\\nhttps://t.co/DyPs0qpOMQ\\n\\nDeezer\\n\\nhttps://t.co/36PY8aXkV7\\n\\nApple Music \\n\\nhttps://t.co/wk5MXtzDYC\\n\\nhttps://t.co/OgovuVtoDq\\n\\nPandora \\n\\nhttps://t.co/idkimHTTjp\\n\\nhttps://t.co/WQ83YKeUOK\", \"authorUserName\": \"hourjinnie\", \"createdAt\": \"2024-11-19T06:16:43\" }, { \"url\": \"https://x.com/yobrxxzy/status/1653723618944090112\", \"text\": \"MOST STREAMED ARTISTS ON THESE STREAMING PLATFORMS:\\n\\nApple Music — WIZKID\\nSpotify — WIZKID\\nYouTube — BURNA BOY\\nPandora — WIZKID\\nTidal — WIZKID\\nAudiomack — BURNA BOY\\nDeezer — WIZKID\\nBoomplay — BURNA BOY\\nSoundCloud — WIZKID\\nShazam — WIZKID\\n\\nWhere is @davido ? https://t.co/JOcwJZ2HUU\", \"authorUserName\": \"yobrxxzy\", \"createdAt\": \"2023-05-03T11:30:10\" }, { \"url\": \"https://x.com/EyelanderMusic/status/1882525103482872115\", \"text\": \"YO IF YOU THINK DUBSTEP IS GETTING “STALE” \\n\\nGET THE HELL OFF OF SPOTIFY AND ON TO SOUNDCLOUD \\n\\nTHERE IS SOOO MUCH INSANE UNDERGROUND TALENT THAT RELEASE MOSTLY JUST TO SOUNDCLOUD. \\n\\n(Plus that’s usually where all showcases, remixes and flips are for copyright purposes)\", \"authorUserName\": \"EyelanderMusic\", \"createdAt\": \"2025-01-23T20:25:34\" }, { \"url\": \"https://x.com/thisiscyclops/status/1815084003050791422\", \"text\": \"i like that more dubstep artists are doing albums this year. like i know it’s not the best release move in 2024 but that kinda lets you know that they’re doing it out of love for the music rather than like the Best Spotify Strategy 👍\", \"authorUserName\": \"thisiscyclops\", \"createdAt\": \"2024-07-21T17:58:43\" }, { \"url\": \"https://x.com/mewaolix/status/1886435921895235989\", \"text\": \"Stays, we can easily reach #3 if we push a little 🥹\\n\\n(DSP counts Spotify, Apple Music, Amazon Music, Deezer, YT Music, Anghami, Gaana, Joox, Melon, JioSaavn, Boomplay, etc) https://t.co/P2hFoSmbtT\", \"authorUserName\": \"mewaolix\", \"createdAt\": \"2025-02-03T15:25:46\" }, { \"url\": \"https://x.com/bhadext/status/1951588819561546145\", \"text\": \"Listen to my songs on Apple music, 🙏\\nBhadext \\n\\nHere: https://t.co/3u79BQvHAZ https://t.co/lmMjN7m2oR\", \"authorUserName\": \"bhadext\", \"createdAt\": \"2025-08-02T10:20:08\" }, { \"url\": \"https://x.com/runthismusic/status/1853150149788209234\", \"text\": \"What if 'Sticky' by @tylerthecreator was Dubstep? \\nOUT NOW ON SC + FREE DL 💚💿\\n@skybreakedm https://t.co/OjaU8um8GC\", \"authorUserName\": \"runthismusic\", \"createdAt\": \"2024-11-03T19:00:00\" }, { \"url\": \"https://x.com/BTStreamingID/status/1953425910612320348\", \"text\": \"Party start 🎉\\n\\nPlaylist 🎶\\n\\nSpotify : \\n1.Premium: https://t.co/qJwpckiSlS\\n2. Free: https://t.co/NqIV40psvp\\nApple music: https://t.co/dblVEdcd1q\\nYouTube: https://t.co/gmCR3oyfze \\nYouTube Music: https://t.co/xhxF2rt90o\\n\\n#BTS #방탄소년단 #PTD_ON_STAGE_LIVE\\n#BangtanPlaylistID\", \"authorUserName\": \"BTStreamingID\", \"createdAt\": \"2025-08-07T12:00:04\" }, { \"url\": \"https://x.com/NewEDMToday/status/1728069779066392828\", \"text\": \"@FlatlandFunk_ @FrankieSinn2k @gabybaumusic @Gladez @grislymusik @HELOSPHEREmusic @HUMANSION_music @kausedubs @Kuhlosul_ @LazrusOfficial @SHEISLUTHIEN @LVCiDdubz @MagMag_dubstep @MVSLOTUNES @raddixofficial @RazrDub @ScarexxDub @SmilesOnlyMusic @soulvalient @SpeedShift6 @stvnkfvcemusic @itstoxicmusic @TremorrOfficial @TyphonOfficial @Verosdubz @voyagerdubz @wilco_beats @zovahofficial all been released on: @Emengy \\n\\ngenre of music: #edm #dubstep\\n\\nwith 30 tracks\\n\\n54 artists\\n\\nhttps://t.co/H9KmeiXJB4\", \"authorUserName\": \"NewEDMToday\", \"createdAt\": \"2023-11-24T15:15:15\" }, { \"url\": \"https://x.com/offsetemusic/status/1729861632308744501\", \"text\": \"i mostly use my local files to listen to music, but i'll share my spotify wrapped anyway\\n\\ni'm happy to see @canotodubz here as no. 1, he's one of the most unique dubstep artists i've discovered this year https://t.co/OUBhgtikn9\", \"authorUserName\": \"offsetemusic\", \"createdAt\": \"2023-11-29T13:55:27\" }, { \"url\": \"https://x.com/paulpoint_/status/1882728999962468414\", \"text\": \"Good Morning 🌞 \\n\\nEspecially, Electronic Music Artists\\n\\nUse any of these?\\n—Laptop \\n——MIDI Keyboard\\n———Software\\n\\nHow about these?\\n—Spotify\\n——Soundcloud\\n———Apple Music\\n\\nMaking sounds like these?\\n—House\\n——Techno\\n———Trance\\n————DnB? ...Dubstep??\\n\\nIf you answered yes to anything above and you are staying consistent\\n\\nIf you are incessantly networking and improving your use of the above, particularly for live\\n\\nThen you may well be taking home your slice of a $25 Bn dollar industry\\n\\nExcited? Well are you? Keep making sounds on your computer 🤝\\n\\nCan't wait to hear your next track!\\n\\nP.\", \"authorUserName\": \"paulpoint_\", \"createdAt\": \"2025-01-24T09:55:47\" }, { \"url\": \"https://x.com/Gunfingers_eu/status/1701277617280663828\", \"text\": \"Join Kaps on his bass music journey! From listener to passionate player, he's mastered the dubstep genre, sharing stages with many confirmed artists.\\nExpect a wealth of experience and skills for your enjoyment!\\n\\nSC : https://t.co/s5sqmIzrK6\\n\\nSpotify : https://t.co/o8bmaRXTNU https://t.co/6DVahvcr5D\", \"authorUserName\": \"Gunfingers_eu\", \"createdAt\": \"2023-09-11T16:52:46\" }, { \"url\": \"https://x.com/ballsackious/status/1714854867645149399\", \"text\": \"This new dirt monkey album is another\\nbeautiful example of dubstep artists \\nbranching out to other genres and sounds and creating something gorgeous and unique\\n\\nIt's so common now. So much good music is coming out I'm so pleased \\n\\nhttps://t.co/BJBXGa1Llz\", \"authorUserName\": \"ballsackious\", \"createdAt\": \"2023-10-19T04:03:55\" }, { \"url\": \"https://x.com/karmiclink/status/1951358837828509849\", \"text\": \"Our full karmic discography is LIVE in all major digital streaming platforms (Deezer, Spotify, Youtube, Apple Music, Amazon Music, TikTok, Tidal, Facebook &amp; Instagram for your stories &amp; reels)! ☯ #karmiclink #cult #dark #metal #project #rock #athens ☯ @TuneCore https://t.co/WWlVrUTVOc\", \"authorUserName\": \"karmiclink\", \"createdAt\": \"2025-08-01T19:06:16\" }, { \"url\": \"https://x.com/OneRougeWave/status/1953444705204588608\", \"text\": \"Oh yeah.. almost forgot😅.. \\nStream my music 🎶…\\n\\nhttps://t.co/mUNJL5AAGf\\n\\nhttps://t.co/aFqbVnuzZV\\n\\n#wavyboss https://t.co/c8mnh9mw3d\", \"authorUserName\": \"OneRougeWave\", \"createdAt\": \"2025-08-07T13:14:45\" } ] } } ] } }"
  },
  "docs/entities/search.html": {
    "href": "docs/entities/search.html",
    "title": "Pesquisa | AIVAX",
    "keywords": "Pesquisa A API de pesquisa, através da query key obtida das coleções, realiza uma busca semântica na mesma, realizando uma comparação inteligente para cada documento indexado em uma coleção. Após criar uma coleção, você obterá seu ID. Utilize o ID da sua coleção para realizar a busca nos documentos indexados da mesma. Use os endpoints dessa API para embutir a pesquisa semântica de documentos no seu modelo de IA ou chatbot. Pesquisando documentos Esse endpoint espera uma requisição GET com os parâmetros: term: obrigatório. Especifica o termo de pesquisa que será pesquisado nos documentos. top: Especifica o máximo de documentos que deverão ser retornados na busca. min: Especifica o score mínimo para obtenção dos documentos. Warning Atenção: esse endpoint gera custo. O custo é calculado em cima dos tokens do termo de busca. O termo de busca é tokenizado de acordo com o modelo usado na indexação dos documentos. Requisição GET /api/v1/collections/{collection-id}/query term=Qual a cor do honda CIVIC? Resposta { \"message\": null, \"data\": [ { \"documentId\": \"01965f93-a391-71a8-968a-47ccd4949de0\", \"documentName\": \"Produtos/Honda Civic 2015.rmd:1\", \"documentContent\": \"[...]\", \"score\": 0.7972834229469299, \"referencedDocuments\": [] }, { \"documentId\": \"01965f93-a391-76b3-bbf5-3fb74d10d412\", \"documentName\": \"Produtos/Honda Civic 2015.rmd:2\", \"documentContent\": \"[...]\", \"score\": 0.5693517327308655, \"referencedDocuments\": [] }, { \"documentId\": \"01965f93-a391-7026-b7aa-1cc6c63cd7d1\", \"documentName\": \"Produtos/Honda Civic 2015.rmd:5\", \"documentContent\": \"[...]\", \"score\": 0.5475733876228333, \"referencedDocuments\": [] }, ... ] } Para o resultado da busca, quanto maior o score, mais semelhante é o documento para o termo da busca. O AIVAX utiliza modelos de embedding que permitem a orientação da tarefa. Para a busca, o termo é vetorizado com uma orientação DOCUMENT_QUERY. Para indexação dos documentos, a orientação é DOCUMENT_RETRIEVAL, o que fornece uma busca mais otimizada e não para averiguar a similaridade entre documentos."
  },
  "docs/getting-started.html": {
    "href": "docs/getting-started.html",
    "title": "Bem-vindo | AIVAX",
    "keywords": "Bem-vindo Boas vindas ao AIVAX. Nosso serviço torna mais fácil o desenvolvimento de modelos de IA inteligentes que usam uma base de conhecimento providenciada por você para conversar com o usuário, responder perguntas, fornecer informações em tempo real e mais. Para começar, todos os endpoints devem ser feitos na URL de produção da AIVAX: https://inference.aivax.net/ Conceitos e definições Entenda os conceitos usados pela API abaixo: Conta: representa uma conta do usuário, que possui um token de autenticação. Coleção: representa uma coleção de documentos de conhecimento. Um usuário pode ter várias coleções de documentos. Documento: representa um fato, um único conhecimento e um item de uma coleção. Uma coleção pode ter vários documentos. AI Gateway: representa um gateway de IA que se beneficia ou não de uma coleção de conhecimento, como um middleware de conhecimento plug-and-play para um modelo. Modelo embutido: representa um modelo de IA que o AIVAX provê para o usuário. Chat client: representa uma interface de usuário que disponibiliza o AI gateway através de um chat interagível online. Sessão de chat: abriga uma conversa e contexto de um cliente de chat. Lidando com erros Todos os erros da API retornam uma resposta HTTP com um status não OK (nunca 2xx ou 3xx), e sempre seguindo o formato JSON: { \"error\": \"Uma mensagem explicando o erro\", \"details\": {} // um objeto contendo informações relevantes sobre o erro. Na maioria das vezes é nulo }"
  },
  "docs/legal/privacy-policy.html": {
    "href": "docs/legal/privacy-policy.html",
    "title": "Política de Privacidade | AIVAX",
    "keywords": "Política de Privacidade Versão: 1.1 Data de vigência: 05 de outubro de 2025 Última atualização anterior: 30 de julho de 2025 Bem-vindo à AIVAX. Esta Política de Privacidade descreve como a AIVAX coleta, utiliza, armazena, compartilha e protege informações em seus serviços de inferência de IA. Nosso compromisso é com transparência, segurança e conformidade com a Lei Geral de Proteção de Dados (LGPD) e o Marco Civil da Internet. Ao utilizar os serviços da AIVAX, o Gestor da Conta reconhece e concorda com os termos desta política. Esta política não constitui aconselhamento jurídico; recomendamos avaliação pelo departamento jurídico do Gestor. 1. Definições AIVAX: Empresa provedora da plataforma e dos serviços de orquestração de modelos de IA. Gestor da Conta AIVAX (\"Gestor\"): Pessoa física ou jurídica que cria e administra a conta e integra a API. Usuário Final: Indivíduo que interage com a aplicação do Gestor que consome a API AIVAX. Dados de Conta: Dados cadastrais e administrativos (ex.: nome, e-mail, empresa, cargo, identificadores internos, preferências, configurações de chave de API). Dados de Faturamento: Dados necessários a cobrança e notas (ex.: CNPJ/CPF, razão social, endereço, meios de pagamento através de processador terceirizado). Dados de Inferência: Entradas (prompts, texto, instruções, metadados) enviadas aos modelos e as saídas/inferências resultantes. (Equivalente aos termos \"Conteúdo de Entrada\" + \"Conteúdo Gerado\" definidos nos Termos de Uso.) Conversas: Conjunto estruturado de interações de Inferência (entrada + resposta + metadados de contexto). Metadados Técnicos: Logs de requisições, IP, timestamp, latência, identificadores de sessão, uso de tokens, códigos de resposta, assinaturas de segurança. Operadora: AIVAX quando processa dados segundo instruções do Gestor (dados de inferência/conversas). Controladora: AIVAX quando define finalidades para dados de conta, faturamento, segurança e compliance. Subprocessador: Terceiro contratado pela AIVAX para apoiar processamento (infraestrutura, monitoramento, billing, e-mail, provedores de modelo, etc.). 2. Papéis de Tratamento Tipo de Dado Papel da AIVAX Papel do Gestor Dados de Conta Controladora Titular/Controlador de sua própria relação interna Dados de Faturamento Controladora (cumprimento legal e contratual) Fornece/verifica Dados de Inferência / Conversas Operadora Controlador (define conteúdo e finalidade) Metadados Técnicos Controladora (segurança / melhoria) e Operadora (execução técnica) Controlador (origem) Quando atuar como Operadora, a AIVAX seguirá estritamente as instruções do Gestor, conforme chamadas de API e configurações de painel. Para coerência contratual, em caso de divergência terminológica entre esta política e os Termos de Uso, prevalecerá a equivalência: Dados de Inferência = Conteúdo de Entrada + Conteúdo Gerado. 3. Categorias de Dados Coletados Fornecidos diretamente pelo Gestor: Dados de Conta, credenciais (hash ou tokens), preferências, configurações de uso, organização, chaves de API geradas. Gerados pelo uso: Metadados técnicos (logs, estatísticas agregadas, contagem de tokens, latências, uso por modelo). Dados de Inferência e Conversas: Conteúdo textual e demais formatos enviados aos modelos e retornos. Suporte e Comunicação: Mensagens em tickets, e-mails enviados ao suporte ou canais de contato. Faturamento: Dados fiscais e de pagamento (processados em parte por terceiros especializados). Dados Agregados/Anonimizados: Métricas derivadas que não identificam o Gestor ou usuários finais. Não coletamos deliberadamente categorias especiais de dados pessoais sensíveis (art. 5º, II, LGPD) salvo se o Gestor optar por enviar nos Dados de Inferência. Nesse caso, o Gestor declara possuir base legal adequada e consentimento quando exigido. 4. Finalidades, Bases Legais e Retenção Categoria Finalidade Principal Base Legal (LGPD) Prazo Indicativo de Retenção* Dados de Conta Criação, gestão da conta, autenticação, comunicações operacionais Execução de contrato (art. 7º, V) Enquanto a conta estiver ativa + até 6 meses após encerramento (auditoria) Dados de Faturamento Cobrança, emissão fiscal, prevenção a fraudes (inclui regras de créditos, expiração e reembolsos – ver Termos de Uso) Obrigações legais (art. 7º, II) / Execução de contrato 5 a 10 anos (exigências fiscais) Metadados Técnicos Segurança, prevenção a abuso, monitoramento de desempenho Legítimo interesse (art. 7º, IX) + Execução de contrato 180 dias (logs principais) / até 1 ano (segurança estendida) Dados de Inferência Execução da inferência solicitada Execução de contrato Tempo operacional (padrão: até 30 dias) Conversas Histórico para monitoramento, auditoria técnica, depuração Legítimo interesse (balanceado) + Execução de contrato Até 30 dias (padrão) ou menor se configurado; exportáveis e excluíveis Suporte Resolver dúvidas, incidentes, compliance Execução de contrato / Legítimo interesse Até 12 meses após resolução Dados Agregados/Anonimizados Métricas de capacidade, melhoria de confiabilidade Fora do escopo da LGPD (dados anonimizados) Indeterminado (enquanto irreversivelmente anonimizados) *Os prazos podem ser encurtados mediante solicitação, exceto onde houver obrigação legal ou necessidade de defesa de direitos. Backups cifrados podem reter dados por até 90 dias adicionais até rotação completa; dados expurgados não retornam a produção após restauração, aplicando-se reprocessamento de exclusões. 5. Não Utilização para Treinamento Próprio A AIVAX não utiliza Dados de Inferência ou Conversas para treinar modelos proprietários, criar perfis de uso individualizados ou monetizar dados. Uso restrito à prestação do serviço contratado. 6. Armazenamento e Exclusão de Conversas O Gestor pode: (i) ajustar retenção (quando a funcionalidade existir), (ii) excluir conversas individualmente ou em lote, (iii) solicitar purga total. Exclusão é definitiva e irreversível em produção; registros podem persistir temporariamente em backups até a janela de retenção técnica. 7. Direitos dos Titulares (Art. 18, LGPD) Quando a AIVAX atuar como Controladora (ex.: dados de conta), os titulares podem exercer: confirmação de tratamento; acesso; correção; anonimização, bloqueio ou eliminação; portabilidade; informação sobre compartilhamentos; revogação de consentimento (se aplicável); oposição a tratamento baseado em legítimo interesse; revisão de decisões automatizadas. Canal: **privacy@aivax.net** ou **wm@aivax.net** (Encarregado). Prazo padrão de resposta: até 15 dias. Poderemos solicitar comprovação de identidade. Para dados em que atuamos como Operadora, direcionaremos o titular ao Gestor Controlador. 8. Encarregado (DPO) Encarregado pelo Tratamento (Art. 41): (Identidade anonimizada) – Contato: **wm@aivax.net**. Funções: canal de comunicação com titulares e ANPD, orientação interna de conformidade, suporte a avaliações de impacto. 9. Subprocessadores Utilizamos subprocessadores para: infraestrutura em nuvem, balanceamento, monitoramento de desempenho, e-mail transacional, faturamento, provedores de modelo, detecção de abuso. Publicaremos (ou já publicamos) lista atualizada em página dedicada: (link a adicionar). Notificaremos alterações materiais antes de entrada em vigor sempre que exigido contratualmente; o uso continuado após prazo de objeção razoável constitui aceitação. 10. Provedores de Modelos de Terceiros Ao selecionar um modelo específico, o Gestor também se sujeita às políticas do respectivo provedor. Alguns provedores podem usar dados de inferência para melhoria ou treinamento. O Gestor deve validar a adequação antes de enviar dados pessoais ou sensíveis. A AIVAX não controla políticas de terceiros e recomenda a leitura prévia. 11. Transferências Internacionais de Dados Dados podem ser processados ou armazenados em datacenters fora do Brasil (ex.: EUA, UE), utilizando provedores que adotam padrões de segurança alinhados às melhores práticas internacionais. Aplicamos: (i) contratos com cláusulas de proteção; (ii) criptografia; (iii) minimização; (iv) segregação lógica. Caso a transferência se enquadre em hipóteses específicas do art. 33, adotaremos salvaguardas contratuais e técnicas apropriadas. 12. Segurança da Informação (Camadas) Medidas principais (sem divulgação de segredos operacionais): Criptografia em trânsito (TLS 1.2+ / 1.3) e em repouso (AES-256 ou equivalente). Controle de acesso baseado em papéis e princípio de mínimo privilégio. Segregação de ambientes (desenvolvimento, staging, produção) e pipeline com revisões. Logs de auditoria para ações administrativas e acessos a dados delicados. Monitoramento de integridade, alertas de anomalia e limitações automáticas de taxa (rate limiting). Testes periódicos de vulnerabilidade e correções priorizadas por criticidade. Hardening de infraestrutura e rotação de credenciais seguras. Pseudonimização ou truncamento de campos sensíveis em logs técnicos. Nenhuma medida de segurança é absoluta; mantemos programa contínuo de aprimoramento. 13. Gestão de Incidentes Incidentes relevantes de segurança serão avaliados conforme impacto, natureza dos dados e risco a titulares. Caso exigido, notificaremos Gestores afetados e a ANPD com: (i) descrição do evento; (ii) dados possivelmente envolvidos; (iii) medidas já tomadas e mitigação planejada; (iv) orientações ao Gestor. Mantemos plano de resposta revisto periodicamente. 14. Decisões Automatizadas Empregamos automações para detecção de abuso, limitação de requisições e prevenção a fraude de uso. Estas automações podem restringir temporariamente acessos ou chaves. Não realizamos decisões exclusivamente automatizadas que produzam efeitos jurídicos ou signifcativos sobre indivíduos. O Gestor pode solicitar revisão humana via suporte. 15. Cookies e Tecnologias de Rastreamento Na interface de painel podemos utilizar cookies estritamente necessários (sessão/autenticação) e possivelmente cookies funcionais para preferências. Não usamos cookies de publicidade comportamental. Caso venhamos a empregar analytics de terceiros, atualizaremos esta seção e forneceremos mecanismo de consentimento quando aplicável. O Gestor pode gerenciar cookies via configurações de navegador; a desativação de cookies estritamente necessários pode limitar funcionalidades. 16. Crianças, Adolescentes e Menores Emancipados Os serviços não se destinam a menores de 18 anos, exceto menores a partir de 16 anos legalmente emancipados nos termos da legislação brasileira. Não coletamos intencionalmente dados pessoais de menores não emancipados. Caso identifiquemos tratamento indevido, adotaremos medidas para remoção rápida e notificação ao Gestor. O Gestor é responsável por implementar verificações quando o uso envolver público potencialmente menor de idade. 17. Dados Sensíveis Não exigimos o envio de dados sensíveis. O Gestor deve evitar enviar dados de saúde, biométricos, genéticos, crenças religiosas, opinião política ou outros dados especiais, a menos que possua base legal apropriada e comunique claramente os titulares. AIVAX poderá aplicar filtros ou bloqueios para tipos de conteúdo considerados de alto risco. 18. Limitações de Uso e Conteúdos Proibidos É proibido utilizar a plataforma para armazenar ou processar conteúdos ilícitos, violadores de direitos, malware, material difamatório ou que infrinja direitos de terceiros. Podemos suspender ou bloquear chaves mediante suspeita razoável de violação, preservando logs necessários para investigação. Medidas de suspensão e rescisão seguem também o disposto nos Termos de Uso (Seções 2.1 e 5). 19. Anonimização e Dados Agregados Podemos gerar estatísticas agregadas (ex.: volume de tokens, taxa de erro, distribuição por modelo) sem identificação direta de indivíduos ou do conteúdo específico das Conversas. Tais dados não retornam à forma identificável. 20. Exportação e Portabilidade Fornecemos (ou forneceremos) mecanismos para exportar histórico de Conversas e métricas em formatos estruturados (JSON), limitados por janelas de retenção e segurança. Para dados mantidos enquanto Operadora, solicitações de titulares devem ser encaminhadas ao Gestor Controlador. 21. Backups e Recuperação de Desastre Backups cifrados são executados em janelas periódicas e retidos por até 90 dias para continuidade operacional. Após exclusões solicitadas, marcamos registros para expurgo lógico e impedimos reintrodução após restauração mediante reprocessamento de fila de exclusões. 22. Alterações a esta Política Alterações materiais serão notificadas por e-mail ao Gestor ou aviso destacado no painel com antecedência razoável (preferencialmente 15 dias), salvo exigência legal ou segurança urgente. A continuidade de uso após a vigência constitui aceitação. 23. Canal de Contato e Reclamações Dúvidas, solicitações de direitos ou reclamações: **privacy@aivax.net** / **wm@aivax.net**. Se não houver solução satisfatória, o titular pode recorrer à ANPD (Autoridade Nacional de Proteção de Dados). 24. Histórico de Revisões Versão Data de Vigência Principais Alterações 1.0 30/07/2025 Versão inicial publicada 1.1 05/10/2025 Inclusão de bases legais, direitos, retenção detalhada, subprocessadores, transferências, segurança ampliada, incidentes, decisões automatizadas, cookies, dados sensíveis, versionamento 25. Contato Geral Legal / Privacidade: **legal@aivax.net** – Encarregado: **wm@aivax.net**. Usar sempre canais oficiais para evitar engenharia social. 26. Disposições Finais Caso alguma cláusula desta política seja considerada inválida, as demais permanecem em pleno vigor. Em caso de conflito entre esta política e termos específicos de produto, prevalecerá a disposição mais protetiva aos titulares, salvo obrigação legal diversa. Se restarem dúvidas sobre qualquer ponto desta política, entre em contato. Mantemos compromisso com melhoria contínua de privacidade e segurança. Nota: Esta política poderá ser complementada por um Acordo de Processamento de Dados (DPA) específico entre AIVAX e o Gestor, quando aplicável."
  },
  "docs/legal/terms-of-service.html": {
    "href": "docs/legal/terms-of-service.html",
    "title": "Termos de Uso | AIVAX",
    "keywords": "Termos de Uso Versão: 1.1 Data de vigência: 05 de outubro de 2025 Última atualização anterior: 30 de julho de 2025 Bem-vindo à AIVAX. Estes Termos de Uso (\"Termos\") governam o seu acesso e uso dos nossos serviços de inferência de IA, APIs, site e qualquer software associado (coletivamente, os \"Serviços\"). Ao criar uma conta, acessar ou utilizar nossos Serviços, você (\"Gestor da Conta AIVAX\") concorda em ficar vinculado a estes Termos e à nossa Política de Privacidade. Se você não concordar com estes Termos, não utilize nossos Serviços. 1. Definições AIVAX: A empresa que fornece os serviços. Gestor da Conta AIVAX: A pessoa física ou jurídica que cria e administra uma conta na plataforma AIVAX e concorda com estes Termos. Conteúdo de Entrada: Os dados, textos, prompts ou qualquer outra informação que o Gestor da Conta AIVAX envia para os Serviços para processamento. Conteúdo Gerado: As respostas, textos, imagens ou qualquer outro dado que é gerado pelos modelos de IA como resultado do processamento do Conteúdo de Entrada. (Correspondência Terminológica): Na Política de Privacidade, \"Dados de Inferência\" abrangem conjuntamente Conteúdo de Entrada e Conteúdo Gerado; \"Conversas\" representam sequências agregadas dessas interações. 2. Uso dos Serviços e Responsabilidades 2.1. Uso Responsável e Conduta Você concorda em usar os Serviços da AIVAX de forma ética e responsável. É estritamente proibido: Abusar do Sistema: Não se envolver em atividades que abusem, interfiram, interrompam ou prejudiquem os Serviços, nossos servidores ou redes. Isso inclui, mas não se limita a, enviar um volume de requisições excessivo que possa ser caracterizado como ataque de negação de serviço (DoS), tentar encontrar e explorar vulnerabilidades ou tentar acessar áreas não autorizadas do sistema. Comportamento Inadequado: Não utilizar os Serviços para assediar, ameaçar, difamar, enganar, ou violar os direitos legais e a dignidade de terceiros. A AIVAX preza por um ambiente de uso tecnológico saudável e não tolerará condutas que possam ser razoavelmente interpretadas como maliciosas ou abusivas. 2.2. Conformidade Legal Você é o único responsável por garantir que o seu uso dos Serviços esteja em total conformidade com todas as leis e regulamentos aplicáveis. Leis Brasileiras e Internacionais: Você concorda em não usar os Serviços para criar ou disseminar Conteúdo Gerado que viole qualquer lei vigente no Brasil ou em jurisdições internacionais relevantes. Isso inclui, mas não se limita a, leis sobre direitos autorais, propriedade intelectual, difamação, incitação ao ódio, terrorismo e exploração infantil. Marco Civil da Internet e LGPD: Seu uso deve respeitar os princípios estabelecidos pelo Marco Civil da Internet (Lei nº 12.965/2014) e pela Lei Geral de Proteção de Dados (LGPD - Lei nº 13.709/2018). 2.3. Consentimento para Uso de Dados Pessoais O Gestor da Conta AIVAX é o controlador dos dados inseridos nos Serviços. Caso o Conteúdo de Entrada inclua dados pessoais de terceiros, você declara e garante que: Possui a Base Legal Apropriada: Você obteve a base legal necessária (como o consentimento explícito e informado do titular dos dados) para coletar, processar e enviar esses dados para a AIVAX para fins de inferência. Responsabilidade Integral: Você é o único e exclusivo responsável por cumprir todas as obrigações da LGPD em relação a esses dados, incluindo a resposta a solicitações dos titulares. A AIVAX atua apenas como operadora desses dados sob suas instruções. 2.4. Eligibilidade Para usar os serviços da AIVAX, você precisa ser civilmente capaz, ou seja, ter pelo menos 18 anos de idade ou ter 16 anos quanto emancipado. Ao usar nossos serviços, você declara que: não foi suspenso, removido ou banido de nosso serviço anteriormente; sua conta está vinculada à uma pessoa sem débitos e em concordância com leis e regulações locais; você possui a idade mínima requerida para usar nossos serviços. Se estiver usando nossos serviços em responsabilidade de outra pessoa, organização ou empresa, você assume que tal empresa possui toda responsabilidade necessária para suas ações e aceitar estes termos de uso. 2.5. Saldo, créditos e reembolsos Para usar a maioria dos serviços da AIVAX é necessária a adição de saldo (\"créditos\") pré-pagos em sua conta. Ao usar nossos serviços, você concorda que: Nossos provedores de pagamentos podem coletar e armazenar dados determinísticos à você, como endereços físicos, dados de pagamentos (como cartões de créditos) e quaisquer informações que justifique a cobrança para adição de saldo. Essas informações não são vinculadas ou usadas à AIVAX e é de responsabilidade de nossos parceiros de pagamentos. Antes de pagar por créditos, você pode visualizar com antecedência as taxas de serviço cobradas pela AIVAX e se recusar à pagá-las, impossibilitando a adição de saldo. Créditos adicionados expiram após um ano de sua adição. Após esse período, o crédito expirado passará a não contabilizar mais o balanço da sua conta. Reembolso é permitido somente se as duas condições forem cumpridas no ato da solicitação do reembolso: o reembolso foi solicitado em até 24 horas do momento da adição do saldo e que o balanço total da conta seja superior ou igual ao valor do reembolso solicitado. A taxa de serviço não é reembolsável. Do valor pago, somente o crédito final será reembolsado pelo provedor de pagamento. 3. Conteúdo Gerado e Propriedade Intelectual 3.1. Propriedade e Responsabilidade do Conteúdo Gerado Sujeito a estes Termos, a AIVAX concede a você todos os direitos, títulos e interesses sobre o Conteúdo Gerado. Em outras palavras: o que você cria é seu. Consequentemente, você é o único e exclusivo responsável pelo Conteúdo Gerado e pelo seu uso subsequente. Você assume todos os riscos associados a ele, incluindo sua legalidade, precisão, adequação e possíveis violações de direitos de terceiros. A AIVAX não tem qualquer responsabilidade ou obrigação sobre o uso que você faz do Conteúdo Gerado. Não Exclusividade e Similaridade: Devido à natureza estatística dos modelos, conteúdos semanticamente ou textualmente semelhantes podem ser gerados para diferentes usuários sem acesso cruzado às entradas originais. Não garantimos exclusividade absoluta de expressões ou ideias resultantes. Você não adquire qualquer direito sobre pesos de modelos, prompts internos, técnicas ou segredos comerciais da AIVAX. Licença Limitada concedida à AIVAX: Ao enviar Conteúdo de Entrada, você concede à AIVAX uma licença mundial, não exclusiva, livre de royalties, limitada ao necessário para (i) processar inferências; (ii) manter logs técnicos e segurança; (iii) detectar abuso; (iv) cumprir obrigações legais. Não usamos Conteúdo de Entrada ou Conteúdo Gerado para treinamento de modelos proprietários. Setores de Alto Risco: O Conteúdo Gerado não deve ser usado como única base para decisões médicas, jurídicas, financeiras, de engenharia de segurança crítica, ou qualquer contexto que possa gerar risco físico ou financeiro relevante sem validação humana qualificada. 3.2. Conteúdo Adulto, Explícito e Sensível A AIVAX é uma ferramenta e, como tal, pode ser utilizada para gerar uma vasta gama de conteúdos. A geração de conteúdo explícito, adulto ou pornográfico é permitida, desde que estritamente observadas as seguintes condições: Responsabilidade Total: Você assume total e completa responsabilidade pela criação, armazenamento e distribuição de tal material. Legalidade Inquestionável: O material não deve, em hipótese alguma, violar qualquer lei vigente sobre o tema, com tolerância zero para conteúdo que represente ou sugira exploração infantil, violência não consensual ou qualquer outra forma de abuso ilegal. Consentimento: Caso o material envolva a representação de pessoas reais, você deve ter o consentimento explícito e verificável dessas pessoas para criar e usar suas imagens para tal finalidade. Controle de Acesso: Você é responsável por implementar seus próprios mecanismos de controle de acesso e verificação de idade, caso decida disponibilizar esse conteúdo a terceiros. A AIVAX não endossa esse tipo de conteúdo e se reserva o direito de investigar e suspender contas que violem as condições acima. 4. Provedores de Modelos de Terceiros Os Serviços da AIVAX podem rotear seu Conteúdo de Entrada para modelos de IA operados por terceiros. Ao usar um modelo específico, você também pode estar sujeito aos termos de uso do provedor daquele modelo. É sua responsabilidade revisar e cumprir tais termos. A AIVAX não se responsabiliza pelas políticas ou práticas de provedores terceiros. 5. Suspensão e Rescisão A AIVAX reserva-se o direito de suspender, rescindir ou banir seu acesso aos nossos serviços prestados, a nosso critério exclusivo e sem aviso prévio, por qualquer violação destes termos. Atividades que podem levar à suspensão incluem, mas não se limitam a, violações de conformidade legal, abuso do sistema ou falta de pagamento. As suspensões podem ser temporárias ou permanentes, dependendo da gravidade da infração. 6. Limitação de Responsabilidade e Isenção de Garantias OS SERVIÇOS SÃO FORNECIDOS \"COMO ESTÃO\" E \"CONFORME DISPONÍVEIS\", SEM GARANTIAS DE QUALQUER TIPO, SEJAM EXPRESSAS OU IMPLÍCITAS. A AIVAX NÃO GARANTE QUE OS SERVIÇOS SERÃO ININTERRUPTOS, SEGUROS OU LIVRES DE ERROS. EM NENHUMA CIRCUNSTÂNCIA A AIVAX SERÁ RESPONSÁVEL POR QUAISQUER DANOS INDIRETOS, INCIDENTAIS, ESPECIAIS, CONSEQUENCIAIS OU PUNITIVOS DECORRENTES DO SEU ACESSO OU USO DOS SERVIÇOS. O CONTEÚDO GERADO PODE CONTER IMPRECISÕES, OMISSÕES OU “ALUCINAÇÕES” E É FORNECIDO PARA FINS INFORMATIVOS, SENDO O USUÁRIO RESPONSÁVEL POR VERIFICAÇÃO HUMANA ANTES DE QUALQUER USO CRÍTICO. 7. Indenização Você concorda em indenizar, defender e manter indene a AIVAX, suas afiliadas, administradores, colaboradores e parceiros contra quaisquer reclamações, perdas, danos, responsabilidades, custos e despesas (incluindo honorários advocatícios razoáveis) resultantes de: (i) Conteúdo de Entrada; (ii) uso indevido dos Serviços; (iii) violação destes Termos ou da legislação aplicável; (iv) infração de direitos de propriedade intelectual, privacidade ou personalidade de terceiros; (v) uso ou exposição indevida de chaves de API emitidas para sua conta. 8. Encerramento e Pós-Término Podemos encerrar ou suspender o acesso aos Serviços (total ou parcialmente) caso: (i) haja violação destes Termos; (ii) risco de segurança; (iii) exigência legal; (iv) inadimplência reiterada; (v) abuso ou fraude. Após encerramento: (a) seu acesso e chaves podem ser desativados imediatamente; (b) você poderá solicitar exportação de dados disponíveis (quando funcionalidade existir) em até 15 dias; (c) dados serão eliminados ou anonimizados conforme a Política de Privacidade, ressalvadas obrigações legais e defesa de direitos; (d) valores devidos continuam exigíveis. 9. Força Maior Nenhuma parte será responsável por falhas ou atrasos de desempenho causados por eventos fora de seu controle razoável, incluindo, mas não se limitando a, desastres naturais, atos governamentais, falhas generalizadas de infraestrutura de internet, ataques cibernéticos massivos, pandemias, guerras ou interrupções amplas de energia. Obrigações de pagamento não são exoneradas por força maior já consumada. 10. Controles de Exportação e Sanções Você declara que não está localizado em, nem atua em nome de entidade ou pessoa sujeita a sanções ou restrições comerciais impostas por autoridades brasileiras ou internacionais (incluindo listas de restrição de comércio ou sanções econômicas). Você não usará os serviços para fins proibidos por leis de exportação, anticorrupção ou antiterrorismo. 11. Confidencialidade e Segurança de Credenciais Você deve manter confidenciais chaves de API, tokens e credenciais associadas à sua conta, adotando controles de acesso. Qualquer atividade realizada com suas credenciais será presumida como autorizada por você até comunicação de comprometimento. Você se compromete a notificar a AIVAX prontamente sobre suspeitas de uso não autorizado. 12. Feedback e Melhorias Quaisquer comentários, sugestões, ideias ou feedback fornecidos podem ser utilizados livremente pela AIVAX para aperfeiçoar ou desenvolver produtos e serviços, sem obrigação de compensação, crédito ou confidencialidade adicional. 13. Recursos Beta e Descontinuação de Modelos Recursos identificados como “Beta”, “Experimental” ou equivalentes podem apresentar instabilidade, alteração de comportamento ou remoção sem aviso. Podemos descontinuar modelos ou ajustar limites técnicos (latência, throughput, quotas) por razões de desempenho, custo, conformidade ou segurança. 14. Procedimento de Notificação e Remoção (Takedown) Se você acreditar que qualquer saída ou uso dos Serviços viola direitos autorais, de marca ou outros direitos, envie notificação para legal@aivax.net contendo: (i) identificação precisa do material; (ii) base da alegação; (iii) seus dados de contato; (iv) declaração de boa-fé e veracidade. Podemos remover ou limitar acesso preventivamente e encerrar contas reincidentes. 15. Cessão Você não pode ceder ou transferir estes Termos sem consentimento prévio por escrito da AIVAX. A AIVAX poderá ceder estes Termos, total ou parcialmente (incluindo em operações societárias, fusões, aquisições ou reorganizações) mediante simples aviso. 16. Sobrevivência As seguintes disposições sobrevivem ao término: Propriedade Intelectual, Limitação de Responsabilidade, Indenização, Confidencialidade, Encerramento (obrigações pós-término), Cessão, Lei Aplicável e Foro, e quaisquer outras que por sua natureza devam persistir. 17. Acordo Integral Estes Termos, juntamente com a Política de Privacidade e eventuais documentos adicionais expressamente referenciados, constituem o acordo integral entre você e a AIVAX, substituindo entendimentos ou comunicações anteriores sobre o objeto. 18. Notificações Notificações formais poderão ocorrer por: (i) e-mail cadastrado; (ii) avisos no painel; ou (iii) publicação em página oficial dos Termos. Considera-se recebida notificação enviada por e-mail após 24 horas do envio, salvo erro técnico comprovado. 19. Atualizações de Preços e Limites Podemos ajustar preços, modelos de cobrança, limites de uso ou políticas de quotas. Alterações que impactem materialmente custos futuros serão comunicadas com antecedência razoável (salvo exigência legal ou emergencial). Uso continuado após vigência das mudanças implica concordância. 20. Idioma Esta versão em português prevalece sobre qualquer tradução fornecida apenas por conveniência. 21. Modificações nos Termos Podemos modificar estes Termos a qualquer momento. Notificaremos sobre alterações publicando versão atualizada ou enviando comunicação eletrônica. Alterações materiais poderão exigir aceitação adicional ou interrupção de uso caso não concorde. O uso continuado após a data de vigência das alterações constitui aceitação. 22. Disposições Gerais Estes Termos são regidos pelas leis da República Federativa do Brasil. Fica eleito o foro da Comarca de São Paulo, Estado de São Paulo, Brasil, para dirimir controvérsias, com renúncia a qualquer outro foro, por mais privilegiado que seja. A eventual invalidade de alguma cláusula não afeta a validade das demais. Para qualquer dúvida sobre estes Termos de Uso, entre em contato: **legal@aivax.net**."
  },
  "docs/limits.html": {
    "href": "docs/limits.html",
    "title": "Limites da API | AIVAX",
    "keywords": "Limites da API Limites de taxa (\"rate limiters\") regulam o número de requisições que você pode enviar em uma janela de tempo. Esses limites ajudam a AIVAX a prevenir abuso e fornecer uma API estável à todos. Os limites da API abaixo são os mesmos para todos os modelos embutidos da AIVAX. Esses limites são categorizados por operações feitas pela API. Cada conta possui um tier que define quais limites são aplicados à conta. Tiers mudam de acordo com o total investido na AIVAX e o tempo que a conta existe. Tier zero: conta nova que nunca adicionou créditos ou que possui créditos de teste. Tier 1: conta criada há pelo menos 48 horas e que já adicionou qualquer valor em créditos. Tier 2: conta criada há pelo menos 1 mês e que já adicionou pelo menos $ 100 em créditos. Tier 3: conta criada há pelo menos 3 meses e que já adicionou pelo menos $ 1.000 em créditos. A medição é pela adição de créditos e não pelo seu consumo. Por exemplo, você não precisa consumir $ 100 em créditos para avançar ao Tier 2. Legendas dos limites: RPM: requisições por minuto. RPD: requisições por dia (24 horas). TPM: tokens de entrada por minuto. Conta nova Tier 1 Tier 2 Tier 3 Operação RPM RPD TPM Pesquisa de documentos 50 - - Inserção de documentos - 100 - Inferência 5 300 50.000 Inferência (modelos high-end) - - - Ferramentas (compartilhado) - 100 - Ferramenta web_search - 20 - Ferramenta x_posts_search - 20 - Ferramenta generate_image - 5 - Operação RPM RPD TPM Pesquisa de documentos 150 - - Inserção de documentos - 3.000 - Inferência 75 10.000 1.000.000 Inferência (modelos high-end) 75 10.000 200.000 Ferramentas (compartilhado) - 1.000 - Ferramenta web_search - 300 - Ferramenta x_posts_search - 300 - Ferramenta generate_image - 30 - Operação RPM RPD TPM Pesquisa de documentos 300 - - Inserção de documentos - 10.000 - Inferência 200 - 4.000.000 Inferência (modelos high-end) 200 - 1.000.000 Ferramentas (compartilhado) - 10.000 - Ferramenta web_search - 1.000 - Ferramenta x_posts_search - 1.000 - Ferramenta generate_image - 300 - Operação RPM RPD TPM Pesquisa de documentos 1.000 - - Inserção de documentos - 30.000 - Inferência 1.000 - 10.000.000 Inferência (modelos high-end) 1.000 - 4.000.000 Ferramentas (compartilhado) - 50.000 - Ferramenta web_search - 10.000 - Ferramenta x_posts_search - 10.000 - Ferramenta generate_image - 1.000 - Pesquisa de documentos: inclui pesquisa semântica de documentos em uma coleção pelo endpoint de pesquisa ../collections/{id}/query. Inserção de documentos: inclui criação e modificação de documentos em uma coleção. Inferência: toda chamada de inferência ou função, seja por chat client ou API. modelos high-end se referem à modelos que necessitam de Tier 1 para poder ser usado. Ferramentas (compartilhado): toda ferramenta integrada invocada pela assistente. Esse limite é compartilhado para todas as ferramentas providas pela AIVAX e não é usado para ferramentas definidas por você ou suas APIs. Ferramenta (nome da ferramenta): todo uso da ferramenta mencionada. Limites para BYOK (Bring-your-own-key) Para modelos providos por você, o limite aplicado é de 1.500 requisições por minuto. Esse limite é separado do limite de inferência integrada."
  },
  "docs/mcp.html": {
    "href": "docs/mcp.html",
    "title": "Suporte à Model Context Protocol (MCP) | AIVAX",
    "keywords": "Suporte à Model Context Protocol (MCP) É possível vincular ferramentas externas do protocolo MCP em seu AI Gateway. O protocolo define funções que executam do lado do servidor e possibilitam a interação da assistente com serviços em tempo real. As funções MCP persistem a chamada de ações do lado do servidor da AIVAX, removendo a necessidade de implementação da função do lado do cliente. Escolhendo o nome da função O nome da função deve ser simples e determinístico ao que essa função faz. Evite nomes difíceis de advinhar ou que não remetam ao papel da função, pois a assistente pode se confundir e não chamar a função quando apropriado. Como um exemplo, vamos pensar em uma função de consultar um usuário em um banco de dados externo. Os nomes a seguir são bons exemplos para considerar para a chamada: search_user query_user Nomes ruins incluem: search (implícito, possivelmente ambíguo) search user (nome com caracteres impróprios) Tendo o nome da função, podemos pensar na descrição da função. Escolhendo a descrição da função A descrição da função deve explicar conceitualmente duas situações: o que ela faz e quando deve ser chamada pela assistente. Essa descrição deve incluir os cenários que a assistente deve considerar chamar ela e quando não deve ser chamada, fornecendo poucos exemplos de chamadas (one-shot) e/ou tornando explícitas as regras da função. Definindo servidores MCP Você pode definir seus servidores MCP no gateway através de um array JSON: [ { \"name\": \"Meu servidor MCP\", \"url\": \"https://example-server.io/mcp\", \"headers\": { \"Authorization\": \"sk-pv-12nbo...\" } } ] Seu servidor MCP deve estar habilitado para SSE ou Streamable HTTP para funcionar com AIVAX. Você pode definir cabeçalhos customizados na configuração do seu servidor MCP para configurar autenticação ou demais necessidades. Chamadas da AIVAX no servidor MCP remoto normalmente enviarão informações de metadata adicionais através do campo _meta do MCP: { \"jsonrpc\": \"2.0\", \"id\": 2, \"method\": \"tools/call\", \"params\": { \"name\": \"get_weather\", \"arguments\": { \"location\": \"New York\" }, \"_meta\": { \"_aiv_nonce\": \"$2a$12$ynC9kC2q6iuEjO8SFDQqVeDxvHPUIZ9jTClE91SJo8VYtt/BSJDUG\", \"_aiv_external_user_id\": \"custom-user-id\", \"_aiv_call_source\": \"WebChatClient\", \"_aiv_conversation_token\": \"iiocc6stxgj5jc75ay4y\", \"_aiv_moment\": \"2025-09-09T16:58:05\", \"custom_metadata_field_1\": \"foo\", \"something\": \"bar\" } } } Dos valores definidos em _meta, você tem os parâmetros de metadata da inferência, cliente ou função. Valores prefixados em _aiv são reservados para parâmetros da AIVAX."
  },
  "docs/models.html": {
    "href": "docs/models.html",
    "title": "Modelos | AIVAX",
    "keywords": "Modelos A AIVAX provê modelos de diferentes provedores para tornar o desenvolvimento ainda mais rápido, dispensando a necessidade de ter que configurar uma conta para cada provedor para ter acessos aos seus modelos mais recentes. Veja a lista abaixo dos modelos disponíveis e suas precificações. Todos os preços consideram o total de entrada e saída de tokens, com ou sem cache. Todos os preços estão em dólares dos Estados Unidos. amazon Nome do modelo Preços Descrição @amazon/nova-pro Entrada: $ 0.80 /1m tokens Saída: $ 3.20 /1m tokens A highly capable multimodal model with the best combination of accuracy, speed, and cost for a wide range of tasks. Entrada: aceita imagens, vídeos Chamadas de função Raciocínio Funções JSON @amazon/nova-lite Entrada: $ 0.06 /1m tokens Saída: $ 0.24 /1m tokens A very low cost multimodal model that is lightning fast for processing image, video, and text inputs. Entrada: aceita imagens, vídeos Chamadas de função Raciocínio Funções JSON @amazon/nova-micro Entrada: $ 0.04 /1m tokens Saída: $ 0.14 /1m tokens A text-only model that delivers the lowest latency responses at very low cost. Chamadas de função Funções JSON anthropic Nome do modelo Preços Descrição @anthropic/claude-4.5-sonnet Entrada: $ 3.00 /1m tokens Entrada (em cache): $ 0.30 /1m tokens Saída: $ 15.00 /1m tokens Claude Sonnet 4.5 is the newest model in the Sonnet series, offering improvements and updates over Sonnet 4. Entrada: aceita imagens Chamadas de função Raciocínio Funções JSON @anthropic/claude-4-sonnet Entrada: $ 3.00 /1m tokens Entrada (em cache): $ 0.30 /1m tokens Saída: $ 15.00 /1m tokens Anthropic's mid-size model with superior intelligence for high-volume uses in coding, in-depth research, agents, & more. Entrada: aceita imagens Chamadas de função Raciocínio Funções JSON @anthropic/claude-3.5-haiku Entrada: $ 0.80 /1m tokens Entrada (em cache): $ 0.08 /1m tokens Saída: $ 4.00 /1m tokens Claude 3.5 Haiku is the next generation of our fastest model. For a similar speed to Claude 3 Haiku, Claude 3.5 Haiku improves across every skill set and surpasses Claude 3 Opus, the largest model in our previous generation, on many intelligence benchmarks. Entrada: aceita imagens Chamadas de função Funções JSON @anthropic/claude-3-haiku Entrada: $ 0.25 /1m tokens Entrada (em cache): $ 0.03 /1m tokens Saída: $ 1.25 /1m tokens Claude 3 Haiku is Anthropic's fastest model yet, designed for enterprise workloads which often involve longer prompts. Entrada: aceita imagens Chamadas de função Funções JSON cohere Nome do modelo Preços Descrição @cohere/command-a Entrada: $ 2.50 /1m tokens Saída: $ 10.00 /1m tokens Command A is Cohere's most performant model to date, excelling at tool use, agents, retrieval augmented generation (RAG), and multilingual use cases. Command A has a context length of 256K, only requires two GPUs to run, and has 150% higher throughput compared to Command R+ 08-2024. Entrada: aceita imagens Chamadas de função Funções JSON deepseekai Nome do modelo Preços Descrição @deepseekai/r1 Entrada: $ 0.50 /1m tokens Entrada (em cache): $ 0.40 /1m tokens Saída: $ 2.15 /1m tokens The DeepSeek R1 model has undergone a minor version upgrade, with the current version being DeepSeek-R1-0528. Chamadas de função Raciocínio Funções JSON @deepseekai/v3.1-terminus Entrada: $ 0.27 /1m tokens Entrada (em cache): $ 0.22 /1m tokens Saída: $ 1.00 /1m tokens DeepSeek-V3.1 is post-trained on the top of DeepSeek-V3.1-Base, which is built upon the original V3 base checkpoint through a two-phase long context extension approach, following the methodology outlined in the original DeepSeek-V3 report. Chamadas de função Raciocínio Funções JSON @deepseekai/v3.2 Entrada: $ 0.27 /1m tokens Saída: $ 0.40 /1m tokens DeepSeek-V3.2-Exp is an intermediate step toward the next-generation architecture of the DeepSeek models by introducing DeepSeek Sparse Attention—a sparse attention mechanism designed to explore and validate optimizations for training and inference efficiency in long-context scenarios. Chamadas de função Raciocínio Funções JSON google Nome do modelo Preços Descrição @google/gemini-2.5-pro Entrada: $ 1.25 /1m tokens Entrada (em cache): $ 0.31 /1m tokens Saída: $ 10.00 /1m tokens One of the most powerful models today. Entrada: aceita imagens, vídeos, áudios Chamadas de função Raciocínio @google/gemini-2.5-flash Entrada: $ 0.30 /1m tokens Entrada (em cache): $ 0.08 /1m tokens Saída: $ 2.50 /1m tokens Google's best model in terms of price-performance, offering well-rounded capabilities. 2.5 Flash is best for large scale processing, low-latency, high volume tasks that require thinking, and agentic use cases. Entrada: aceita imagens, vídeos, áudios Chamadas de função Raciocínio Funções JSON @google/gemini-2.5-flash-lite Entrada: $ 0.10 /1m tokens Entrada (em cache): $ 0.03 /1m tokens Saída: $ 0.40 /1m tokens A Gemini 2.5 Flash model optimized for cost efficiency and low latency. Entrada: aceita imagens, vídeos, áudios Chamadas de função Raciocínio Funções JSON @google/gemini-2.0-flash Entrada: $ 0.10 /1m tokens Entrada (em cache): $ 0.03 /1m tokens Saída: $ 0.40 /1m tokens Gemini 2.0 Flash delivers next-gen features and improved capabilities, including superior speed, native tool use, and a 1M token context window. Entrada: aceita imagens, vídeos, áudios Chamadas de função Funções JSON @google/gemini-2.0-flash-lite Entrada: $ 0.08 /1m tokens Saída: $ 0.30 /1m tokens General-purpose model, with image recognition, smart and fast. Great for an economical chat. Entrada: aceita imagens, vídeos, áudios Chamadas de função Funções JSON inception Nome do modelo Preços Descrição @inception/mercury Entrada: $ 0.25 /1m tokens Saída: $ 1.00 /1m tokens Extremely fast model by generative diffusion. Chamadas de função Funções JSON metaai Nome do modelo Preços Descrição @metaai/llama-3.3-70b Entrada: $ 0.59 /1m tokens Saída: $ 0.79 /1m tokens Previous generation model with many parameters and surprisingly fast speed. Chamadas de função Funções JSON @metaai/llama-4-maverick-17b-128e Entrada: $ 0.20 /1m tokens Saída: $ 0.60 /1m tokens Fast model, with 17 billion activated parameters and 128 experts. Entrada: aceita imagens Chamadas de função Funções JSON @metaai/llama-4-scout-17b-16e Entrada: $ 0.11 /1m tokens Saída: $ 0.34 /1m tokens Smaller version of the Llama 4 family with 17 billion activated parameters and 16 experts. Entrada: aceita imagens Chamadas de função Funções JSON @metaai/llama-3.1-8b Entrada: $ 0.05 /1m tokens Saída: $ 0.08 /1m tokens Cheap and fast model for less demanding tasks. Chamadas de função Funções JSON mistral Nome do modelo Preços Descrição @mistral/pixtral-large Entrada: $ 2.00 /1m tokens Saída: $ 6.00 /1m tokens Pixtral Large is the second model in our multimodal family and demonstrates frontier-level image understanding. Particularly, the model is able to understand documents, charts and natural images, while maintaining the leading text-only understanding of Mistral Large 2. Entrada: aceita imagens Chamadas de função Funções JSON @mistral/magistral-medium Entrada: $ 2.00 /1m tokens Saída: $ 5.00 /1m tokens Mistral's frontier-class reasoning model update released September 2025 with vision support. Entrada: aceita imagens Raciocínio Funções JSON @mistral/medium Entrada: $ 0.40 /1m tokens Saída: $ 2.00 /1m tokens Mistral Medium 3 delivers frontier performance while being an order of magnitude less expensive. For instance, the model performs at or above 90% of Claude Sonnet 3.7 on benchmarks across the board at a significantly lower cost. Entrada: aceita imagens Chamadas de função Funções JSON @mistral/magistral-small Entrada: $ 0.50 /1m tokens Saída: $ 1.50 /1m tokens Complex thinking, backed by deep understanding, with transparent reasoning you can follow and verify. The model excels in maintaining high-fidelity reasoning across numerous languages, even when switching between languages mid-task. Raciocínio Funções JSON @mistral/small Entrada: $ 0.10 /1m tokens Saída: $ 0.30 /1m tokens Mistral Small is the ideal choice for simple tasks that one can do in bulk - like Classification, Customer Support, or Text Generation. It offers excellent performance at an affordable price point. Entrada: aceita imagens Chamadas de função Funções JSON @mistral/nemo-12b-it-2407 Entrada: $ 0.02 /1m tokens Saída: $ 0.04 /1m tokens 12B model trained jointly by Mistral AI and NVIDIA, it significantly outperforms existing models smaller or similar in size. Chamadas de função Funções JSON model-router Nome do modelo Preços Descrição @model-router/gemini Entrada: $ 0.08 /1m tokens Saída: $ 0.30 /1m tokens Model router for Google Gemini. The routing is made between Gemini 2.0 Flash, Gemini 2.5 Flash (no thinking) and Gemini 2.5 Flash (dynamic thinking). @model-router/openai Entrada: $ 0.08 /1m tokens Saída: $ 0.30 /1m tokens Model router for OpenAI. The routing is made between GPT 5 Nano (minimal), GPT 5 Mini (Low) and GPT-5 Mini (medium). @model-router/openai-high Entrada: $ 0.08 /1m tokens Saída: $ 0.30 /1m tokens Model router for OpenAI. The routing is made between GPT 5 Mini (low), o4-mini (low) and o4-mini (high). @model-router/llama Entrada: $ 0.08 /1m tokens Saída: $ 0.30 /1m tokens Model router for Meta Llama. The routing is made between Llama 4 Scout, Llama 4 Maverick and Llama 3.3 70b. moonshotai Nome do modelo Preços Descrição @moonshotai/kimi-k2 Entrada: $ 1.00 /1m tokens Entrada (em cache): $ 0.50 /1m tokens Saída: $ 3.00 /1m tokens Model with 1tri total parameters, 32bi activated parameters, optimized for agentic intelligence. Chamadas de função Funções JSON openai Nome do modelo Preços Descrição @openai/gpt-4o Entrada: $ 2.50 /1m tokens Entrada (em cache): $ 1.25 /1m tokens Saída: $ 10.00 /1m tokens Dedicated to tasks requiring reasoning for mathematical and logical problem solving. Entrada: aceita imagens Chamadas de função Funções JSON @openai/gpt-5-chat Entrada: $ 1.25 /1m tokens Entrada (em cache): $ 0.13 /1m tokens Saída: $ 10.00 /1m tokens GPT-5 snapshot currently used by OpenAI's ChatGPT. Entrada: aceita imagens Chamadas de função @openai/gpt-5 Entrada: $ 1.25 /1m tokens Entrada (em cache): $ 0.13 /1m tokens Saída: $ 10.00 /1m tokens OpenAI's newest flagship model for coding, reasoning, and agentic tasks across domains. Entrada: aceita imagens Chamadas de função Raciocínio Funções JSON @openai/gpt-4.1 Entrada: $ 2.00 /1m tokens Entrada (em cache): $ 0.50 /1m tokens Saída: $ 8.00 /1m tokens Versatile, highly intelligent, and top-of-the-line. One of the most capable models currently available. Entrada: aceita imagens Chamadas de função Funções JSON @openai/o3 Entrada: $ 2.00 /1m tokens Entrada (em cache): $ 0.50 /1m tokens Saída: $ 8.00 /1m tokens A well-rounded and powerful model across domains. It sets a new standard for math, science, coding, and visual reasoning tasks. Entrada: aceita imagens Chamadas de função Raciocínio Funções JSON @openai/o4-mini Entrada: $ 1.10 /1m tokens Entrada (em cache): $ 0.28 /1m tokens Saída: $ 4.40 /1m tokens Optimized for fast, effective reasoning with exceptionally efficient performance in coding and visual tasks. Entrada: aceita imagens Chamadas de função Raciocínio Funções JSON @openai/o3-mini Entrada: $ 1.10 /1m tokens Entrada (em cache): $ 0.55 /1m tokens Saída: $ 4.40 /1m tokens o3-mini provides high intelligence at the same cost and latency targets of previous versions of o-mini series. Chamadas de função Raciocínio Funções JSON @openai/gpt-5-mini Entrada: $ 0.25 /1m tokens Entrada (em cache): $ 0.03 /1m tokens Saída: $ 2.00 /1m tokens GPT-5 mini is a faster, more cost-efficient version of GPT-5. Entrada: aceita imagens Chamadas de função Funções JSON @openai/gpt-4.1-mini Entrada: $ 0.40 /1m tokens Entrada (em cache): $ 0.10 /1m tokens Saída: $ 1.60 /1m tokens Fast and cheap for focused tasks. Entrada: aceita imagens Chamadas de função Funções JSON @openai/gpt-oss-120b Entrada: $ 0.15 /1m tokens Saída: $ 0.75 /1m tokens OpenAI's flagship open source model, built on a Mixture-of-Experts (MoE) architecture with 120 billion parameters and 128 experts. Chamadas de função Raciocínio Funções JSON @openai/gpt-4o-mini Entrada: $ 0.15 /1m tokens Entrada (em cache): $ 0.08 /1m tokens Saída: $ 0.60 /1m tokens Smaller version of 4o, optimized for everyday tasks. Entrada: aceita imagens Chamadas de função Funções JSON @openai/gpt-oss-20b Entrada: $ 0.10 /1m tokens Saída: $ 0.50 /1m tokens OpenAI's flagship open source model, built on a Mixture-of-Experts (MoE) architecture with 20 billion parameters and 128 experts. Chamadas de função Raciocínio Funções JSON @openai/gpt-4.1-nano Entrada: $ 0.10 /1m tokens Entrada (em cache): $ 0.03 /1m tokens Saída: $ 0.40 /1m tokens The fastest and cheapest GPT 4.1 model. Entrada: aceita imagens Chamadas de função Funções JSON @openai/gpt-5-nano Entrada: $ 0.05 /1m tokens Entrada (em cache): $ 0.01 /1m tokens Saída: $ 0.40 /1m tokens OpenAI's fastest, cheapest version of GPT-5. Entrada: aceita imagens Chamadas de função Funções JSON qwen Nome do modelo Preços Descrição @qwen/qwen3-max Entrada: $ 1.20 /1m tokens Entrada (em cache): $ 0.24 /1m tokens Saída: $ 6.00 /1m tokens Qwen3-Max improves instruction following, multilingual ability, and tool use; reduced hallucinations. Chamadas de função Raciocínio Funções JSON @qwen/qwen3-coder-plus Entrada: $ 1.00 /1m tokens Saída: $ 5.00 /1m tokens Powered by Qwen3, this is a powerful Coding Agent that excels in tool calling and environment interaction to achieve autonomous programming. Chamadas de função Funções JSON @qwen/qwen3-next-80b-a3b-it Entrada: $ 0.14 /1m tokens Saída: $ 1.40 /1m tokens An 80 B-parameter instruction model with hybrid attention and Mixture‑of‑Experts, optimized for ultra‑long contexts up to 262 k tokens. Chamadas de função Funções JSON @qwen/qwen3-next-80b-a3b-think Entrada: $ 0.14 /1m tokens Saída: $ 1.40 /1m tokens A 80 B‑parameter “thinking‑only” model with hybrid attention and high‑sparsity MoE, designed for deep reasoning over ultra‑long contexts. Chamadas de função Raciocínio Funções JSON @qwen/qwen3-coder-480b-a35b-it Entrada: $ 0.29 /1m tokens Saída: $ 1.20 /1m tokens Qwen3-Coder-480B-A35B-Instruct is the Qwen3's most agentic code model, featuring Significant Performance on Agentic Coding, Agentic Browser-Use and other foundational coding tasks, achieving results comparable to Claude Sonnet. Chamadas de função Funções JSON @qwen/qwen3-32b Entrada: $ 0.29 /1m tokens Saída: $ 0.59 /1m tokens 32B-parameter LLM with a 131K-token context window, offering advanced chain-of-thought reasoning, seamless tool calling, native JSON outputs, and robust multilingual fluency. Chamadas de função Raciocínio Funções JSON venice Nome do modelo Preços Descrição @venice/dphn-24b-uncensored Entrada: $ 0.10 /1m tokens Saída: $ 0.45 /1m tokens Venice Uncensored is a fine-tuned version of Mistral-Small-24B-Instruct-2501, created by dphn.ai in partnership with Venice.ai. Funções JSON x-ai Nome do modelo Preços Descrição @x-ai/grok-4 Entrada: $ 3.00 /1m tokens Saída: $ 15.00 /1m tokens xAI's latest and greatest flagship model, offering unparalleled performance in natural language, math and reasoning - the perfect jack of all trades. Entrada: aceita imagens Chamadas de função Raciocínio Funções JSON @x-ai/grok-3 Entrada: $ 3.00 /1m tokens Saída: $ 15.00 /1m tokens xAI's flagship model that excels at enterprise use cases like data extraction, coding, and text summarization. Possesses deep domain knowledge in finance, healthcare, law, and science. Entrada: aceita imagens Chamadas de função Funções JSON @x-ai/grok-3-mini Entrada: $ 0.30 /1m tokens Saída: $ 0.50 /1m tokens xAI's lightweight model that thinks before responding. Great for simple or logic-based tasks that do not require deep domain knowledge. The raw thinking traces are accessible. Entrada: aceita imagens Chamadas de função Raciocínio Funções JSON @x-ai/grok-4-fast-reasoning Entrada: $ 0.20 /1m tokens Entrada (em cache): $ 0.05 /1m tokens Saída: $ 0.50 /1m tokens Grok 4 Fast is xAI's latest multimodal model with SOTA cost-efficiency and a 2M token context window. Entrada: aceita imagens Chamadas de função Raciocínio Funções JSON @x-ai/grok-4-fast Entrada: $ 0.20 /1m tokens Entrada (em cache): $ 0.05 /1m tokens Saída: $ 0.50 /1m tokens Grok 4 Fast is xAI's latest multimodal model with SOTA cost-efficiency and a 2M token context window. Entrada: aceita imagens Chamadas de função Funções JSON z-ai Nome do modelo Preços Descrição @z-ai/glm-4.6 Entrada: $ 0.60 /1m tokens Saída: $ 2.00 /1m tokens GLM‑4.6 is a high‑capacity LLM with a 200K‑token context window, strong coding and reasoning abilities, and enhanced tool‑use capabilities. Chamadas de função Raciocínio Funções JSON @z-ai/glm-4.5v Entrada: $ 0.60 /1m tokens Saída: $ 1.80 /1m tokens A 106 B‑parameter multimodal vision‑language model (12 B active) that handles image, video, and document reasoning with tool‑calling. Entrada: aceita imagens, vídeos Chamadas de função Raciocínio Funções JSON @z-ai/glm-4.5 Entrada: $ 0.38 /1m tokens Saída: $ 1.60 /1m tokens A 355b parameter hybrid reasoning model (32 B active) for intelligent agents, supporting both thinking and non‑thinking modes with tool‑calling. Chamadas de função Raciocínio Funções JSON @z-ai/glm-4.5-air Entrada: $ 0.20 /1m tokens Saída: $ 1.10 /1m tokens A compact 106 B‑parameter hybrid‑reasoning model (12 B active) for intelligent agents, supporting both thinking and non‑thinking modes with tool‑calling. Chamadas de função Raciocínio Funções JSON"
  },
  "docs/pricing.html": {
    "href": "docs/pricing.html",
    "title": "Precificação | AIVAX",
    "keywords": "Precificação O modelo de pagamento da AIVAX é pré-pago, ou seja, você usa nossos serviços com o saldo que adiciona em sua conta. Não enviamos faturas no começo do mês pelo seu uso. Dessa forma, fica previsível saber quanto você irá gastar usando nossos serviços de inferência e criação de agentes. A AIVAX cobra uma pequena taxa (variável por método de pagamento) no momento da adição de créditos para encobrir impostos, taxas do provedor de pagamentos e nossa taxa de serviço. A precificação dos modelos e de inferência é fornecida diretamente pelos provedores de inferência e de seus modelos, como a Google e a OpenAI. Não há nenhuma taxa ou adição em cima destes preços. Você paga o mesmo valor que pagaria para esses provedores diretamente. Usamos diferentes serviços para ajudar você à criar assistentes agênticos. Algumas ferramentas e serviços possuem custo, e estes custos são repassados para sua conta sem nenhuma taxa adicional. A inferência é cobrada em dólares americanos (USD), portanto, pode existir flutuação de moeda ao converter da sua moeda local para o dólar americano. Bring-your-own-key (BYOK) Você pode trazer sua própria chave de API compatível com OpenAI para usar diretamente na AIVAX. Como não sabemos qual modelo você estará usando, não cobramos nada em cima da inferência que você usar em seus modelos. Além disso, ao usar seu próprio modelo com a AIVAX, os limites de taxa são aumentados para 1.500 requisições por minuto, sem limitação ao peso de tokens, que é o equivalente à 60 requisições por segundo. Note que, você ainda é cobrado para serviços que usar com seus próprios modelos, como RAG, pesquisa na internet, geração de imagens, etc. Se sua conta ficar com saldo negativo, você não conseguirá usar nenhum serviço, incluindo inferência para suas próprias API-keys, até que adicione saldo novamente. RAG (coleções) Atualmente, o modelo padrão usado para incorporação de coleções é o Gemini Embedding, o qual é precificado em $ 0,15 para 1 milhão de tokens de entrada. Outros documentos podem ser vetorizados usando outros modelos de incorporação depreciados no sistema, mas ativos por compatibilidade: @google/gemini-embedding-001, $ 0,15 por milhão de tokens. (padrão) @google/text-embedding-004, $ 0,10 por milhão de tokens. (depreciado) @baai/bge-m3, $0,012 por milhão de tokens. (depreciado) No momento, não cobramos taxa de computação e/ou armazenamento de vetores. Para a cobrança ocorrer, precisamos calcular quantos tokens foram processados da entrada, e nem todos os provedores de incorporação retornam a quantia de tokens indexados. Portanto, usamos uma aproximação para calcular a quantia de tokens processados: tokens = ceil(utf8_bytes_count / 4) O resultado dessa aproximação é o que cobramos de você. Ferramentas Ferramentas fornecidas pela AIVAX (ferramentas embutidas) possuem precificações e limites distintos de uma para outra. Para funções que você define para sua API, não há nenhuma cobrança."
  },
  "docs/protocol-functions.html": {
    "href": "docs/protocol-functions.html",
    "title": "Funções do lado do servidor | AIVAX",
    "keywords": "Funções do lado do servidor Important Funções de protocolo não serão mais mantidas e foram substituídas por funções MCP. As funções de protocolo da AIVAX, ou server-side functions, é uma implementação em que a chamada de ferramentas do modelo ocorre do lado do servidor. Similar ao MCP, mas com suporte nativo à autenticação e otimizado para funcionar externamente. As funções de protocolo permitem a tomada de ações no lado do servidor da AIVAX, removendo a necessidade de implementação da função no lado do cliente e integrando com aplicações e serviços existentes. Essas funções esperam um callback através de uma URL, e quando o modelo decide chamar a função, o callback é acessado com os parâmetros informados pela própria assistente. A assistente não sabe qual URL ela está chamando, pois a mesma permanece invisível tanto para a assistente quanto para o usuário. Escolhendo o nome da função O nome da função deve ser simples e determinístico ao que essa função faz. Evite nomes difíceis de advinhar ou que não remetam ao papel da função, pois a assistente pode se confundir e não chamar a função quando apropriado. Como um exemplo, vamos pensar em uma função de consultar um usuário em um banco de dados externo. Os nomes a seguir são bons exemplos para considerar para a chamada: search_user query_user Nomes ruins incluem: search (pouco abrangente) query-user-in-database-data (nome muito grande) pesquisa-usuario (nome não em inglês) search user (nome com caracteres impróprios) Tendo o nome da função, podemos pensar na descrição da função. Escolhendo a descrição da função. A descrição da função deve explicar conceitualmente duas situações: o que ela faz e quando deve ser chamada pela assistente. Essa descrição deve incluir os cenários que a assistente deve considerar chamar ela e quando não deve ser chamada, fornecendo poucos exemplos de chamadas (one-shot) e/ou tornando explícitas as regras da função. Definindo funções de protocolo Essas funções são definidas no AI-gateway, o que permite a criação de agentes inteligentes que realizam ações sem intervenção humana. Elas seguem uma sintaxe simples, esperam o nome da função, uma descrição do que ela faz e os parâmetros de invocação. Funções de protocolo são definidas no AI gateway seguindo o JSON: POST /api/v1/ai-gateways { \"name\": \"my-ai-gateway\", \"parameters\": { ... \"protocolFunctions\": [ { \"name\": \"list_clients\", \"description\": \"Use essa ferramenta para listar e procurar pelos clientes do usuário.\", \"callbackUrl\": \"https://my-external-api.com/api/scp/users\", \"contentFormat\": null }, { \"name\": \"view_client\", \"description\": \"Use essa ferramenta para obter detalhes e pedidos de um cliente através do seu ID.\", \"callbackUrl\": \"https://my-external-api.com/api/scp/users\", \"contentFormat\": { \"type\": \"object\", \"properties\": { \"user_id\": { \"type\": \"string\", \"format\": \"uuid\" } }, \"required\": [\"user_id\"] } } ] } } No snippet acima, você está fornecendo duas funções para seu modelo de IA: list_clients e view_client, o qual irá decidir qual será executada durante o seu raciocínio. Você pode fornecer também um formato de conteúdo JSON para qual o modelo irá chamar sua API fornecendo o contéudo informado. Você também pode definir as lista de funções suportadas através de um endpoint. Toda vez que o modelo receber uma mensagem, ele irá consultar o endpoint fornecido para obter uma lista de funções que ele possa executar. Defina os endpoints de listagem de funções no seu AI gateway: POST /api/v1/ai-gateways { \"name\": \"my-ai-gateway\", \"parameters\": { ... \"protocolFunctionSources\": [ \"https://my-external-api.com/api/scp/listings\" ] } } Os endpoint de fornecimento de funções deve responder seguindo o formato: GET https://my-external-api.com/api/scp/listings { \"functions\": [ { \"name\": \"list_clients\", \"description\": \"Use essa ferramenta para listar e procurar pelos clientes do usuário.\", \"callbackUrl\": \"https://my-external-api.com/api/scp/users\", \"contentFormat\": null }, { \"name\": \"view_client\", \"description\": \"Use essa ferramenta para obter detalhes e pedidos de um cliente através do seu ID.\", \"callbackUrl\": \"https://my-external-api.com/api/scp/users\", \"contentFormat\": { \"type\": \"object\", \"properties\": { \"user_id\": { \"type\": \"string\", \"format\": \"uuid\" } }, \"required\": [\"user_id\"] } } ] } Essas funções são armazenadas em cache por 10 minutos antes de uma nova requisição ser feita no endpoint fornecido. Lidando com chamada de funções As funções são invocadas no endpoint fornecido em callbackUrl através de uma requisição HTTP POST, com o corpo: { \"function\": { \"name\": \"view_client\", \"content\": { \"user_id\": \"3e5a2823-98fa-49a1-831a-0c4c5d33450e\" } }, \"context\": { \"externalUserId\": \"...\", \"moment\": \"2025-05-18T03:36:27\" } } A resposta dessa ação deve responder sempre com um status HTTP OK (2xx ou 3xx), até mesmo para erros que a assistente possa ter cometido. Uma resposta não OK irá indicar para a assistente que não foi possível chamar a função e ela não irá continuar com o que estava planejando fazer. Formato das respostas As respostas bem sucedidas devem ser textuais e serão anexadas como resposta da função do jeito que for respondida pelo endpoint. Não há formato JSON ou estrutura para essa resposta, mas é aconselhável que dê uma resposta simples, humanamente legível, para que a assistente consiga ler o resultado da ação. Erros podem ser comuns, como não encontrar um cliente pelo ID ou algum campo não estiver no formato desejado. Nestes casos, responda com um status OK e no corpo da resposta inclua uma descrição humana do erro e como a assistente pode contornar ele. É garantido que a requisição irá seguir estritamente o JSON Schema do conteúdo fornecido pela definição da função. Funções que não esperam argumentos não devem especificar um formato de conteúdo para essa função. Important Quanto mais funções você definir, mais de entrada tokens você irá consumir no processo de raciocínio. A definição da função, bem como o formato dela, consome tokens do processo de raciocínio. Autenticação A autenticação das requisições são feitas pelo cabeçalho X-Aivax-Nonce enviado em todas as requisições de protocolo das funções, até mesmo as de listagem. Veja o manual de autenticação para entender como autenticar requisições reversas do AIVAX. Autenticação de usuário As chamadas de função enviam um campo $.context.externalUserId contendo a tag de usuário criada em uma sessão de chat. Essa tag pode ser usada para autenticar o usuário que chamou essa função. Considerações de segurança Para o modelo de IA, somente é visível o nome, descrição e formato da função. Ela não é capaz de ver o endpoint para onde essa função aponta. Além disso, ela não possui acesso à tag do usuário que está autenticado em um cliente de chat. Funções especialistas Além das funções embutidas, você pode definir funções especialistas, que executam tarefas específicas na sua conta da AIVAX. Você define funções especialistas pelo esquema de URL aivax://, seguindo o exemplo abaixo: { \"name\": \"my-ai-gateway\", \"parameters\": { ... \"protocolFunctions\": [ { \"name\": \"search_disease\", \"description\": \"Use essa ferramenta para pesquisar por doenças, tratamentos e sintomas.\", \"callbackUrl\": \"aivax://query-collection?collection-id=0196f5ef-9334-742b-a988-f913bb3be5ba&top=5&min=0.4\", \"contentFormat\": { \"type\": \"object\", \"properties\": { \"query\": { \"type\": \"string\", \"description\": \"Nome da doença, tratamento ou sintomas.\" } }, \"required\": [ \"query\" ] } } ] } } A função acima cria uma ferramenta para IA consultar em uma coleção de documentos específica, guiando a assistente do que ela deve pesquisar nessa coleção e o que esperar de uma resposta. Dessa forma, você pode vincular várias coleções de RAG para uma assistente poder buscar conteúdo especialista. Você pode personalizar a descrição das propriedades do JSON Schema de funções especialistas mas não sua estrutura, pois nosso backend espera um formato específico para chamar as funções. Os parâmetros de funções especialistas são fornecidos na URL através de parâmetros da query. Atualmente, apenas uma função especialista existe: query-collection: executa uma pesquisa RAG em uma coleção informada. Parâmetros da query: collection-id: o UUID da coleção que será pesquisada. top: um número indicando quantos documentos devem ser retornados na pesquisa. min: um decimal indicando qual a pontuação mínima de similaridade da busca. Formato JSON da função: { \"type\": \"object\", \"properties\": { \"query\": { \"type\": \"string\", \"description\": \"Conteúdo da pesquisa.\" } }, \"required\": [ \"query\" ] }"
  },
  "index.html": {
    "href": "index.html",
    "title": "Bem-vindo! | AIVAX",
    "keywords": "Bem-vindo! Bem-vindo à documentação da AIVAX."
  },
  "readme.html": {
    "href": "readme.html",
    "title": "Sisk Documentation | AIVAX",
    "keywords": "Sisk Documentation This repository contains the source code of the Sisk Documentation website. Building Firstly, make sure you have docfx installed in your machine. You'll need .NET SDK to install it. Clone this repository. Build the Sisk Framework project and put the .DLL binaries and XML documentation file at the ref/ directory, on the repository root. Run docfx, then docfx serve. Warning Please, do not use the docfx version 2.78.0 or later. This version has a bug that changes the documentation navigation layout. See the tracking issue. Prefer the version 2.76.0: dotnet tool install -g docfx --version 2.76.0 Then you're ready to go and you'll have the static website files at /_site. Contributing Contributions are always welcome. Contribute with spelling corrections, fixing broken links and more. Please, only edit english documentation files. Documentation files for another languages are AI-generated from english files through. Note Please do not edit API specification files (XML). These files are generated. If you want to edit any API documentation, edit it in the repository where the code is hosted."
  }
}