<!DOCTYPE html>
<html>
    <head>
        <meta charset="utf-8">
        <title>Modelos | Open Indexer </title>
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <meta name="title" content="Modelos | Open Indexer ">


        <link rel="icon" href="../assets/img/favicon.ico">
        <link rel="stylesheet" href="../public/docfx.min.css">
        <link rel="stylesheet" href="../public/main.css">

        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="">
        <link href="https://fonts.googleapis.com/css2?family=Geist+Mono:wght@100..900&family=Geist:wght@100..900&display=swap" rel="stylesheet">
        
        <link href="https://cdn.jsdelivr.net/npm/remixicon@4.6.0/fonts/remixicon.css" rel="stylesheet">

        <meta name="docfx:navrel" content="../toc.html">
        <meta name="docfx:tocrel" content="toc.html">

        <meta name="docfx:rel" content="../">


        <meta name="docfx:docurl" content="https://github.com/CypherPotato/open-indexer-docs/blob/master/docs/models.md/#L1">
        <meta name="loc:inThisArticle" content="In this article">
        <meta name="loc:searchResultsCount" content="{count} results for &quot;{query}&quot;">
        <meta name="loc:searchNoResults" content="No results for &quot;{query}&quot;">
        <meta name="loc:tocFilter" content="Filter by title">
        <meta name="loc:nextArticle" content="Next">
        <meta name="loc:prevArticle" content="Previous">
        <meta name="loc:themeLight" content="Light">
        <meta name="loc:themeDark" content="Dark">
        <meta name="loc:themeAuto" content="Auto">
        <meta name="loc:changeTheme" content="Change theme">
        <meta name="loc:copy" content="Copy">
        <meta name="loc:downloadPdf" content="Download PDF">
        
        <script type="module" src="./../public/docfx.min.js"></script>
        <script>
            const theme = localStorage.getItem('theme') || 'auto';
            document.documentElement.setAttribute('data-bs-theme', theme === 'auto' ? (window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light') : theme)
        </script>
        
        <script src="https://unpkg.com/@cypherpotato/el/dist/el.min.js"></script>
                
        <script>            
            function switchLanguage(lang) {
                const docPart = window.location.pathname.match(/\/docs\/((en)\/)?(.*)/)[3];
                const newPath = lang + docPart;
                window.location.href = window.location.origin + newPath;
            }        
        </script>
        
    </head>
    
    
    <body class="tex2jax_ignore" data-layout="" data-yaml-mime="">
        <header class="bg-body border-bottom">
            <nav id="autocollapse" class="navbar navbar-expand-md" role="navigation">
                <div class="container-xxl flex-nowrap">
                    <a class="navbar-brand" href="../index.html">
                        <img id="logo" class="svg" src="../assets/img/Icon.png" alt="Open Indexer">
                        Open Indexer
                    </a>
                    <button class="btn btn-lg d-md-none border-0" type="button" data-bs-toggle="collapse" data-bs-target="#navpanel" aria-controls="navpanel" aria-expanded="false" aria-label="Toggle navigation">
                        <i class="bi bi-three-dots"></i>
                    </button>
                    <div class="collapse navbar-collapse" id="navpanel">
                        <div id="navbar">
                            <form class="search" role="search" id="search">
                                <i class="bi bi-search"></i>
                                <input class="form-control" id="search-query" type="search" disabled="" placeholder="Search" autocomplete="off" aria-label="Search">
                            </form>
                        </div>
                    </div>
                </div>
            </nav>
        </header>

        <main class="container-xxl">
            <div class="toc-offcanvas">
                <div class="offcanvas-md offcanvas-start" tabindex="-1" id="tocOffcanvas" aria-labelledby="tocOffcanvasLabel">
                    <div class="offcanvas-header">
                        <h5 class="offcanvas-title" id="tocOffcanvasLabel">Table of Contents</h5>
                        <button type="button" class="btn-close" data-bs-dismiss="offcanvas" data-bs-target="#tocOffcanvas" aria-label="Close"></button>
                    </div>
                    <div class="offcanvas-body">
                        <nav class="toc" id="toc"></nav>
                    </div>
                </div>
            </div>

            <div class="content">
                <div class="actionbar">
                    <button class="btn btn-lg border-0 d-md-none" style="margin-top: -.65em; margin-left: -.8em" type="button" data-bs-toggle="offcanvas" data-bs-target="#tocOffcanvas" aria-controls="tocOffcanvas" aria-expanded="false" aria-label="Show table of contents">
                        <i class="bi bi-list"></i>
                    </button>

                    <nav id="breadcrumb"></nav>

                    <div id="language-wrapper">
                        <a class="btn border-0 dropdown-toggle show" data-bs-toggle="dropdown" aria-expanded="true" title="Change theme">
                            <i class="bi bi-globe"></i>
                        </a>
                        <ul class="dropdown-menu dropdown-menu-end language-dropdown">
                            <li>
                                <a class="dropdown-item" href="javascript:switchLanguage('/docs/')">
                                    <img src="/assets/flag/brazil.png">
                                    Português
                                </a>
                            </li>
                            <li>
                                <a class="dropdown-item" href="javascript:switchLanguage('/docs/en/')">
                                    <img src="/assets/flag/usa.png">
                                    English
                                </a>
                            </li>
                        </ul>
                    </div>
                </div>

                <article data-uid="">
<h1 id="modelos">Modelos</h1>

<p>O Open Indexer provê modelos de diferentes provedores para tornar o desenvolvimento ainda mais rápido, dispensando a necessidade de ter que configurar uma conta para cada provedor para ter acessos aos seus modelos mais recentes.</p>
<p>Veja a lista abaixo dos modelos disponíveis e suas precificações. Todos os preços consideram o total de entrada e saída de tokens, com ou sem cache.</p>
<p>Todos os preços estão em dólares dos Estados Unidos.</p>
<h2 id="-deepseek"><img src="/assets/icon/deepseek.svg" class="inline-icon"> DeepSeek</h2>
<table>
    <thead>
        <colgroup>
            <col style="width: 30%">
            <col style="width: 20%">
            <col style="width: 50%">
        </colgroup>
        <tr>
            <th>Nome do modelo</th>
            <th>Preço/1m tokens</th>
            <th>Descrição</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>
                @deepseekai/r1-distill-llama-70b
            </td>
            <td>
                <span>$ 2,76</span>
            </td>
            <td>
                Modelo com raciocínio e pensamento profundo, melhor para tarefas mais exigentes.
                <div class="model-capabilities">
                    <div>
                        <i class="ri-lightbulb-line"></i>
                        Pensamento
                    </div>
                    <div>
                        <i class="ri-instance-line"></i>
                        Chamadas de função
                    </div>
                </div>
            </td>
        </tr>        
    </tbody>
</table>
<h2 id="-google"><img src="/assets/icon/google.svg" class="inline-icon"> Google</h2>
<table>
    <thead>
        <colgroup>
            <col style="width: 30%">
            <col style="width: 20%">
            <col style="width: 50%">
        </colgroup>
        <tr>
            <th>Nome do modelo</th>
            <th>Preço/1m tokens</th>
            <th>Descrição</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>
                @google/gemini-2.5-pro
            </td>
            <td>
                <span>$ 12,25</span>
            </td>
            <td>
                Um dos modelos mais poderosos da atualidade.
                <div class="model-capabilities">
                    <div>
                        <i class="ri-lightbulb-line"></i>
                        Pensamento
                    </div>
                    <div>
                        <i class="ri-multi-image-fill"></i>
                        Entrada: aceita imagens, vídeos e áudios
                    </div>
                    <div>
                        <i class="ri-instance-line"></i>
                        Chamadas de função
                    </div>
                </div>
            </td>
        </tr>
        <tr>
            <td>
                @google/gemini-2.5-flash-think
            </td>
            <td>
                <span>$ 4,65</span>
            </td>
            <td>
                Modelo da geração mais recente com raciocínio e
                pensamento integrado.
                <div class="model-capabilities">
                    <div>
                        <i class="ri-lightbulb-line"></i>
                        Pensamento
                    </div>
                    <div>
                        <i class="ri-multi-image-fill"></i>
                        Entrada: aceita imagens, vídeos e áudios
                    </div>
                    <div>
                        <i class="ri-instance-line"></i>
                        Chamadas de função
                    </div>
                </div>
            </td>
        </tr>
        <tr>
            <td>
                @google/gemini-2.5-flash
            </td>
            <td>
                <span>$ 1,31</span>
            </td>
            <td>
                Modelo da geração mais recente, sem pensamento profundo.
                <div class="model-capabilities">
                    <div>
                        <i class="ri-multi-image-fill"></i>
                        Entrada: aceita imagens, vídeos e áudios
                    </div>
                    <div>
                        <i class="ri-instance-line"></i>
                        Chamadas de função
                    </div>
                </div>
            </td>
        </tr>
        <tr>
            <td>
                @google/gemini-2.0-flash
            </td>
            <td>
                <span>$ 0,88</span>
            </td>
            <td>
                Oferece recursos da nova geração, com velocidade melhorada e geração multi-modal.
                <div class="model-capabilities">
                    <div>
                        <i class="ri-multi-image-fill"></i>
                        Entrada: aceita imagens, vídeos e áudios
                    </div>
                    <div>
                        <i class="ri-instance-line"></i>
                        Chamadas de função
                    </div>
                </div>
            </td>
        </tr>
        <tr>
            <td>
                @google/gemma2-9b
            </td>
            <td>
                <span>$ 0,70</span>
            </td>
            <td>
                Modelo rápido, estudo de código aberto da Google para realizar a maioria das tarefas.
                <div class="model-capabilities">
                    <div>
                        <i class="ri-instance-line"></i>
                        Chamadas de função
                    </div>
                </div>
            </td>
        </tr>
        <tr>
            <td>
                @google/gemini-2.0-flash-lite
            </td>
            <td>
                <span>$ 0,67</span>
            </td>
            <td>
                Modelo de uso geral, com reconhecimento de imagens, esperto e rápido. Ótimo para um chat econômico.
                <div class="model-capabilities">
                    <div>
                        <i class="ri-multi-image-fill"></i>
                        Entrada: aceita imagens, vídeos e áudios
                    </div>
                    <div>
                        <i class="ri-instance-line"></i>
                        Chamadas de função
                    </div>
                </div>
            </td>
        </tr>
        <tr>
            <td>
                @google/gemini-1.5-flash-8b
            </td>
            <td>
                <span>$ 0,33</span>
            </td>
            <td>
                Modelo de uso geral da geração anterior, otimizado para tarefas menos exigentes e simples.
                <div class="model-capabilities">
                    <div>
                        <i class="ri-multi-image-fill"></i>
                        Entrada: aceita imagens, vídeos e áudios
                    </div>
                    <div>
                        <i class="ri-instance-line"></i>
                        Chamadas de função
                    </div>
                </div>
            </td>
        </tr>
    </tbody>
</table>
<h2 id="-openai"><img src="/assets/icon/openai.svg" class="inline-icon"> OpenAI</h2>
<table>
    <thead>
        <colgroup>
            <col style="width: 30%">
            <col style="width: 20%">
            <col style="width: 50%">
        </colgroup>
        <tr>
            <th>Nome do modelo</th>
            <th>Preço/1m tokens</th>
            <th>Descrição</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>
                @openai/gpt-4o
            </td>
            <td>
                <span>$ 13,50</span>
            </td>
            <td>
                Versátil, altamente inteligente e top de linha. Um dos modelos mais capazes atualmente.
                <div class="model-capabilities">
                    <div>
                        <i class="ri-multi-image-fill"></i>
                        Entrada: aceita imagens
                    </div>
                    <div>
                        <i class="ri-instance-line"></i>
                        Chamadas de função
                    </div>
                </div>
            </td>
        </tr>
        <tr>
            <td>
                @openai/gpt-4.1
            </td>
            <td>
                <span>$ 11,00</span>
            </td>
            <td>
                Versátil, altamente inteligente e top de linha. Um dos modelos mais capazes atualmente.
                <div class="model-capabilities">
                    <div>
                        <i class="ri-multi-image-fill"></i>
                        Entrada: aceita imagens
                    </div>
                    <div>
                        <i class="ri-instance-line"></i>
                        Chamadas de função
                    </div>
                </div>
            </td>
        </tr>
        <tr>
            <td>
                @openai/o1-mini
            </td>
            <td>
                <span>$ 6,50</span>
            </td>
            <td>
                Um pequeno e esperto modelo com raciocínio.
                <div class="model-capabilities">
                    <div>
                        <i class="ri-lightbulb-line"></i>
                        Pensamento
                    </div>
                </div>
            </td>
        </tr>
        <tr>
            <td>
                @openai/gpt-4o-mini
            </td>
            <td>
                <span>$ 1,31</span>
            </td>
            <td>
                Rápido e barato para tarefas focadas.
                <div class="model-capabilities">
                    <div>
                        <i class="ri-multi-image-fill"></i>
                        Entrada: aceita imagens
                    </div>
                    <div>
                        <i class="ri-instance-line"></i>
                        Chamadas de função
                    </div>
                </div>
            </td>
        </tr>
        <tr>
            <td>
                @openai/gpt-4.1-nano
            </td>
            <td>
                <span>$ 0,88</span>
            </td>
            <td>
                O mais rápido e barato modelo do GPT 4.1.
                <div class="model-capabilities">
                    <div>
                        <i class="ri-multi-image-fill"></i>
                        Entrada: aceita imagens
                    </div>
                    <div>
                        <i class="ri-instance-line"></i>
                        Chamadas de função
                    </div>
                </div>
            </td>
        </tr>
    </tbody>
</table>
<h2 id="-meta-ai"><img src="/assets/icon/meta.svg" class="inline-icon"> Meta AI</h2>
<table>
    <thead>
        <colgroup>
            <col style="width: 30%">
            <col style="width: 20%">
            <col style="width: 50%">
        </colgroup>
        <tr>
            <th>Nome do modelo</th>
            <th>Preço/1m tokens</th>
            <th>Descrição</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>
                @metaai/llama-3.3-70b
            </td>
            <td>
                <span>$ 2,40</span>
            </td>
            <td>
                Modelo de geração anterior com bastantes parâmetros e velocidade surpreendentemente rápida.
                <div class="model-capabilities">
                    <div>
                        <i class="ri-instance-line"></i>
                        Chamadas de função
                    </div>
                </div>
            </td>
        </tr>
        <tr>
            <td>
                @metaai/llama-4-maverick-17b
            </td>
            <td>
                <span>$ 1,40</span>
            </td>
            <td>
                Modelo rápido, com 17 bilhões de parâmetros ativados e 128 especialistas.
                <div class="model-capabilities">
                    <div>
                        <i class="ri-multi-image-fill"></i>
                        Entrada: aceita imagens
                    </div>
                    <div>
                        <i class="ri-instance-line"></i>
                        Chamadas de função
                    </div>
                </div>
            </td>
        </tr>
        <tr>
            <td>
                @metaai/llama-4-scout-17b
            </td>
            <td>
                <span>$ 0,79</span>
            </td>
            <td>
                Menor versão da família Llama 4 com 17 bilhões de parâmetros ativados e 16 especialistas.
                <div class="model-capabilities">
                    <div>
                        <i class="ri-multi-image-fill"></i>
                        Entrada: aceita imagens
                    </div>
                    <div>
                        <i class="ri-instance-line"></i>
                        Chamadas de função
                    </div>
                </div>
            </td>
        </tr>
        <tr>
            <td>
                @metaai/llama-3.1-8b
            </td>
            <td>
                <span>$ 0,23</span>
            </td>
            <td>
                Modelo barato e rápido para tarefas menos exigentes.
                <div class="model-capabilities">
                    <div>
                        <i class="ri-instance-line"></i>
                        Chamadas de função
                    </div>
                </div>
            </td>
        </tr>
    </tbody>
</table>
<h2 id="-groq"><img src="/assets/icon/groq.svg" class="inline-icon"> Groq</h2>
<table>
    <thead>
        <colgroup>
            <col style="width: 30%">
            <col style="width: 20%">
            <col style="width: 50%">
        </colgroup>
        <tr>
            <th>Nome do modelo</th>
            <th>Preço/1m tokens</th>
            <th>Descrição</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>
                @groq/compound-beta
            </td>
            <td>
                <span>$ 3,25</span>
            </td>
            <td>
                Agente de conversação que pesquisa na internet para contextualização e informação em tempo real.
                <div class="model-capabilities">
                    <div>
                        <i class="ri-global-line"></i>
                        Live data
                    </div>
                    <div>
                        <i class="ri-multi-image-fill"></i>
                        Entrada: aceita imagens
                    </div>
                    <div>
                        <i class="ri-instance-line"></i>
                        Chamadas de função
                    </div>
                </div>
            </td>
        </tr>
        <tr>
            <td>
                @groq/compound-beta-mini
            </td>
            <td>
                <span>$ 2,60</span>
            </td>
            <td>
                Versão menor da família Compound, que possui menos especialistas.
                <div class="model-capabilities">
                    <div>
                        <i class="ri-global-line"></i>
                        Live data
                    </div>
                    <div>
                        <i class="ri-multi-image-fill"></i>
                        Entrada: aceita imagens
                    </div>
                    <div>
                        <i class="ri-instance-line"></i>
                        Chamadas de função
                    </div>
                </div>
            </td>
        </tr>
    </tbody>
</table>
<h2 id="-qwen"><img src="/assets/icon/qwen.svg" class="inline-icon"> Qwen</h2>
<table>
    <thead>
        <colgroup>
            <col style="width: 30%">
            <col style="width: 20%">
            <col style="width: 50%">
        </colgroup>
        <tr>
            <th>Nome do modelo</th>
            <th>Preço/1m tokens</th>
            <th>Descrição</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>
                @qwen/qwq-32b
            </td>
            <td>
                <span>$ 1,23</span>
            </td>
            <td>
                Modelo de conversação com pensamento e raciocínio para resolução de tarefas complexas.
                <div class="model-capabilities">
                    <div>
                        <i class="ri-lightbulb-line"></i>
                        Pensamento
                    </div>
                    <div>
                        <i class="ri-instance-line"></i>
                        Chamadas de função
                    </div>
                </div>
            </td>
        </tr>
    </tbody>
</table>

</article>

                <div class="contribution d-print-none">
                    <a href="https://github.com/CypherPotato/open-indexer-docs/blob/master/docs/models.md/#L1" class="edit-link">Edit this page</a>
                </div>

                <div class="next-article d-print-none border-top" id="nextArticle"></div>

            </div>

            <div class="affix">
                <nav id="affix"></nav>
            </div>
        </main>

        <div class="container-xxl search-results" id="search-results"></div>

        <footer class="border-top text-secondary">
            <div class="container-xxl">
                <div class="flex-fill">
                    <span>Made with <a href="https://dotnet.github.io/docfx">docfx</a></span>
                </div>
            </div>
            <script>
                if (window.location.pathname.startsWith('/docs/')) {
                    document.getElementById('language-wrapper').style.display = 'block';
                }
                
                function splitText(text, words) {
                    if (!Array.isArray(words)) return [];
                    const escapedWords = words.map(word =>
                        word.replace(/([.*+?^${}()|[\]\\])/g, '\\$1').replace(/\s/g, '\\$&'));
                        
                    escapedWords.sort((a, b) => b.length - a.length || b.localeCompare(a, 'en-US', { sensitivity: 'base' }));
                    const pattern = new RegExp(`\\b(${escapedWords.join('|')})\\b`, 'gi');
                    const splitResult = text.split(pattern);
                    const cleanedResult = splitResult.filter(segment => segment !== '');
                    return cleanedResult;
                }
                
                function runPostHljsFunctions() {
                    if (!document.querySelector("pre>code")) {
                        return;
                    }
                    if (!document.querySelector(".hljs")) {
                        setTimeout(runPostHljsFunctions, 100);
                        return;
                    }
                    
                    function highlightMissingCodeTokens(pre) {
                        const tokenClasses = [
                            "HttpResponse", "HttpRequest", "File", "Task",
                            "Router", "Route", "StringContent", "StreamContent",
                            "JsonContent", "RegexRoute", "HtmlContent", "CancellationTokenSource",
                            "HttpContext", "Stream", "MultipartObject", "Thread", "Task", "Encoding",
                            "HttpKnownHeaderNames", "HttpMethod", "List", "JsonSerializer",
                            "LogStream", "HttpServer", "RotatingLogPolicy", "StringBuilder",
                            "Console", "HttpRequestEventSource", "HttpWebSocket", "X509Certificate2",
                            "AppDomain", "Path", "Directory", "HttpServerConfiguration", "ListeningHost",
                            "ByteArrayContent", "ForwardingResolver", "IPAddress", "IPEndPoint",
                            "HttpServerExecutionResult", "ArgumentNullException", "JsonSerializerOptions",
                            "DbContext"
                        ];
                        const tokenValues = [
                            "RouteMethod", "Guid", "RequestHandlerExecutionMode", "HttpStatusCode",
                            "HttpStatusInformation", "DateTime", "TimeSpan", "RouterMethod",
                            "ListeningPort"
                        ];
                        const tokenInterfaces = [
                            "IRequestHandler", "IEnumerable", "ICollection", "IList"
                        ];
                        
                        function runStyles(node) {
                            if (node.nodeType === 3) {
                                applyStyles(node);
                                
                            } else if (node.nodeType === 1) {
                                
                                const prohibitedClasses = ["hljs-comment", "hljs-string"];
                                
                                if (! prohibitedClasses.some(cls => node.classList.contains(cls))) {
                                    for(const child of node.childNodes) {
                                        runStyles(child);
                                    }
                                }
                            }
                        }
                        
                        function applyStyles(textNode) {
                            const text = textNode.textContent;
                            const fragment = [];
                            
                            for (const token of splitText(text, [...tokenClasses, ...tokenValues, ...tokenInterfaces])) {
                                if (tokenClasses.includes(token)) {
                                    fragment.push(el("span.hljs-meta", token));
                                    
                                } else if (tokenValues.includes(token)) {
                                    fragment.push(el("span.hljs-meta-value", token));
                                    
                                } else if (tokenInterfaces.includes(token)) {
                                    fragment.push(el("span.hljs-meta-interface", token));
                                    
                                } else {
                                    fragment.push(token);
                                }
                            }
                            
                            textNode.replaceWith(el.fragment(...fragment));
                        }
                        
                        const code = pre.querySelector("code");
                        if (code && (code.classList.contains("lang-csharp") || code.classList.contains("lang-cs"))) {
                            runStyles(code);
                        }
                    }
                    
                    function addLineNumbers(pre) {
                        const code = pre.querySelector("code");
                        if (!code) return;
                        
                        var lines = (code.textContent.match(/\n/g) || []).length;
                        
                        if (lines <= 1) {
                            return;
                        }
                        
                        const lineElements = [];
                        for (let i = 1; i <= lines; i++) {
                            lineElements.push(el("span.hljs-line-number", i + "\n"));
                        }
                        
                        code.prepend(el("div.line-numbers", ...lineElements));
                        code.classList.add("has-line-numbers");
                    }
                                        
                    document.querySelectorAll("pre").forEach(pre => {
                        highlightMissingCodeTokens(pre);
                        addLineNumbers(pre);
                    });
                }
                
                runPostHljsFunctions();
            </script>
        </footer>
    </body>
</html>