# AI Gateway

Os gateways de AI √© um servi√ßo que a AIVAX fornece para criar um t√∫nel de infer√™ncia entre um modelo de LLM e uma base de conhecimento. Nele √© poss√≠vel:

- Criar um modelo com instru√ß√µes personalizadas
- Usar um modelo provido por voc√™ atrav√©s de um endpoint OpenAI compat√≠vel, ou usar um modelo disponibilizado pela AIVAX
- Personalizar par√¢metros de infer√™ncia, como temperatura, top_p, prefill
- Usar uma cole√ß√£o de conhecimento como funda√ß√£o de respostas para IA

Dentre outros recursos. Com o AI Gateway, voc√™ cria um modelo pronto para uso, parametrizado e fundamentado nas instru√ß√µes que voc√™ definir.

## Modelos

Voc√™ pode trazer um modelo de IA compat√≠vel com a interface OpenAI para o gateway de IA. Se voc√™ trazer seu modelo de IA, iremos cobrar apenas pela pesquisa de documentos anexada na IA. Voc√™ tamb√©m pode usar um dos modelos abaixo que j√° est√£o prontos para come√ßar com o AIVAX.

Ao usar um modelo, voc√™ perceber√° que alguns s√£o mais inteligentes que outros para determinadas tarefas. Alguns modelos s√£o melhores com certas estrat√©gias de obten√ß√£o de dados do que outros. Realize testes para encontrar o melhor modelo.

Voc√™ pode ver os modelos dispon√≠veis na [p√°gina de modelos](/docs/models).

## Usar um gateway de IA

A AIVAX prov√™ um endpoint compat√≠vel com a interface OpenAI atrav√©s de um AI-gateway, o que facilita a integra√ß√£o do modelo criado pela AIVAX com aplica√ß√µes e SDKs existentes. Vale ressaltar que somente algumas propriedades s√£o suportadas.

Em um gateway de IA, voc√™ j√° configura os par√¢metros do modelo, como System Prompt, temperatura e nome do modelo. Ao usar esse endpoint, alguns valores do gateway podem ser sobrescritos pela requisi√ß√£o.

#### Requisi√ß√£o

<div class="request-item post">
    <span>POST</span>
    <span>
        /api/v1/chat-completions
    </span>
</div>

```json
{
    "model": "0197cb0f-893a-7b7d-be0a-71ada1208aaf",
    "messages": [
        {
            "role": "user",
            "content": "Quem √© voc√™?"
        }
    ],
    "stream": false
}
```

#### Resposta para n√£o-streaming

```json
{
    "id": "0197dbdc-6456-7d54-b7ec-04cb9c80f460",
    "object": "chat.completion",
    "created": 1751740343,
    "model": "@google/gemini-2.5-flash",
    "choices": [
        {
            "index": 0,
            "message": {
                "role": "assistant",
                "completion_text": "Oi! üòä Eu sou a Zia, a assistente inteligente do Z√© do Ingresso. T√¥ aqui pra te ajudar com tudo sobre ingressos, eventos, e tudo que rola na nossa querida S√£o Jos√© do Rio Preto. Se precisar de alguma coisa, tipo saber sobre nomea√ß√£o de ja o bagulho, s√≥ chamar! Vamos juntos aproveitar tudo o que tiver rolando! O que voc√™ precisa? ü•≥ ",
                "refusal": null,
                "annotations": []
            },
            "logprobs": null,
            "finish_reason": "stop"
        }
    ],
    "usage": {
        "prompt_tokens": 1118,
        "completion_tokens": 88,
        "total_tokens": 1206
    },
    "service_tier": "default"
}
```

#### Resposta streaming

```text
data: {"id":"0197dbde-c40b-720d-a13e-f689c303c571","object":"chat.completion.chunk","created":1751740498,"model":"@google/gemini-2.5-flash","system_fingerprint":"fp_y8jidd","choices":[{"index":0,"finish_reason":null,"delta":{"role":"assistant","content":""}}],"usage":null,"sentinel_usage":null}

...

data: {"id":"0197dbde-c88c-7764-8017-c1fee0d79096","object":"chat.completion.chunk","created":1751740500,"model":"@google/gemini-2.5-flash","system_fingerprint":"fp_2he7ot","choices":[{"index":0,"finish_reason":null,"delta":{"content":""}}],"usage":null,"sentinel_usage":null}

data: {"id":"0197dbde-c890-7329-9e65-faecbe158efa","object":"chat.completion.chunk","created":1751740500,"model":"@aivax\/sentinel-mini","system_fingerprint":"fp_q6qh7x","choices":[{"index":0,"finish_reason":"STOP","delta":{}}],"usage":{"prompt_tokens":1097,"completion_tokens":92,"total_tokens":1189},"sentinel_usage":null}
```

## Uso com SDKs

Por prover endpoints compat√≠veis com a interface OpenAI, a AIVAX √© totalmente compat√≠vel com SDKs existentes, facilitando a integra√ß√£o plug-and-play.

Veja o exemplo abaixo:

```python
from openai import OpenAI
 
client = OpenAI(
    base_url="https://inference.aivax.net/api/v1",
    api_key="oky_gr5u...oqbfd3d9y"
)
 
response = client.chat.completions.create(
    model="my-gateway:50c3", # you can also provide your ai-gateway full ID here
    messages=[
        {"role": "user", "content": "Explain why AI-gateways are useful."}
    ]
)
 
print(response.choices[0].message.content)
```

No momento, a AIVAX s√≥ suporta o formato `chat/completions`. No futuro, pretendemos criar suporte para a API Responses.