# Models

AIVAX provides models from different providers to make development even faster, eliminating the need to configure an account for each provider to access their latest models.

See the list below of available models and their pricing. All prices consider the total input and output tokens, with or without cache.

All prices are in United States dollars.

## <img src="/assets/icon/deepseekai.svg" class="inline-icon"> deepseekai

<table>
    <thead>
        <colgroup>
            <col style="width: 30%" />
            <col style="width: 20%" />
            <col style="width: 50%" />
        </colgroup>
        <tr>
            <th>Model name</th>
            <th>Pricing</th>
            <th>Description</th>
        </tr>
    </thead>
    <tbody>
<tr>
    <td>
        <code>
            @deepseekai/r1
        </code>
    </td>
    <td>
        <div class="item-pricing">
            <small>
                Input:
            </small>
            <div>
                $ 0.70 <small>/1m tokens</small>
            </div>
        </div>
        
        <div class="item-pricing">
            <small>
                Output:
            </small>
            <div>
                $ 2.50 <small>/1m tokens</small>
            </div>
        </div>
    </td>
    <td>
        High-capacity chain-of-thought reasoning model with a massive 164K token context window. Ideal for complex math, step-by-step logic, and advanced code authoring.
        <div class="model-capabilities">
<div>
    <i class="ri-instance-line"></i>
    Function calls
</div>
<div>
    <i class="ri-lightbulb-line"></i>
    Reasoning
</div>
<div>
    <i class="ri-braces-line"></i>
    JSON functions
</div>
        </div>
    </td>
</tr>
<tr>
    <td>
        <code>
            @deepseekai/v3.1
        </code>
    </td>
    <td>
        <div class="item-pricing">
            <small>
                Input:
            </small>
            <div>
                $ 0.55 <small>/1m tokens</small>
            </div>
        </div>
        
        <div class="item-pricing">
            <small>
                Output:
            </small>
            <div>
                $ 1.66 <small>/1m tokens</small>
            </div>
        </div>
    </td>
    <td>
        A 675B-parameter hybrid LLM with 163K context that supports both thinking and non‑thinking chat modes.
        <div class="model-capabilities">
<div>
    <i class="ri-instance-line"></i>
    Function calls
</div>
<div>
    <i class="ri-lightbulb-line"></i>
    Reasoning
</div>
<div>
    <i class="ri-braces-line"></i>
    JSON functions
</div>
        </div>
    </td>
</tr>
<tr>
    <td>
        <code>
            @deepseekai/v3
        </code>
    </td>
    <td>
        <div class="item-pricing">
            <small>
                Input:
            </small>
            <div>
                $ 0.50 <small>/1m tokens</small>
            </div>
        </div>
        
        <div class="item-pricing">
            <small>
                Output:
            </small>
            <div>
                $ 1.50 <small>/1m tokens</small>
            </div>
        </div>
    </td>
    <td>
        Balanced reasoning model with a 128K token context. Delivers efficient tool calling, reliable code assistance, and strong analytical output at lower cost.
        <div class="model-capabilities">
<div>
    <i class="ri-instance-line"></i>
    Function calls
</div>
<div>
    <i class="ri-braces-line"></i>
    JSON functions
</div>
        </div>
    </td>
</tr>
<tr>
    <td>
        <code>
            @deepseekai/r1-distill-llama-70b
        </code>
    </td>
    <td>
        <div class="item-pricing">
            <small>
                Input:
            </small>
            <div>
                $ 0.75 <small>/1m tokens</small>
            </div>
        </div>
        
        <div class="item-pricing">
            <small>
                Output:
            </small>
            <div>
                $ 0.99 <small>/1m tokens</small>
            </div>
        </div>
    </td>
    <td>
        Distilled Llama 3 70B model emulating R1’s chain-of-thought prowess. Offers transparent reasoning blocks and fast throughput on Groq hardware.
        <div class="model-capabilities">
<div>
    <i class="ri-lightbulb-line"></i>
    Reasoning
</div>
<div>
    <i class="ri-braces-line"></i>
    JSON functions
</div>
        </div