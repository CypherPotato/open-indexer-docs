# Modelos

A AIVAX provê modelos de diferentes provedores para tornar o desenvolvimento ainda mais rápido, dispensando a necessidade de ter que configurar uma conta para cada provedor para ter acessos aos seus modelos mais recentes.

Veja a lista abaixo dos modelos disponíveis e suas precificações. Todos os preços consideram o total de entrada e saída de tokens, com ou sem cache.

Todos os preços estão em dólares dos Estados Unidos.

## <img src="/assets/icon/amazon.svg" class="inline-icon"> amazon

<table>
    <thead>
        <colgroup>
            <col style="width: 30%" />
            <col style="width: 20%" />
            <col style="width: 50%" />
        </colgroup>
        <tr>
            <th>Nome do modelo</th>
            <th>Preços</th>
            <th>Descrição</th>
        </tr>
    </thead>
    <tbody>
<tr>
    <td>
        <code>
            @amazon/nova-pro
        </code>
    </td>
    <td>
        <div class="item-pricing">
            <small>
                Entrada:
            </small>
            <div>
                $ 0.80 <small>/1m tokens</small>
            </div>
        </div>
        
        <div class="item-pricing">
            <small>
                Saída:
            </small>
            <div>
                $ 3.20 <small>/1m tokens</small>
            </div>
        </div>
    </td>
    <td>
        A highly capable multimodal model with the best combination of accuracy, speed, and cost for a wide range of tasks.
        <div class="model-capabilities">
<div>
    <i class="ri-image-circle-line"></i>
    Entrada: aceita imagens, vídeos
</div>
<div>
    <i class="ri-instance-line"></i>
    Chamadas de função
</div>
<div>
    <i class="ri-lightbulb-line"></i>
    Raciocínio
</div>
<div>
    <i class="ri-braces-line"></i>
    Funções JSON
</div>
        </div>
    </td>
</tr>
<tr>
    <td>
        <code>
            @amazon/nova-lite
        </code>
    </td>
    <td>
        <div class="item-pricing">
            <small>
                Entrada:
            </small>
            <div>
                $ 0.06 <small>/1m tokens</small>
            </div>
        </div>
        
        <div class="item-pricing">
            <small>
                Saída:
            </small>
            <div>
                $ 0.24 <small>/1m tokens</small>
            </div>
        </div>
    </td>
    <td>
        A very low cost multimodal model that is lightning fast for processing image, video, and text inputs.
        <div class="model-capabilities">
<div>
    <i class="ri-image-circle-line"></i>
    Entrada: aceita imagens, vídeos
</div>
<div>
    <i class="ri-instance-line"></i>
    Chamadas de função
</div>
<div>
    <i class="ri-lightbulb-line"></i>
    Raciocínio
</div>
<div>
    <i class="ri-braces-line"></i>
    Funções JSON
</div>
        </div>
    </td>
</tr>
<tr>
    <td>
        <code>
            @amazon/nova-micro
        </code>
    </td>
    <td>
        <div class="item-pricing">
            <small>
                Entrada:
            </small>
            <div>
                $ 0.04 <small>/1m tokens</small>
            </div>
        </div>
        
        <div class="item-pricing">
            <small>
                Saída:
            </small>
            <div>
                $ 0.14 <small>/1m tokens</small>
            </div>
        </div>
    </td>
    <td>
        A text-only model that delivers the lowest latency responses at very low cost.
        <div class="model-capabilities">
<div>
    <i class="ri-instance-line"></i>
    Chamadas de função
</div>
<div>
    <i class="ri-braces-line"></i>
    Funções JSON
</div>
        </div>
    </td>
</tr>
    </tbody>
</table>

## <img src="/assets/icon/anthropic.svg" class="inline-icon"> anthropic

<table>
    <thead>
        <colgroup>
            <col style="width: 30%" />
            <col style="width: 20%" />
            <col style="width: 50%" />
        </colgroup>
        <tr>
            <th>Nome do modelo</th>
            <th>Preços</th>
            <th>Descrição</th>
        </tr>
    </thead>
    <tbody>
<tr>
    <td>
        <code>
            @anthropic/claude-4.1-opus
        </code>
    </td>
    <td>
        <div class="item-pricing">
            <small>
                Entrada:
            </small>
            <div>
                $ 15.00 <small>/1m tokens</small>
            </div>
        </div>
        <div class="item-pricing">
    <small>
        Entrada (em cache):
    </small>
    <div>
        $ 1.50 <small>/1m tokens</small>
    </div>
</div>
        <div class="item-pricing">
            <small>
                Saída:
            </small>
            <div>
                $ 75.00 <small>/1m tokens</small>
            </div>
        </div>
    </td>
    <td>
        Claude Opus 4.1 is Anthropic’s flagship model, offering improved performance in coding, reasoning, and agentic tasks.
        <div class="model-capabilities">
<div>
    <i class="ri-image-circle-line"></i>
    Entrada: aceita imagens
</div>
<div>
    <i class="ri-instance-line"></i>
    Chamadas de função
</div>
<div>
    <i class="ri-lightbulb-line"></i>
    Raciocínio
</div>
<div>
    <i class="ri-braces-line"></i>
    Funções JSON
</div>
        </div>
    </td>
</tr>
<tr>
    <td>
        <code>
            @anthropic/claude-4.5-opus
        </code>
    </td>
    <td>
        <div class="item-pricing">
            <small>
                Entrada:
            </small>
            <div>
                $ 5.00 <small>/1m tokens</small>
            </div>
        </div>
        <div class="item-pricing">
    <small>
        Entrada (em cache):
    </small>
    <div>
        $ 0.50 <small>/1m tokens</small>
    </div>
</div>
        <div class="item-pricing">
            <small>
                Saída:
            </small>
            <div>
                $ 25.00 <small>/1m tokens</small>
            </div>
        </div>
    </td>
    <td>
        Claude Opus 4.5 is Anthropic’s latest reasoning model, developed for advanced software engineering, complex agent workflows, and extended computer tasks.
        <div class="model-capabilities">
<div>
    <i class="ri-image-circle-line"></i>
    Entrada: aceita imagens
</div>
<div>
    <i class="ri-instance-line"></i>
    Chamadas de função
</div>
<div>
    <i class="ri-lightbulb-line"></i>
    Raciocínio
</div>
<div>
    <i class="ri-braces-line"></i>
    Funções JSON
</div>
        </div>
    </td>
</tr>
<tr>
    <td>
        <code>
            @anthropic/claude-4.5-sonnet
        </code>
    </td>
    <td>
        <div class="item-pricing">
            <small>
                Entrada:
            </small>
            <div>
                $ 3.00 <small>/1m tokens</small>
            </div>
        </div>
        <div class="item-pricing">
    <small>
        Entrada (em cache):
    </small>
    <div>
        $ 0.30 <small>/1m tokens</small>
    </div>
</div>
        <div class="item-pricing">
            <small>
                Saída:
            </small>
            <div>
                $ 15.00 <small>/1m tokens</small>
            </div>
        </div>
    </td>
    <td>
        Claude Sonnet 4.5 is the newest model in the Sonnet series, offering improvements and updates over Sonnet 4.
        <div class="model-capabilities">
<div>
    <i class="ri-image-circle-line"></i>
    Entrada: aceita imagens
</div>
<div>
    <i class="ri-instance-line"></i>
    Chamadas de função
</div>
<div>
    <i class="ri-lightbulb-line"></i>
    Raciocínio
</div>
<div>
    <i class="ri-braces-line"></i>
    Funções JSON
</div>
        </div>
    </td>
</tr>
<tr>
    <td>
        <code>
            @anthropic/claude-4-sonnet
        </code>
    </td>
    <td>
        <div class="item-pricing">
            <small>
                Entrada:
            </small>
            <div>
                $ 3.00 <small>/1m tokens</small>
            </div>
        </div>
        <div class="item-pricing">
    <small>
        Entrada (em cache):
    </small>
    <div>
        $ 0.30 <small>/1m tokens</small>
    </div>
</div>
        <div class="item-pricing">
            <small>
                Saída:
            </small>
            <div>
                $ 15.00 <small>/1m tokens</small>
            </div>
        </div>
    </td>
    <td>
        Anthropic's mid-size model with superior intelligence for high-volume uses in coding, in-depth research, agents, & more.
        <div class="model-capabilities">
<div>
    <i class="ri-image-circle-line"></i>
    Entrada: aceita imagens
</div>
<div>
    <i class="ri-instance-line"></i>
    Chamadas de função
</div>
<div>
    <i class="ri-lightbulb-line"></i>
    Raciocínio
</div>
<div>
    <i class="ri-braces-line"></i>
    Funções JSON
</div>
        </div>
    </td>
</tr>
<tr>
    <td>
        <code>
            @anthropic/claude-4.5-haiku
        </code>
    </td>
    <td>
        <div class="item-pricing">
            <small>
                Entrada:
            </small>
            <div>
                $ 1.00 <small>/1m tokens</small>
            </div>
        </div>
        <div class="item-pricing">
    <small>
        Entrada (em cache):
    </small>
    <div>
        $ 0.10 <small>/1m tokens</small>
    </div>
</div>
        <div class="item-pricing">
            <small>
                Saída:
            </small>
            <div>
                $ 5.00 <small>/1m tokens</small>
            </div>
        </div>
    </td>
    <td>
        Claude Haiku 4.5 is Anthropic’s fastest and most efficient model, offering near-frontier intelligence with much lower cost and latency than larger Claude models.
        <div class="model-capabilities">
<div>
    <i class="ri-image-circle-line"></i>
    Entrada: aceita imagens
</div>
<div>
    <i class="ri-instance-line"></i>
    Chamadas de função
</div>
<div>
    <i class="ri-braces-line"></i>
    Funções JSON
</div>
        </div>
    </td>
</tr>
<tr>
    <td>
        <code>
            @anthropic/claude-3.5-haiku
        </code>
    </td>
    <td>
        <div class="item-pricing">
            <small>
                Entrada:
            </small>
            <div>
                $ 0.80 <small>/1m tokens</small>
            </div>
        </div>
        <div class="item-pricing">
    <small>
        Entrada (em cache):
    </small>
    <div>
        $ 0.08 <small>/1m tokens</small>
    </div>
</div>
        <div class="item-pricing">
            <small>
                Saída:
            </small>
            <div>
                $ 4.00 <small>/1m tokens</small>
            </div>
        </div>
    </td>
    <td>
        Claude 3.5 Haiku is the next generation of our fastest model. For a similar speed to Claude 3 Haiku, Claude 3.5 Haiku improves across every skill set and surpasses Claude 3 Opus, the largest model in our previous generation, on many intelligence benchmarks.
        <div class="model-capabilities">
<div>
    <i class="ri-image-circle-line"></i>
    Entrada: aceita imagens
</div>
<div>
    <i class="ri-instance-line"></i>
    Chamadas de função
</div>
<div>
    <i class="ri-braces-line"></i>
    Funções JSON
</div>
        </div>
    </td>
</tr>
<tr>
    <td>
        <code>
            @anthropic/claude-3-haiku
        </code>
    </td>
    <td>
        <div class="item-pricing">
            <small>
                Entrada:
            </small>
            <div>
                $ 0.25 <small>/1m tokens</small>
            </div>
        </div>
        <div class="item-pricing">
    <small>
        Entrada (em cache):
    </small>
    <div>
        $ 0.03 <small>/1m tokens</small>
    </div>
</div>
        <div class="item-pricing">
            <small>
                Saída:
            </small>
            <div>
                $ 1.25 <small>/1m tokens</small>
            </div>
        </div>
    </td>
    <td>
        Claude 3 Haiku is Anthropic's fastest model yet, designed for enterprise workloads which often involve longer prompts.
        <div class="model-capabilities">
<div>
    <i class="ri-image-circle-line"></i>
    Entrada: aceita imagens
</div>
<div>
    <i class="ri-instance-line"></i>
    Chamadas de função
</div>
<div>
    <i class="ri-braces-line"></i>
    Funções JSON
</div>
        </div>
    </td>
</tr>
    </tbody>
</table>

## <img src="/assets/icon/cohere.svg" class="inline-icon"> cohere

<table>
    <thead>
        <colgroup>
            <col style="width: 30%" />
            <col style="width: 20%" />
            <col style="width: 50%" />
        </colgroup>
        <tr>
            <th>Nome do modelo</th>
            <th>Preços</th>
            <th>Descrição</th>
        </tr>
    </thead>
    <tbody>
<tr>
    <td>
        <code>
            @cohere/command-a
        </code>
    </td>
    <td>
        <div class="item-pricing">
            <small>
                Entrada:
            </small>
            <div>
                $ 2.50 <small>/1m tokens</small>
            </div>
        </div>
        
        <div class="item-pricing">
            <small>
                Saída:
            </small>
            <div>
                $ 10.00 <small>/1m tokens</small>
            </div>
        </div>
    </td>
    <td>
        Command A is Cohere's most performant model to date, excelling at tool use, agents, retrieval augmented generation (RAG), and multilingual use cases. Command A has a context length of 256K, only requires two GPUs to run, and has 150% higher throughput compared to Command R+ 08-2024.
        <div class="model-capabilities">
<div>
    <i class="ri-image-circle-line"></i>
    Entrada: aceita imagens
</div>
<div>
    <i class="ri-instance-line"></i>
    Chamadas de função
</div>
<div>
    <i class="ri-braces-line"></i>
    Funções JSON
</div>
        </div>
    </td>
</tr>
    </tbody>
</table>

## <img src="/assets/icon/deepseekai.svg" class="inline-icon"> deepseekai

<table>
    <thead>
        <colgroup>
            <col style="width: 30%" />
            <col style="width: 20%" />
            <col style="width: 50%" />
        </colgroup>
        <tr>
            <th>Nome do modelo</th>
            <th>Preços</th>
            <th>Descrição</th>
        </tr>
    </thead>
    <tbody>
<tr>
    <td>
        <code>
            @deepseekai/r1
        </code>
    </td>
    <td>
        <div class="item-pricing">
            <small>
                Entrada:
            </small>
            <div>
                $ 0.50 <small>/1m tokens</small>
            </div>
        </div>
        <div class="item-pricing">
    <small>
        Entrada (em cache):
    </small>
    <div>
        $ 0.40 <small>/1m tokens</small>
    </div>
</div>
        <div class="item-pricing">
            <small>
                Saída:
            </small>
            <div>
                $ 2.15 <small>/1m tokens</small>
            </div>
        </div>
    </td>
    <td>
        The DeepSeek R1 model has undergone a minor version upgrade, with the current version being DeepSeek-R1-0528.
        <div class="model-capabilities">
<div>
    <i class="ri-instance-line"></i>
    Chamadas de função
</div>
<div>
    <i class="ri-lightbulb-line"></i>
    Raciocínio
</div>
<div>
    <i class="ri-braces-line"></i>
    Funções JSON
</div>
        </div>
    </td>
</tr>
<tr>
    <td>
        <code>
            @deepseekai/v3.1-terminus
        </code>
    </td>
    <td>
        <div class="item-pricing">
            <small>
                Entrada:
            </small>
            <div>
                $ 0.27 <small>/1m tokens</small>
            </div>
        </div>
        <div class="item-pricing">
    <small>
        Entrada (em cache):
    </small>
    <div>
        $ 0.22 <small>/1m tokens</small>
    </div>
</div>
        <div class="item-pricing">
            <small>
                Saída:
            </small>
            <div>
                $ 1.00 <small>/1m tokens</small>
            </div>
        </div>
    </td>
    <td>
        DeepSeek-V3.1 is post-trained on the top of DeepSeek-V3.1-Base, which is built upon the original V3 base checkpoint through a two-phase long context extension approach, following the methodology outlined in the original DeepSeek-V3 report.
        <div class="model-capabilities">
<div>
    <i class="ri-instance-line"></i>
    Chamadas de função
</div>
<div>
    <i class="ri-lightbulb-line"></i>
    Raciocínio
</div>
<div>
    <i class="ri-braces-line"></i>
    Funções JSON
</div>
        </div>
    </td>
</tr>
<tr>
    <td>
        <code>
            @deepseekai/v3.2-speciale
        </code>
    </td>
    <td>
        <div class="item-pricing">
            <small>
                Entrada:
            </small>
            <div>
                $ 0.28 <small>/1m tokens</small>
            </div>
        </div>
        <div class="item-pricing">
    <small>
        Entrada (em cache):
    </small>
    <div>
        $ 0.03 <small>/1m tokens</small>
    </div>
</div>
        <div class="item-pricing">
            <small>
                Saída:
            </small>
            <div>
                $ 0.42 <small>/1m tokens</small>
            </div>
        </div>
    </td>
    <td>
        DeepSeek-V3.2-Speciale is a high-compute version of DeepSeek-V3.2, designed for maximum reasoning and agentic performance.
        <div class="model-capabilities">
<div>
    <i class="ri-lightbulb-line"></i>
    Raciocínio
</div>
<div>
    <i class="ri-braces-line"></i>
    Funções JSON
</div>
        </div>
    </td>
</tr>
<tr>
    <td>
        <code>
            @deepseekai/v3.2
        </code>
    </td>
    <td>
        <div class="item-pricing">
            <small>
                Entrada:
            </small>
            <div>
                $ 0.28 <small>/1m tokens</small>
            </div>
        </div>
        <div class="item-pricing">
    <small>
        Entrada (em cache):
    </small>
    <div>
        $ 0.03 <small>/1m tokens</small>
    </div>
</div>
        <div class="item-pricing">
            <small>
                Saída:
            </small>
            <div>
                $ 0.42 <small>/1m tokens</small>
            </div>
        </div>
    </td>
    <td>
        DeepSeek-V3.2 is a large language model optimized for high computational efficiency and strong tool-use reasoning.
        <div class="model-capabilities">
<div>
    <i class="ri-instance-line"></i>
    Chamadas de função
</div>
<div>
    <i class="ri-lightbulb-line"></i>
    Raciocínio
</div>
<div>
    <i class="ri-braces-line"></i>
    Funções JSON
</div>
        </div>
    </td>
</tr>
    </tbody>
</table>

## <img src="/assets/icon/google.svg" class="inline-icon"> google

<table>
    <thead>
        <colgroup>
            <col style="width: 30%" />
            <col style="width: 20%" />
            <col style="width: 50%" />
        </colgroup>
        <tr>
            <th>Nome do modelo</th>
            <th>Preços</th>
            <th>Descrição</th>
        </tr>
    </thead>
    <tbody>
<tr>
    <td>
        <code>
            @google/gemini-3-pro
        </code>
    </td>
    <td>
        <div class="item-pricing">
            <small>
                Entrada:
            </small>
            <div>
                $ 2.00 <small>/1m tokens</small>
            </div>
        </div>
        
        <div class="item-pricing">
            <small>
                Saída:
            </small>
            <div>
                $ 12.00 <small>/1m tokens</small>
            </div>
        </div>
    </td>
    <td>
        Gemini 3 Pro Preview is Google’s most advanced AI model, setting new records on leading benchmarks like LMArena (1501 Elo), GPQA Diamond (91.9%), and MathArena Apex (23.4%).
        <div class="model-capabilities">
<div>
    <i class="ri-image-circle-line"></i>
    Entrada: aceita imagens, vídeos, áudios
</div>
<div>
    <i class="ri-instance-line"></i>
    Chamadas de função
</div>
<div>
    <i class="ri-lightbulb-line"></i>
    Raciocínio
</div>
<div>
    <i class="ri-braces-line"></i>
    Funções JSON
</div>
        </div>
    </td>
</tr>
<tr>
    <td>
        <code>
            @google/gemini-2.5-pro
        </code>
    </td>
    <td>
        <div class="item-pricing">
            <small>
                Entrada:
            </small>
            <div>
                $ 1.25 <small>/1m tokens</small>
            </div>
        </div>
        <div class="item-pricing">
    <small>
        Entrada (em cache):
    </small>
    <div>
        $ 0.31 <small>/1m tokens</small>
    </div>
</div>
        <div class="item-pricing">
            <small>
                Saída:
            </small>
            <div>
                $ 10.00 <small>/1m tokens</small>
            </div>
        </div>
    </td>
    <td>
        One of the most powerful models today.
        <div class="model-capabilities">
<div>
    <i class="ri-image-circle-line"></i>
    Entrada: aceita imagens, vídeos, áudios
</div>
<div>
    <i class="ri-instance-line"></i>
    Chamadas de função
</div>
<div>
    <i class="ri-lightbulb-line"></i>
    Raciocínio
</div>
<div>
    <i class="ri-braces-line"></i>
    Funções JSON
</div>
        </div>
    </td>
</tr>
<tr>
    <td>
        <code>
            @google/gemini-2.5-flash
        </code>
    </td>
    <td>
        <div class="item-pricing">
            <small>
                Entrada:
            </small>
            <div>
                $ 0.30 <small>/1m tokens</small>
            </div>
        </div>
        <div class="item-pricing">
    <small>
        Entrada (em cache):
    </small>
    <div>
        $ 0.08 <small>/1m tokens</small>
    </div>
</div>
        <div class="item-pricing">
            <small>
                Saída:
            </small>
            <div>
                $ 2.50 <small>/1m tokens</small>
            </div>
        </div>
    </td>
    <td>
        Google's best model in terms of price-performance, offering well-rounded capabilities. 2.5 Flash is best for large scale processing, low-latency, high volume tasks that require thinking, and agentic use cases.
        <div class="model-capabilities">
<div>
    <i class="ri-image-circle-line"></i>
    Entrada: aceita imagens, vídeos, áudios
</div>
<div>
    <i class="ri-instance-line"></i>
    Chamadas de função
</div>
<div>
    <i class="ri-lightbulb-line"></i>
    Raciocínio
</div>
<div>
    <i class="ri-braces-line"></i>
    Funções JSON
</div>
        </div>
    </td>
</tr>
<tr>
    <td>
        <code>
            @google/gemini-2.5-flash-lite
        </code>
    </td>
    <td>
        <div class="item-pricing">
            <small>
                Entrada:
            </small>
            <div>
                $ 0.10 <small>/1m tokens</small>
            </div>
        </div>
        <div class="item-pricing">
    <small>
        Entrada (em cache):
    </small>
    <div>
        $ 0.03 <small>/1m tokens</small>
    </div>
</div>
        <div class="item-pricing">
            <small>
                Saída:
            </small>
            <div>
                $ 0.40 <small>/1m tokens</small>
            </div>
        </div>
    </td>
    <td>
        A Gemini 2.5 Flash model optimized for cost efficiency and low latency.
        <div class="model-capabilities">
<div>
    <i class="ri-image-circle-line"></i>
    Entrada: aceita imagens, vídeos, áudios
</div>
<div>
    <i class="ri-instance-line"></i>
    Chamadas de função
</div>
<div>
    <i class="ri-lightbulb-line"></i>
    Raciocínio
</div>
<div>
    <i class="ri-braces-line"></i>
    Funções JSON
</div>
        </div>
    </td>
</tr>
<tr>
    <td>
        <code>
            @google/gemini-2.0-flash
        </code>
    </td>
    <td>
        <div class="item-pricing">
            <small>
                Entrada:
            </small>
            <div>
                $ 0.10 <small>/1m tokens</small>
            </div>
        </div>
        <div class="item-pricing">
    <small>
        Entrada (em cache):
    </small>
    <div>
        $ 0.03 <small>/1m tokens</small>
    </div>
</div>
        <div class="item-pricing">
            <small>
                Saída:
            </small>
            <div>
                $ 0.40 <small>/1m tokens</small>
            </div>
        </div>
    </td>
    <td>
        Gemini 2.0 Flash delivers next-gen features and improved capabilities, including superior speed, native tool use, and a 1M token context window.
        <div class="model-capabilities">
<div>
    <i class="ri-image-circle-line"></i>
    Entrada: aceita imagens, vídeos, áudios
</div>
<div>
    <i class="ri-instance-line"></i>
    Chamadas de função
</div>
<div>
    <i class="ri-braces-line"></i>
    Funções JSON
</div>
        </div>
    </td>
</tr>
<tr>
    <td>
        <code>
            @google/gemini-2.0-flash-lite
        </code>
    </td>
    <td>
        <div class="item-pricing">
            <small>
                Entrada:
            </small>
            <div>
                $ 0.08 <small>/1m tokens</small>
            </div>
        </div>
        
        <div class="item-pricing">
            <small>
                Saída:
            </small>
            <div>
                $ 0.30 <small>/1m tokens</small>
            </div>
        </div>
    </td>
    <td>
        General-purpose model, with image recognition, smart and fast. Great for an economical chat.
        <div class="model-capabilities">
<div>
    <i class="ri-image-circle-line"></i>
    Entrada: aceita imagens, vídeos, áudios
</div>
<div>
    <i class="ri-instance-line"></i>
    Chamadas de função
</div>
<div>
    <i class="ri-braces-line"></i>
    Funções JSON
</div>
        </div>
    </td>
</tr>
    </tbody>
</table>

## <img src="/assets/icon/inception.svg" class="inline-icon"> inception

<table>
    <thead>
        <colgroup>
            <col style="width: 30%" />
            <col style="width: 20%" />
            <col style="width: 50%" />
        </colgroup>
        <tr>
            <th>Nome do modelo</th>
            <th>Preços</th>
            <th>Descrição</th>
        </tr>
    </thead>
    <tbody>
<tr>
    <td>
        <code>
            @inception/mercury
        </code>
    </td>
    <td>
        <div class="item-pricing">
            <small>
                Entrada:
            </small>
            <div>
                $ 0.25 <small>/1m tokens</small>
            </div>
        </div>
        
        <div class="item-pricing">
            <small>
                Saída:
            </small>
            <div>
                $ 1.00 <small>/1m tokens</small>
            </div>
        </div>
    </td>
    <td>
        Extremely fast model by generative diffusion.
        <div class="model-capabilities">
<div>
    <i class="ri-instance-line"></i>
    Chamadas de função
</div>
<div>
    <i class="ri-braces-line"></i>
    Funções JSON
</div>
        </div>
    </td>
</tr>
    </tbody>
</table>

## <img src="/assets/icon/metaai.svg" class="inline-icon"> metaai

<table>
    <thead>
        <colgroup>
            <col style="width: 30%" />
            <col style="width: 20%" />
            <col style="width: 50%" />
        </colgroup>
        <tr>
            <th>Nome do modelo</th>
            <th>Preços</th>
            <th>Descrição</th>
        </tr>
    </thead>
    <tbody>
<tr>
    <td>
        <code>
            @metaai/llama-3.3-70b
        </code>
    </td>
    <td>
        <div class="item-pricing">
            <small>
                Entrada:
            </small>
            <div>
                $ 0.59 <small>/1m tokens</small>
            </div>
        </div>
        
        <div class="item-pricing">
            <small>
                Saída:
            </small>
            <div>
                $ 0.79 <small>/1m tokens</small>
            </div>
        </div>
    </td>
    <td>
        Previous generation model with many parameters and surprisingly fast speed.
        <div class="model-capabilities">
<div>
    <i class="ri-instance-line"></i>
    Chamadas de função
</div>
<div>
    <i class="ri-braces-line"></i>
    Funções JSON
</div>
        </div>
    </td>
</tr>
<tr>
    <td>
        <code>
            @metaai/llama-4-maverick-17b-128e
        </code>
    </td>
    <td>
        <div class="item-pricing">
            <small>
                Entrada:
            </small>
            <div>
                $ 0.20 <small>/1m tokens</small>
            </div>
        </div>
        
        <div class="item-pricing">
            <small>
                Saída:
            </small>
            <div>
                $ 0.60 <small>/1m tokens</small>
            </div>
        </div>
    </td>
    <td>
        Fast model, with 17 billion activated parameters and 128 experts.
        <div class="model-capabilities">
<div>
    <i class="ri-image-circle-line"></i>
    Entrada: aceita imagens
</div>
<div>
    <i class="ri-instance-line"></i>
    Chamadas de função
</div>
<div>
    <i class="ri-braces-line"></i>
    Funções JSON
</div>
        </div>
    </td>
</tr>
<tr>
    <td>
        <code>
            @metaai/llama-4-scout-17b-16e
        </code>
    </td>
    <td>
        <div class="item-pricing">
            <small>
                Entrada:
            </small>
            <div>
                $ 0.11 <small>/1m tokens</small>
            </div>
        </div>
        
        <div class="item-pricing">
            <small>
                Saída:
            </small>
            <div>
                $ 0.34 <small>/1m tokens</small>
            </div>
        </div>
    </td>
    <td>
        Smaller version of the Llama 4 family with 17 billion activated parameters and 16 experts.
        <div class="model-capabilities">
<div>
    <i class="ri-image-circle-line"></i>
    Entrada: aceita imagens
</div>
<div>
    <i class="ri-instance-line"></i>
    Chamadas de função
</div>
<div>
    <i class="ri-braces-line"></i>
    Funções JSON
</div>
        </div>
    </td>
</tr>
<tr>
    <td>
        <code>
            @metaai/llama-3.1-8b
        </code>
    </td>
    <td>
        <div class="item-pricing">
            <small>
                Entrada:
            </small>
            <div>
                $ 0.05 <small>/1m tokens</small>
            </div>
        </div>
        
        <div class="item-pricing">
            <small>
                Saída:
            </small>
            <div>
                $ 0.08 <small>/1m tokens</small>
            </div>
        </div>
    </td>
    <td>
        Cheap and fast model for less demanding tasks.
        <div class="model-capabilities">
<div>
    <i class="ri-instance-line"></i>
    Chamadas de função
</div>
<div>
    <i class="ri-braces-line"></i>
    Funções JSON
</div>
        </div>
    </td>
</tr>
    </tbody>
</table>

## <img src="/assets/icon/minimax.svg" class="inline-icon"> minimax

<table>
    <thead>
        <colgroup>
            <col style="width: 30%" />
            <col style="width: 20%" />
            <col style="width: 50%" />
        </colgroup>
        <tr>
            <th>Nome do modelo</th>
            <th>Preços</th>
            <th>Descrição</th>
        </tr>
    </thead>
    <tbody>
<tr>
    <td>
        <code>
            @minimax/m2
        </code>
    </td>
    <td>
        <div class="item-pricing">
            <small>
                Entrada:
            </small>
            <div>
                $ 0.30 <small>/1m tokens</small>
            </div>
        </div>
        
        <div class="item-pricing">
            <small>
                Saída:
            </small>
            <div>
                $ 1.20 <small>/1m tokens</small>
            </div>
        </div>
    </td>
    <td>
        MiniMax-M2 is a compact, high-efficiency large language model optimized for end-to-end coding and agentic workflows.
        <div class="model-capabilities">
<div>
    <i class="ri-instance-line"></i>
    Chamadas de função
</div>
<div>
    <i class="ri-lightbulb-line"></i>
    Raciocínio
</div>
<div>
    <i class="ri-braces-line"></i>
    Funções JSON
</div>
        </div>
    </td>
</tr>
    </tbody>
</table>

## <img src="/assets/icon/mistral.svg" class="inline-icon"> mistral

<table>
    <thead>
        <colgroup>
            <col style="width: 30%" />
            <col style="width: 20%" />
            <col style="width: 50%" />
        </colgroup>
        <tr>
            <th>Nome do modelo</th>
            <th>Preços</th>
            <th>Descrição</th>
        </tr>
    </thead>
    <tbody>
<tr>
    <td>
        <code>
            @mistral/pixtral-large
        </code>
    </td>
    <td>
        <div class="item-pricing">
            <small>
                Entrada:
            </small>
            <div>
                $ 2.00 <small>/1m tokens</small>
            </div>
        </div>
        
        <div class="item-pricing">
            <small>
                Saída:
            </small>
            <div>
                $ 6.00 <small>/1m tokens</small>
            </div>
        </div>
    </td>
    <td>
        Pixtral Large is the second model in our multimodal family and demonstrates frontier-level image understanding. Particularly, the model is able to understand documents, charts and natural images, while maintaining the leading text-only understanding of Mistral Large 2.
        <div class="model-capabilities">
<div>
    <i class="ri-image-circle-line"></i>
    Entrada: aceita imagens
</div>
<div>
    <i class="ri-instance-line"></i>
    Chamadas de função
</div>
<div>
    <i class="ri-braces-line"></i>
    Funções JSON
</div>
        </div>
    </td>
</tr>
<tr>
    <td>
        <code>
            @mistral/magistral-medium
        </code>
    </td>
    <td>
        <div class="item-pricing">
            <small>
                Entrada:
            </small>
            <div>
                $ 2.00 <small>/1m tokens</small>
            </div>
        </div>
        
        <div class="item-pricing">
            <small>
                Saída:
            </small>
            <div>
                $ 5.00 <small>/1m tokens</small>
            </div>
        </div>
    </td>
    <td>
        Mistral's frontier-class reasoning model update released September 2025 with vision support.
        <div class="model-capabilities">
<div>
    <i class="ri-image-circle-line"></i>
    Entrada: aceita imagens
</div>
<div>
    <i class="ri-lightbulb-line"></i>
    Raciocínio
</div>
<div>
    <i class="ri-braces-line"></i>
    Funções JSON
</div>
        </div>
    </td>
</tr>
<tr>
    <td>
        <code>
            @mistral/medium
        </code>
    </td>
    <td>
        <div class="item-pricing">
            <small>
                Entrada:
            </small>
            <div>
                $ 0.40 <small>/1m tokens</small>
            </div>
        </div>
        
        <div class="item-pricing">
            <small>
                Saída:
            </small>
            <div>
                $ 2.00 <small>/1m tokens</small>
            </div>
        </div>
    </td>
    <td>
        Mistral Medium 3 delivers frontier performance while being an order of magnitude less expensive. For instance, the model performs at or above 90% of Claude Sonnet 3.7 on benchmarks across the board at a significantly lower cost.
        <div class="model-capabilities">
<div>
    <i class="ri-image-circle-line"></i>
    Entrada: aceita imagens
</div>
<div>
    <i class="ri-instance-line"></i>
    Chamadas de função
</div>
<div>
    <i class="ri-braces-line"></i>
    Funções JSON
</div>
        </div>
    </td>
</tr>
<tr>
    <td>
        <code>
            @mistral/large-2512
        </code>
    </td>
    <td>
        <div class="item-pricing">
            <small>
                Entrada:
            </small>
            <div>
                $ 0.50 <small>/1m tokens</small>
            </div>
        </div>
        
        <div class="item-pricing">
            <small>
                Saída:
            </small>
            <div>
                $ 1.50 <small>/1m tokens</small>
            </div>
        </div>
    </td>
    <td>
        Mistral Large 3 2512 is Mistral’s most capable model to date, featuring a sparse mixture-of-experts architecture with 41B active parameters (675B total).
        <div class="model-capabilities">
<div>
    <i class="ri-instance-line"></i>
    Chamadas de função
</div>
<div>
    <i class="ri-braces-line"></i>
    Funções JSON
</div>
        </div>
    </td>
</tr>
<tr>
    <td>
        <code>
            @mistral/magistral-small
        </code>
    </td>
    <td>
        <div class="item-pricing">
            <small>
                Entrada:
            </small>
            <div>
                $ 0.50 <small>/1m tokens</small>
            </div>
        </div>
        
        <div class="item-pricing">
            <small>
                Saída:
            </small>
            <div>
                $ 1.50 <small>/1m tokens</small>
            </div>
        </div>
    </td>
    <td>
        Complex thinking, backed by deep understanding, with transparent reasoning you can follow and verify. The model excels in maintaining high-fidelity reasoning across numerous languages, even when switching between languages mid-task.
        <div class="model-capabilities">
<div>
    <i class="ri-lightbulb-line"></i>
    Raciocínio
</div>
<div>
    <i class="ri-braces-line"></i>
    Funções JSON
</div>
        </div>
    </td>
</tr>
<tr>
    <td>
        <code>
            @mistral/small
        </code>
    </td>
    <td>
        <div class="item-pricing">
            <small>
                Entrada:
            </small>
            <div>
                $ 0.10 <small>/1m tokens</small>
            </div>
        </div>
        
        <div class="item-pricing">
            <small>
                Saída:
            </small>
            <div>
                $ 0.30 <small>/1m tokens</small>
            </div>
        </div>
    </td>
    <td>
        Mistral Small is the ideal choice for simple tasks that one can do in bulk - like Classification, Customer Support, or Text Generation. It offers excellent performance at an affordable price point.
        <div class="model-capabilities">
<div>
    <i class="ri-image-circle-line"></i>
    Entrada: aceita imagens
</div>
<div>
    <i class="ri-instance-line"></i>
    Chamadas de função
</div>
<div>
    <i class="ri-braces-line"></i>
    Funções JSON
</div>
        </div>
    </td>
</tr>
<tr>
    <td>
        <code>
            @mistral/nemo-12b-it-2407
        </code>
    </td>
    <td>
        <div class="item-pricing">
            <small>
                Entrada:
            </small>
            <div>
                $ 0.02 <small>/1m tokens</small>
            </div>
        </div>
        
        <div class="item-pricing">
            <small>
                Saída:
            </small>
            <div>
                $ 0.04 <small>/1m tokens</small>
            </div>
        </div>
    </td>
    <td>
        12B model trained jointly by Mistral AI and NVIDIA, it significantly outperforms existing models smaller or similar in size.
        <div class="model-capabilities">
<div>
    <i class="ri-instance-line"></i>
    Chamadas de função
</div>
<div>
    <i class="ri-braces-line"></i>
    Funções JSON
</div>
        </div>
    </td>
</tr>
    </tbody>
</table>

## <img src="/assets/icon/model-router.svg" class="inline-icon"> model-router

<table>
    <thead>
        <colgroup>
            <col style="width: 30%" />
            <col style="width: 20%" />
            <col style="width: 50%" />
        </colgroup>
        <tr>
            <th>Nome do modelo</th>
            <th>Preços</th>
            <th>Descrição</th>
        </tr>
    </thead>
    <tbody>
<tr>
    <td>
        <code>
            @model-router/complexity
        </code>
    </td>
    <td>
        <div class="item-pricing">
            <small>
                Entrada:
            </small>
            <div>
                $ 0.20 <small>/1m tokens</small>
            </div>
        </div>
        <div class="item-pricing">
    <small>
        Entrada (em cache):
    </small>
    <div>
        $ 0.05 <small>/1m tokens</small>
    </div>
</div>
        <div class="item-pricing">
            <small>
                Saída:
            </small>
            <div>
                $ 0.50 <small>/1m tokens</small>
            </div>
        </div>
    </td>
    <td>
        Model Router: chooses the best models according to the complexity of the conversation.
        <div class="model-capabilities">
        </div>
    </td>
</tr>
    </tbody>
</table>

## <img src="/assets/icon/moonshotai.svg" class="inline-icon"> moonshotai

<table>
    <thead>
        <colgroup>
            <col style="width: 30%" />
            <col style="width: 20%" />
            <col style="width: 50%" />
        </colgroup>
        <tr>
            <th>Nome do modelo</th>
            <th>Preços</th>
            <th>Descrição</th>
        </tr>
    </thead>
    <tbody>
<tr>
    <td>
        <code>
            @moonshotai/kimi-k2
        </code>
    </td>
    <td>
        <div class="item-pricing">
            <small>
                Entrada:
            </small>
            <div>
                $ 1.00 <small>/1m tokens</small>
            </div>
        </div>
        <div class="item-pricing">
    <small>
        Entrada (em cache):
    </small>
    <div>
        $ 0.50 <small>/1m tokens</small>
    </div>
</div>
        <div class="item-pricing">
            <small>
                Saída:
            </small>
            <div>
                $ 3.00 <small>/1m tokens</small>
            </div>
        </div>
    </td>
    <td>
        Model with 1tri total parameters, 32bi activated parameters, optimized for agentic intelligence.
        <div class="model-capabilities">
<div>
    <i class="ri-instance-line"></i>
    Chamadas de função
</div>
<div>
    <i class="ri-braces-line"></i>
    Funções JSON
</div>
        </div>
    </td>
</tr>
<tr>
    <td>
        <code>
            @moonshotai/kimi-k2-thinking
        </code>
    </td>
    <td>
        <div class="item-pricing">
            <small>
                Entrada:
            </small>
            <div>
                $ 0.60 <small>/1m tokens</small>
            </div>
        </div>
        <div class="item-pricing">
    <small>
        Entrada (em cache):
    </small>
    <div>
        $ 0.15 <small>/1m tokens</small>
    </div>
</div>
        <div class="item-pricing">
            <small>
                Saída:
            </small>
            <div>
                $ 2.50 <small>/1m tokens</small>
            </div>
        </div>
    </td>
    <td>
        Kimi K2 Thinking is Moonshot AI’s most advanced open reasoning model to date, extending the K2 series into agentic, long-horizon reasoning.
        <div class="model-capabilities">
<div>
    <i class="ri-instance-line"></i>
    Chamadas de função
</div>
<div>
    <i class="ri-lightbulb-line"></i>
    Raciocínio
</div>
<div>
    <i class="ri-braces-line"></i>
    Funções JSON
</div>
        </div>
    </td>
</tr>
    </tbody>
</table>

## <img src="/assets/icon/openai.svg" class="inline-icon"> openai

<table>
    <thead>
        <colgroup>
            <col style="width: 30%" />
            <col style="width: 20%" />
            <col style="width: 50%" />
        </colgroup>
        <tr>
            <th>Nome do modelo</th>
            <th>Preços</th>
            <th>Descrição</th>
        </tr>
    </thead>
    <tbody>
<tr>
    <td>
        <code>
            @openai/gpt-4o
        </code>
    </td>
    <td>
        <div class="item-pricing">
            <small>
                Entrada:
            </small>
            <div>
                $ 2.50 <small>/1m tokens</small>
            </div>
        </div>
        <div class="item-pricing">
    <small>
        Entrada (em cache):
    </small>
    <div>
        $ 1.25 <small>/1m tokens</small>
    </div>
</div>
        <div class="item-pricing">
            <small>
                Saída:
            </small>
            <div>
                $ 10.00 <small>/1m tokens</small>
            </div>
        </div>
    </td>
    <td>
        Dedicated to tasks requiring reasoning for mathematical and logical problem solving.
        <div class="model-capabilities">
<div>
    <i class="ri-image-circle-line"></i>
    Entrada: aceita imagens
</div>
<div>
    <i class="ri-instance-line"></i>
    Chamadas de função
</div>
<div>
    <i class="ri-braces-line"></i>
    Funções JSON
</div>
        </div>
    </td>
</tr>
<tr>
    <td>
        <code>
            @openai/gpt-5.1
        </code>
    </td>
    <td>
        <div class="item-pricing">
            <small>
                Entrada:
            </small>
            <div>
                $ 1.25 <small>/1m tokens</small>
            </div>
        </div>
        <div class="item-pricing">
    <small>
        Entrada (em cache):
    </small>
    <div>
        $ 0.13 <small>/1m tokens</small>
    </div>
</div>
        <div class="item-pricing">
            <small>
                Saída:
            </small>
            <div>
                $ 10.00 <small>/1m tokens</small>
            </div>
        </div>
    </td>
    <td>
        GPT-5.1 is the newest top-tier model in the GPT-5 series, featuring enhanced general reasoning, better instruction following, and a more natural conversational tone compared to GPT-5.
        <div class="model-capabilities">
<div>
    <i class="ri-image-circle-line"></i>
    Entrada: aceita imagens
</div>
<div>
    <i class="ri-instance-line"></i>
    Chamadas de função
</div>
<div>
    <i class="ri-lightbulb-line"></i>
    Raciocínio
</div>
<div>
    <i class="ri-braces-line"></i>
    Funções JSON
</div>
        </div>
    </td>
</tr>
<tr>
    <td>
        <code>
            @openai/gpt-5.1-chat
        </code>
    </td>
    <td>
        <div class="item-pricing">
            <small>
                Entrada:
            </small>
            <div>
                $ 1.25 <small>/1m tokens</small>
            </div>
        </div>
        <div class="item-pricing">
    <small>
        Entrada (em cache):
    </small>
    <div>
        $ 0.13 <small>/1m tokens</small>
    </div>
</div>
        <div class="item-pricing">
            <small>
                Saída:
            </small>
            <div>
                $ 10.00 <small>/1m tokens</small>
            </div>
        </div>
    </td>
    <td>
        GPT-5.1 Chat (also known as Instant) is the fast, lightweight member of the 5.1 family, optimized for low-latency chat while retaining strong general intelligence.
        <div class="model-capabilities">
<div>
    <i class="ri-image-circle-line"></i>
    Entrada: aceita imagens
</div>
<div>
    <i class="ri-instance-line"></i>
    Chamadas de função
</div>
<div>
    <i class="ri-lightbulb-line"></i>
    Raciocínio
</div>
<div>
    <i class="ri-braces-line"></i>
    Funções JSON
</div>
        </div>
    </td>
</tr>
<tr>
    <td>
        <code>
            @openai/gpt-5.1-codex
        </code>
    </td>
    <td>
        <div class="item-pricing">
            <small>
                Entrada:
            </small>
            <div>
                $ 1.25 <small>/1m tokens</small>
            </div>
        </div>
        <div class="item-pricing">
    <small>
        Entrada (em cache):
    </small>
    <div>
        $ 0.13 <small>/1m tokens</small>
    </div>
</div>
        <div class="item-pricing">
            <small>
                Saída:
            </small>
            <div>
                $ 10.00 <small>/1m tokens</small>
            </div>
        </div>
    </td>
    <td>
        GPT-5.1-Codex is a specialized version of GPT-5.1 optimized for software engineering and coding workflows.
        <div class="model-capabilities">
<div>
    <i class="ri-image-circle-line"></i>
    Entrada: aceita imagens
</div>
<div>
    <i class="ri-instance-line"></i>
    Chamadas de função
</div>
<div>
    <i class="ri-lightbulb-line"></i>
    Raciocínio
</div>
<div>
    <i class="ri-braces-line"></i>
    Funções JSON
</div>
        </div>
    </td>
</tr>
<tr>
    <td>
        <code>
            @openai/gpt-5.1-codex-max
        </code>
    </td>
    <td>
        <div class="item-pricing">
            <small>
                Entrada:
            </small>
            <div>
                $ 1.25 <small>/1m tokens</small>
            </div>
        </div>
        <div class="item-pricing">
    <small>
        Entrada (em cache):
    </small>
    <div>
        $ 0.13 <small>/1m tokens</small>
    </div>
</div>
        <div class="item-pricing">
            <small>
                Saída:
            </small>
            <div>
                $ 10.00 <small>/1m tokens</small>
            </div>
        </div>
    </td>
    <td>
        GPT-5.1-Codex-Max is OpenAI’s latest agentic coding model, designed for long-running, high-context software development tasks.
        <div class="model-capabilities">
<div>
    <i class="ri-image-circle-line"></i>
    Entrada: aceita imagens
</div>
<div>
    <i class="ri-instance-line"></i>
    Chamadas de função
</div>
<div>
    <i class="ri-lightbulb-line"></i>
    Raciocínio
</div>
<div>
    <i class="ri-braces-line"></i>
    Funções JSON
</div>
        </div>
    </td>
</tr>
<tr>
    <td>
        <code>
            @openai/gpt-5-chat
        </code>
    </td>
    <td>
        <div class="item-pricing">
            <small>
                Entrada:
            </small>
            <div>
                $ 1.25 <small>/1m tokens</small>
            </div>
        </div>
        <div class="item-pricing">
    <small>
        Entrada (em cache):
    </small>
    <div>
        $ 0.13 <small>/1m tokens</small>
    </div>
</div>
        <div class="item-pricing">
            <small>
                Saída:
            </small>
            <div>
                $ 10.00 <small>/1m tokens</small>
            </div>
        </div>
    </td>
    <td>
        GPT-5 snapshot currently used by OpenAI's ChatGPT.
        <div class="model-capabilities">
<div>
    <i class="ri-image-circle-line"></i>
    Entrada: aceita imagens
</div>
<div>
    <i class="ri-instance-line"></i>
    Chamadas de função
</div>
        </div>
    </td>
</tr>
<tr>
    <td>
        <code>
            @openai/gpt-5-codex
        </code>
    </td>
    <td>
        <div class="item-pricing">
            <small>
                Entrada:
            </small>
            <div>
                $ 1.25 <small>/1m tokens</small>
            </div>
        </div>
        <div class="item-pricing">
    <small>
        Entrada (em cache):
    </small>
    <div>
        $ 0.13 <small>/1m tokens</small>
    </div>
</div>
        <div class="item-pricing">
            <small>
                Saída:
            </small>
            <div>
                $ 10.00 <small>/1m tokens</small>
            </div>
        </div>
    </td>
    <td>
        GPT-5-Codex is a specialized version of GPT-5 tailored for software engineering and coding tasks.
        <div class="model-capabilities">
<div>
    <i class="ri-image-circle-line"></i>
    Entrada: aceita imagens
</div>
<div>
    <i class="ri-instance-line"></i>
    Chamadas de função
</div>
<div>
    <i class="ri-lightbulb-line"></i>
    Raciocínio
</div>
<div>
    <i class="ri-braces-line"></i>
    Funções JSON
</div>
        </div>
    </td>
</tr>
<tr>
    <td>
        <code>
            @openai/gpt-5
        </code>
    </td>
    <td>
        <div class="item-pricing">
            <small>
                Entrada:
            </small>
            <div>
                $ 1.25 <small>/1m tokens</small>
            </div>
        </div>
        <div class="item-pricing">
    <small>
        Entrada (em cache):
    </small>
    <div>
        $ 0.13 <small>/1m tokens</small>
    </div>
</div>
        <div class="item-pricing">
            <small>
                Saída:
            </small>
            <div>
                $ 10.00 <small>/1m tokens</small>
            </div>
        </div>
    </td>
    <td>
        OpenAI's newest flagship model for coding, reasoning, and agentic tasks across domains.
        <div class="model-capabilities">
<div>
    <i class="ri-image-circle-line"></i>
    Entrada: aceita imagens
</div>
<div>
    <i class="ri-instance-line"></i>
    Chamadas de função
</div>
<div>
    <i class="ri-lightbulb-line"></i>
    Raciocínio
</div>
<div>
    <i class="ri-braces-line"></i>
    Funções JSON
</div>
        </div>
    </td>
</tr>
<tr>
    <td>
        <code>
            @openai/gpt-4.1
        </code>
    </td>
    <td>
        <div class="item-pricing">
            <small>
                Entrada:
            </small>
            <div>
                $ 2.00 <small>/1m tokens</small>
            </div>
        </div>
        <div class="item-pricing">
    <small>
        Entrada (em cache):
    </small>
    <div>
        $ 0.50 <small>/1m tokens</small>
    </div>
</div>
        <div class="item-pricing">
            <small>
                Saída:
            </small>
            <div>
                $ 8.00 <small>/1m tokens</small>
            </div>
        </div>
    </td>
    <td>
        Versatile, highly intelligent, and top-of-the-line. One of the most capable models currently available.
        <div class="model-capabilities">
<div>
    <i class="ri-image-circle-line"></i>
    Entrada: aceita imagens
</div>
<div>
    <i class="ri-instance-line"></i>
    Chamadas de função
</div>
<div>
    <i class="ri-braces-line"></i>
    Funções JSON
</div>
        </div>
    </td>
</tr>
<tr>
    <td>
        <code>
            @openai/o3
        </code>
    </td>
    <td>
        <div class="item-pricing">
            <small>
                Entrada:
            </small>
            <div>
                $ 2.00 <small>/1m tokens</small>
            </div>
        </div>
        <div class="item-pricing">
    <small>
        Entrada (em cache):
    </small>
    <div>
        $ 0.50 <small>/1m tokens</small>
    </div>
</div>
        <div class="item-pricing">
            <small>
                Saída:
            </small>
            <div>
                $ 8.00 <small>/1m tokens</small>
            </div>
        </div>
    </td>
    <td>
        A well-rounded and powerful model across domains. It sets a new standard for math, science, coding, and visual reasoning tasks.
        <div class="model-capabilities">
<div>
    <i class="ri-image-circle-line"></i>
    Entrada: aceita imagens
</div>
<div>
    <i class="ri-instance-line"></i>
    Chamadas de função
</div>
<div>
    <i class="ri-lightbulb-line"></i>
    Raciocínio
</div>
<div>
    <i class="ri-braces-line"></i>
    Funções JSON
</div>
        </div>
    </td>
</tr>
<tr>
    <td>
        <code>
            @openai/o4-mini
        </code>
    </td>
    <td>
        <div class="item-pricing">
            <small>
                Entrada:
            </small>
            <div>
                $ 1.10 <small>/1m tokens</small>
            </div>
        </div>
        <div class="item-pricing">
    <small>
        Entrada (em cache):
    </small>
    <div>
        $ 0.28 <small>/1m tokens</small>
    </div>
</div>
        <div class="item-pricing">
            <small>
                Saída:
            </small>
            <div>
                $ 4.40 <small>/1m tokens</small>
            </div>
        </div>
    </td>
    <td>
        Optimized for fast, effective reasoning with exceptionally efficient performance in coding and visual tasks.
        <div class="model-capabilities">
<div>
    <i class="ri-image-circle-line"></i>
    Entrada: aceita imagens
</div>
<div>
    <i class="ri-instance-line"></i>
    Chamadas de função
</div>
<div>
    <i class="ri-lightbulb-line"></i>
    Raciocínio
</div>
<div>
    <i class="ri-braces-line"></i>
    Funções JSON
</div>
        </div>
    </td>
</tr>
<tr>
    <td>
        <code>
            @openai/o3-mini
        </code>
    </td>
    <td>
        <div class="item-pricing">
            <small>
                Entrada:
            </small>
            <div>
                $ 1.10 <small>/1m tokens</small>
            </div>
        </div>
        <div class="item-pricing">
    <small>
        Entrada (em cache):
    </small>
    <div>
        $ 0.55 <small>/1m tokens</small>
    </div>
</div>
        <div class="item-pricing">
            <small>
                Saída:
            </small>
            <div>
                $ 4.40 <small>/1m tokens</small>
            </div>
        </div>
    </td>
    <td>
        o3-mini provides high intelligence at the same cost and latency targets of previous versions of o-mini series.
        <div class="model-capabilities">
<div>
    <i class="ri-instance-line"></i>
    Chamadas de função
</div>
<div>
    <i class="ri-lightbulb-line"></i>
    Raciocínio
</div>
<div>
    <i class="ri-braces-line"></i>
    Funções JSON
</div>
        </div>
    </td>
</tr>
<tr>
    <td>
        <code>
            @openai/gpt-5.1-codex-mini
        </code>
    </td>
    <td>
        <div class="item-pricing">
            <small>
                Entrada:
            </small>
            <div>
                $ 0.25 <small>/1m tokens</small>
            </div>
        </div>
        <div class="item-pricing">
    <small>
        Entrada (em cache):
    </small>
    <div>
        $ 0.03 <small>/1m tokens</small>
    </div>
</div>
        <div class="item-pricing">
            <small>
                Saída:
            </small>
            <div>
                $ 2.00 <small>/1m tokens</small>
            </div>
        </div>
    </td>
    <td>
        GPT-5.1-Codex-Mini is a more compact and faster variant of GPT-5.1-Codex.
        <div class="model-capabilities">
<div>
    <i class="ri-image-circle-line"></i>
    Entrada: aceita imagens
</div>
<div>
    <i class="ri-instance-line"></i>
    Chamadas de função
</div>
<div>
    <i class="ri-lightbulb-line"></i>
    Raciocínio
</div>
<div>
    <i class="ri-braces-line"></i>
    Funções JSON
</div>
        </div>
    </td>
</tr>
<tr>
    <td>
        <code>
            @openai/gpt-5-mini
        </code>
    </td>
    <td>
        <div class="item-pricing">
            <small>
                Entrada:
            </small>
            <div>
                $ 0.25 <small>/1m tokens</small>
            </div>
        </div>
        <div class="item-pricing">
    <small>
        Entrada (em cache):
    </small>
    <div>
        $ 0.03 <small>/1m tokens</small>
    </div>
</div>
        <div class="item-pricing">
            <small>
                Saída:
            </small>
            <div>
                $ 2.00 <small>/1m tokens</small>
            </div>
        </div>
    </td>
    <td>
        GPT-5 mini is a faster, more cost-efficient version of GPT-5.
        <div class="model-capabilities">
<div>
    <i class="ri-image-circle-line"></i>
    Entrada: aceita imagens
</div>
<div>
    <i class="ri-instance-line"></i>
    Chamadas de função
</div>
<div>
    <i class="ri-braces-line"></i>
    Funções JSON
</div>
        </div>
    </td>
</tr>
<tr>
    <td>
        <code>
            @openai/gpt-4.1-mini
        </code>
    </td>
    <td>
        <div class="item-pricing">
            <small>
                Entrada:
            </small>
            <div>
                $ 0.40 <small>/1m tokens</small>
            </div>
        </div>
        <div class="item-pricing">
    <small>
        Entrada (em cache):
    </small>
    <div>
        $ 0.10 <small>/1m tokens</small>
    </div>
</div>
        <div class="item-pricing">
            <small>
                Saída:
            </small>
            <div>
                $ 1.60 <small>/1m tokens</small>
            </div>
        </div>
    </td>
    <td>
        Fast and cheap for focused tasks.
        <div class="model-capabilities">
<div>
    <i class="ri-image-circle-line"></i>
    Entrada: aceita imagens
</div>
<div>
    <i class="ri-instance-line"></i>
    Chamadas de função
</div>
<div>
    <i class="ri-braces-line"></i>
    Funções JSON
</div>
        </div>
    </td>
</tr>
<tr>
    <td>
        <code>
            @openai/gpt-oss-120b
        </code>
    </td>
    <td>
        <div class="item-pricing">
            <small>
                Entrada:
            </small>
            <div>
                $ 0.15 <small>/1m tokens</small>
            </div>
        </div>
        
        <div class="item-pricing">
            <small>
                Saída:
            </small>
            <div>
                $ 0.75 <small>/1m tokens</small>
            </div>
        </div>
    </td>
    <td>
        OpenAI's flagship open source model, built on a Mixture-of-Experts (MoE) architecture with 120 billion parameters and 128 experts.
        <div class="model-capabilities">
<div>
    <i class="ri-instance-line"></i>
    Chamadas de função
</div>
<div>
    <i class="ri-lightbulb-line"></i>
    Raciocínio
</div>
<div>
    <i class="ri-braces-line"></i>
    Funções JSON
</div>
        </div>
    </td>
</tr>
<tr>
    <td>
        <code>
            @openai/gpt-4o-mini
        </code>
    </td>
    <td>
        <div class="item-pricing">
            <small>
                Entrada:
            </small>
            <div>
                $ 0.15 <small>/1m tokens</small>
            </div>
        </div>
        <div class="item-pricing">
    <small>
        Entrada (em cache):
    </small>
    <div>
        $ 0.08 <small>/1m tokens</small>
    </div>
</div>
        <div class="item-pricing">
            <small>
                Saída:
            </small>
            <div>
                $ 0.60 <small>/1m tokens</small>
            </div>
        </div>
    </td>
    <td>
        Smaller version of 4o, optimized for everyday tasks.
        <div class="model-capabilities">
<div>
    <i class="ri-image-circle-line"></i>
    Entrada: aceita imagens
</div>
<div>
    <i class="ri-instance-line"></i>
    Chamadas de função
</div>
<div>
    <i class="ri-braces-line"></i>
    Funções JSON
</div>
        </div>
    </td>
</tr>
<tr>
    <td>
        <code>
            @openai/gpt-oss-20b
        </code>
    </td>
    <td>
        <div class="item-pricing">
            <small>
                Entrada:
            </small>
            <div>
                $ 0.10 <small>/1m tokens</small>
            </div>
        </div>
        
        <div class="item-pricing">
            <small>
                Saída:
            </small>
            <div>
                $ 0.50 <small>/1m tokens</small>
            </div>
        </div>
    </td>
    <td>
        OpenAI's flagship open source model, built on a Mixture-of-Experts (MoE) architecture with 20 billion parameters and 128 experts.
        <div class="model-capabilities">
<div>
    <i class="ri-instance-line"></i>
    Chamadas de função
</div>
<div>
    <i class="ri-lightbulb-line"></i>
    Raciocínio
</div>
<div>
    <i class="ri-braces-line"></i>
    Funções JSON
</div>
        </div>
    </td>
</tr>
<tr>
    <td>
        <code>
            @openai/gpt-4.1-nano
        </code>
    </td>
    <td>
        <div class="item-pricing">
            <small>
                Entrada:
            </small>
            <div>
                $ 0.10 <small>/1m tokens</small>
            </div>
        </div>
        <div class="item-pricing">
    <small>
        Entrada (em cache):
    </small>
    <div>
        $ 0.03 <small>/1m tokens</small>
    </div>
</div>
        <div class="item-pricing">
            <small>
                Saída:
            </small>
            <div>
                $ 0.40 <small>/1m tokens</small>
            </div>
        </div>
    </td>
    <td>
        The fastest and cheapest GPT 4.1 model.
        <div class="model-capabilities">
<div>
    <i class="ri-image-circle-line"></i>
    Entrada: aceita imagens
</div>
<div>
    <i class="ri-instance-line"></i>
    Chamadas de função
</div>
<div>
    <i class="ri-braces-line"></i>
    Funções JSON
</div>
        </div>
    </td>
</tr>
<tr>
    <td>
        <code>
            @openai/gpt-5-nano
        </code>
    </td>
    <td>
        <div class="item-pricing">
            <small>
                Entrada:
            </small>
            <div>
                $ 0.05 <small>/1m tokens</small>
            </div>
        </div>
        <div class="item-pricing">
    <small>
        Entrada (em cache):
    </small>
    <div>
        $ 0.01 <small>/1m tokens</small>
    </div>
</div>
        <div class="item-pricing">
            <small>
                Saída:
            </small>
            <div>
                $ 0.40 <small>/1m tokens</small>
            </div>
        </div>
    </td>
    <td>
        OpenAI's fastest, cheapest version of GPT-5.
        <div class="model-capabilities">
<div>
    <i class="ri-image-circle-line"></i>
    Entrada: aceita imagens
</div>
<div>
    <i class="ri-instance-line"></i>
    Chamadas de função
</div>
<div>
    <i class="ri-braces-line"></i>
    Funções JSON
</div>
        </div>
    </td>
</tr>
    </tbody>
</table>

## <img src="/assets/icon/qwen.svg" class="inline-icon"> qwen

<table>
    <thead>
        <colgroup>
            <col style="width: 30%" />
            <col style="width: 20%" />
            <col style="width: 50%" />
        </colgroup>
        <tr>
            <th>Nome do modelo</th>
            <th>Preços</th>
            <th>Descrição</th>
        </tr>
    </thead>
    <tbody>
<tr>
    <td>
        <code>
            @qwen/qwen3-max
        </code>
    </td>
    <td>
        <div class="item-pricing">
            <small>
                Entrada:
            </small>
            <div>
                $ 1.20 <small>/1m tokens</small>
            </div>
        </div>
        <div class="item-pricing">
    <small>
        Entrada (em cache):
    </small>
    <div>
        $ 0.24 <small>/1m tokens</small>
    </div>
</div>
        <div class="item-pricing">
            <small>
                Saída:
            </small>
            <div>
                $ 6.00 <small>/1m tokens</small>
            </div>
        </div>
    </td>
    <td>
        Qwen3-Max improves instruction following, multilingual ability, and tool use; reduced hallucinations.
        <div class="model-capabilities">
<div>
    <i class="ri-instance-line"></i>
    Chamadas de função
</div>
<div>
    <i class="ri-lightbulb-line"></i>
    Raciocínio
</div>
<div>
    <i class="ri-braces-line"></i>
    Funções JSON
</div>
        </div>
    </td>
</tr>
<tr>
    <td>
        <code>
            @qwen/qwen3-coder-plus
        </code>
    </td>
    <td>
        <div class="item-pricing">
            <small>
                Entrada:
            </small>
            <div>
                $ 1.00 <small>/1m tokens</small>
            </div>
        </div>
        
        <div class="item-pricing">
            <small>
                Saída:
            </small>
            <div>
                $ 5.00 <small>/1m tokens</small>
            </div>
        </div>
    </td>
    <td>
        Powered by Qwen3, this is a powerful Coding Agent that excels in tool calling and environment interaction to achieve autonomous programming.
        <div class="model-capabilities">
<div>
    <i class="ri-instance-line"></i>
    Chamadas de função
</div>
<div>
    <i class="ri-braces-line"></i>
    Funções JSON
</div>
        </div>
    </td>
</tr>
<tr>
    <td>
        <code>
            @qwen/qwen3-next-80b-a3b-it
        </code>
    </td>
    <td>
        <div class="item-pricing">
            <small>
                Entrada:
            </small>
            <div>
                $ 0.14 <small>/1m tokens</small>
            </div>
        </div>
        
        <div class="item-pricing">
            <small>
                Saída:
            </small>
            <div>
                $ 1.40 <small>/1m tokens</small>
            </div>
        </div>
    </td>
    <td>
        An 80 B-parameter instruction model with hybrid attention and Mixture‑of‑Experts, optimized for ultra‑long contexts up to 262 k tokens.
        <div class="model-capabilities">
<div>
    <i class="ri-instance-line"></i>
    Chamadas de função
</div>
<div>
    <i class="ri-braces-line"></i>
    Funções JSON
</div>
        </div>
    </td>
</tr>
<tr>
    <td>
        <code>
            @qwen/qwen3-next-80b-a3b-think
        </code>
    </td>
    <td>
        <div class="item-pricing">
            <small>
                Entrada:
            </small>
            <div>
                $ 0.14 <small>/1m tokens</small>
            </div>
        </div>
        
        <div class="item-pricing">
            <small>
                Saída:
            </small>
            <div>
                $ 1.40 <small>/1m tokens</small>
            </div>
        </div>
    </td>
    <td>
        A 80 B‑parameter “thinking‑only” model with hybrid attention and high‑sparsity MoE, designed for deep reasoning over ultra‑long contexts.
        <div class="model-capabilities">
<div>
    <i class="ri-instance-line"></i>
    Chamadas de função
</div>
<div>
    <i class="ri-lightbulb-line"></i>
    Raciocínio
</div>
<div>
    <i class="ri-braces-line"></i>
    Funções JSON
</div>
        </div>
    </td>
</tr>
<tr>
    <td>
        <code>
            @qwen/qwen3-coder-480b-a35b-it
        </code>
    </td>
    <td>
        <div class="item-pricing">
            <small>
                Entrada:
            </small>
            <div>
                $ 0.29 <small>/1m tokens</small>
            </div>
        </div>
        
        <div class="item-pricing">
            <small>
                Saída:
            </small>
            <div>
                $ 1.20 <small>/1m tokens</small>
            </div>
        </div>
    </td>
    <td>
        Qwen3-Coder-480B-A35B-Instruct is the Qwen3's most agentic code model, featuring Significant Performance on Agentic Coding, Agentic Browser-Use and other foundational coding tasks, achieving results comparable to Claude Sonnet.
        <div class="model-capabilities">
<div>
    <i class="ri-instance-line"></i>
    Chamadas de função
</div>
<div>
    <i class="ri-braces-line"></i>
    Funções JSON
</div>
        </div>
    </td>
</tr>
<tr>
    <td>
        <code>
            @qwen/qwen3-32b
        </code>
    </td>
    <td>
        <div class="item-pricing">
            <small>
                Entrada:
            </small>
            <div>
                $ 0.29 <small>/1m tokens</small>
            </div>
        </div>
        
        <div class="item-pricing">
            <small>
                Saída:
            </small>
            <div>
                $ 0.59 <small>/1m tokens</small>
            </div>
        </div>
    </td>
    <td>
        32B-parameter LLM with a 131K-token context window, offering advanced chain-of-thought reasoning, seamless tool calling, native JSON outputs, and robust multilingual fluency.
        <div class="model-capabilities">
<div>
    <i class="ri-instance-line"></i>
    Chamadas de função
</div>
<div>
    <i class="ri-lightbulb-line"></i>
    Raciocínio
</div>
<div>
    <i class="ri-braces-line"></i>
    Funções JSON
</div>
        </div>
    </td>
</tr>
    </tbody>
</table>

## <img src="/assets/icon/venice.svg" class="inline-icon"> venice

<table>
    <thead>
        <colgroup>
            <col style="width: 30%" />
            <col style="width: 20%" />
            <col style="width: 50%" />
        </colgroup>
        <tr>
            <th>Nome do modelo</th>
            <th>Preços</th>
            <th>Descrição</th>
        </tr>
    </thead>
    <tbody>
<tr>
    <td>
        <code>
            @venice/dphn-24b-uncensored
        </code>
    </td>
    <td>
        <div class="item-pricing">
            <small>
                Entrada:
            </small>
            <div>
                $ 0.10 <small>/1m tokens</small>
            </div>
        </div>
        
        <div class="item-pricing">
            <small>
                Saída:
            </small>
            <div>
                $ 0.45 <small>/1m tokens</small>
            </div>
        </div>
    </td>
    <td>
        Venice Uncensored is a fine-tuned version of Mistral-Small-24B-Instruct-2501, created by dphn.ai in partnership with Venice.ai.
        <div class="model-capabilities">
<div>
    <i class="ri-braces-line"></i>
    Funções JSON
</div>
        </div>
    </td>
</tr>
    </tbody>
</table>

## <img src="/assets/icon/x-ai.svg" class="inline-icon"> x-ai

<table>
    <thead>
        <colgroup>
            <col style="width: 30%" />
            <col style="width: 20%" />
            <col style="width: 50%" />
        </colgroup>
        <tr>
            <th>Nome do modelo</th>
            <th>Preços</th>
            <th>Descrição</th>
        </tr>
    </thead>
    <tbody>
<tr>
    <td>
        <code>
            @x-ai/grok-4
        </code>
    </td>
    <td>
        <div class="item-pricing">
            <small>
                Entrada:
            </small>
            <div>
                $ 3.00 <small>/1m tokens</small>
            </div>
        </div>
        
        <div class="item-pricing">
            <small>
                Saída:
            </small>
            <div>
                $ 15.00 <small>/1m tokens</small>
            </div>
        </div>
    </td>
    <td>
        xAI's latest and greatest flagship model, offering unparalleled performance in natural language, math and reasoning - the perfect jack of all trades.
        <div class="model-capabilities">
<div>
    <i class="ri-image-circle-line"></i>
    Entrada: aceita imagens
</div>
<div>
    <i class="ri-instance-line"></i>
    Chamadas de função
</div>
<div>
    <i class="ri-lightbulb-line"></i>
    Raciocínio
</div>
<div>
    <i class="ri-braces-line"></i>
    Funções JSON
</div>
        </div>
    </td>
</tr>
<tr>
    <td>
        <code>
            @x-ai/grok-3
        </code>
    </td>
    <td>
        <div class="item-pricing">
            <small>
                Entrada:
            </small>
            <div>
                $ 3.00 <small>/1m tokens</small>
            </div>
        </div>
        
        <div class="item-pricing">
            <small>
                Saída:
            </small>
            <div>
                $ 15.00 <small>/1m tokens</small>
            </div>
        </div>
    </td>
    <td>
        xAI's flagship model that excels at enterprise use cases like data extraction, coding, and text summarization. Possesses deep domain knowledge in finance, healthcare, law, and science.
        <div class="model-capabilities">
<div>
    <i class="ri-image-circle-line"></i>
    Entrada: aceita imagens
</div>
<div>
    <i class="ri-instance-line"></i>
    Chamadas de função
</div>
<div>
    <i class="ri-braces-line"></i>
    Funções JSON
</div>
        </div>
    </td>
</tr>
<tr>
    <td>
        <code>
            @x-ai/grok-code-fast
        </code>
    </td>
    <td>
        <div class="item-pricing">
            <small>
                Entrada:
            </small>
            <div>
                $ 0.20 <small>/1m tokens</small>
            </div>
        </div>
        <div class="item-pricing">
    <small>
        Entrada (em cache):
    </small>
    <div>
        $ 0.02 <small>/1m tokens</small>
    </div>
</div>
        <div class="item-pricing">
            <small>
                Saída:
            </small>
            <div>
                $ 1.50 <small>/1m tokens</small>
            </div>
        </div>
    </td>
    <td>
        Grok Code Fast 1 is a speedy and economical reasoning model that excels at agentic coding.
        <div class="model-capabilities">
<div>
    <i class="ri-instance-line"></i>
    Chamadas de função
</div>
<div>
    <i class="ri-braces-line"></i>
    Funções JSON
</div>
        </div>
    </td>
</tr>
<tr>
    <td>
        <code>
            @x-ai/grok-3-mini
        </code>
    </td>
    <td>
        <div class="item-pricing">
            <small>
                Entrada:
            </small>
            <div>
                $ 0.30 <small>/1m tokens</small>
            </div>
        </div>
        
        <div class="item-pricing">
            <small>
                Saída:
            </small>
            <div>
                $ 0.50 <small>/1m tokens</small>
            </div>
        </div>
    </td>
    <td>
        xAI's lightweight model that thinks before responding. Great for simple or logic-based tasks that do not require deep domain knowledge. The raw thinking traces are accessible.
        <div class="model-capabilities">
<div>
    <i class="ri-image-circle-line"></i>
    Entrada: aceita imagens
</div>
<div>
    <i class="ri-instance-line"></i>
    Chamadas de função
</div>
<div>
    <i class="ri-lightbulb-line"></i>
    Raciocínio
</div>
<div>
    <i class="ri-braces-line"></i>
    Funções JSON
</div>
        </div>
    </td>
</tr>
<tr>
    <td>
        <code>
            @x-ai/grok-4.1-fast-reasoning
        </code>
    </td>
    <td>
        <div class="item-pricing">
            <small>
                Entrada:
            </small>
            <div>
                $ 0.20 <small>/1m tokens</small>
            </div>
        </div>
        <div class="item-pricing">
    <small>
        Entrada (em cache):
    </small>
    <div>
        $ 0.05 <small>/1m tokens</small>
    </div>
</div>
        <div class="item-pricing">
            <small>
                Saída:
            </small>
            <div>
                $ 0.50 <small>/1m tokens</small>
            </div>
        </div>
    </td>
    <td>
        Grok 4.1 Fast Reasoning is xAI's most capable tool-calling model, engineered for production-grade agentic applications with a 2M token context window.
        <div class="model-capabilities">
<div>
    <i class="ri-image-circle-line"></i>
    Entrada: aceita imagens
</div>
<div>
    <i class="ri-instance-line"></i>
    Chamadas de função
</div>
<div>
    <i class="ri-lightbulb-line"></i>
    Raciocínio
</div>
<div>
    <i class="ri-braces-line"></i>
    Funções JSON
</div>
        </div>
    </td>
</tr>
<tr>
    <td>
        <code>
            @x-ai/grok-4.1-fast
        </code>
    </td>
    <td>
        <div class="item-pricing">
            <small>
                Entrada:
            </small>
            <div>
                $ 0.20 <small>/1m tokens</small>
            </div>
        </div>
        <div class="item-pricing">
    <small>
        Entrada (em cache):
    </small>
    <div>
        $ 0.05 <small>/1m tokens</small>
    </div>
</div>
        <div class="item-pricing">
            <small>
                Saída:
            </small>
            <div>
                $ 0.50 <small>/1m tokens</small>
            </div>
        </div>
    </td>
    <td>
        Grok 4.1 Fast Non-Reasoning is xAI's high-speed variant optimized for instant responses and straightforward queries, featuring a 2M token context window.
        <div class="model-capabilities">
<div>
    <i class="ri-image-circle-line"></i>
    Entrada: aceita imagens
</div>
<div>
    <i class="ri-instance-line"></i>
    Chamadas de função
</div>
<div>
    <i class="ri-braces-line"></i>
    Funções JSON
</div>
        </div>
    </td>
</tr>
<tr>
    <td>
        <code>
            @x-ai/grok-4-fast-reasoning
        </code>
    </td>
    <td>
        <div class="item-pricing">
            <small>
                Entrada:
            </small>
            <div>
                $ 0.20 <small>/1m tokens</small>
            </div>
        </div>
        <div class="item-pricing">
    <small>
        Entrada (em cache):
    </small>
    <div>
        $ 0.05 <small>/1m tokens</small>
    </div>
</div>
        <div class="item-pricing">
            <small>
                Saída:
            </small>
            <div>
                $ 0.50 <small>/1m tokens</small>
            </div>
        </div>
    </td>
    <td>
        Grok 4 Fast is xAI's latest multimodal model with SOTA cost-efficiency and a 2M token context window.
        <div class="model-capabilities">
<div>
    <i class="ri-image-circle-line"></i>
    Entrada: aceita imagens
</div>
<div>
    <i class="ri-instance-line"></i>
    Chamadas de função
</div>
<div>
    <i class="ri-lightbulb-line"></i>
    Raciocínio
</div>
<div>
    <i class="ri-braces-line"></i>
    Funções JSON
</div>
        </div>
    </td>
</tr>
<tr>
    <td>
        <code>
            @x-ai/grok-4-fast
        </code>
    </td>
    <td>
        <div class="item-pricing">
            <small>
                Entrada:
            </small>
            <div>
                $ 0.20 <small>/1m tokens</small>
            </div>
        </div>
        <div class="item-pricing">
    <small>
        Entrada (em cache):
    </small>
    <div>
        $ 0.05 <small>/1m tokens</small>
    </div>
</div>
        <div class="item-pricing">
            <small>
                Saída:
            </small>
            <div>
                $ 0.50 <small>/1m tokens</small>
            </div>
        </div>
    </td>
    <td>
        Grok 4 Fast is xAI's latest multimodal model with SOTA cost-efficiency and a 2M token context window.
        <div class="model-capabilities">
<div>
    <i class="ri-image-circle-line"></i>
    Entrada: aceita imagens
</div>
<div>
    <i class="ri-instance-line"></i>
    Chamadas de função
</div>
<div>
    <i class="ri-braces-line"></i>
    Funções JSON
</div>
        </div>
    </td>
</tr>
    </tbody>
</table>

## <img src="/assets/icon/z-ai.svg" class="inline-icon"> z-ai

<table>
    <thead>
        <colgroup>
            <col style="width: 30%" />
            <col style="width: 20%" />
            <col style="width: 50%" />
        </colgroup>
        <tr>
            <th>Nome do modelo</th>
            <th>Preços</th>
            <th>Descrição</th>
        </tr>
    </thead>
    <tbody>
<tr>
    <td>
        <code>
            @z-ai/glm-4.6
        </code>
    </td>
    <td>
        <div class="item-pricing">
            <small>
                Entrada:
            </small>
            <div>
                $ 0.60 <small>/1m tokens</small>
            </div>
        </div>
        
        <div class="item-pricing">
            <small>
                Saída:
            </small>
            <div>
                $ 2.00 <small>/1m tokens</small>
            </div>
        </div>
    </td>
    <td>
        GLM‑4.6 is a high‑capacity LLM with a 200K‑token context window, strong coding and reasoning abilities, and enhanced tool‑use capabilities.
        <div class="model-capabilities">
<div>
    <i class="ri-instance-line"></i>
    Chamadas de função
</div>
<div>
    <i class="ri-lightbulb-line"></i>
    Raciocínio
</div>
<div>
    <i class="ri-braces-line"></i>
    Funções JSON
</div>
        </div>
    </td>
</tr>
    </tbody>
</table>

